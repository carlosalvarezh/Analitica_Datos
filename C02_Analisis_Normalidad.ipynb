{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d9048b9",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Analítica de datos para la toma de decisiones empresariales</h1>\n",
    "<h1 align=\"center\">Análisis de Normalidad</h1>\n",
    "<h1 align=\"center\">Centro de Educación Continua</h1>\n",
    "<h1 align=\"center\">EAFIT</h1>\n",
    "<h1 align=\"center\">2023</h1>\n",
    "<h1 align=\"center\">MEDELLÍN - COLOMBIA</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a8d9e",
   "metadata": {},
   "source": [
    "*** \n",
    "|![Gmail](https://img.shields.io/badge/Gmail-D14836?style=plastic&logo=gmail&logoColor=white)|<carlosalvarezh@gmail.com>|![Outlook](https://img.shields.io/badge/Microsoft_Outlook-0078D4?style=plastic&logo=microsoft-outlook&logoColor=white)|<calvar52@eafit.edu.co>|\n",
    "|-:|:-|--:|:--|\n",
    "|[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=plastic&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/carlosalvarez5/)|[![@alvarezhenao](https://img.shields.io/twitter/url/https/twitter.com/alvarezhenao.svg?style=social&label=Follow%20%40alvarezhenao)](https://twitter.com/alvarezhenao)|[![@carlosalvarezh](https://img.shields.io/badge/github-%23121011.svg?style=plastic&logo=github&logoColor=white)](https://github.com/carlosalvarezh)|[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/carlosalvarezh/Curso_CEC_EAFIT/blob/main/C02_Analisis_Normalidad.ipynb)|\n",
    "\n",
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/CCLogoColorPop1.gif?raw=true\" width=\"25\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license.(c) Carlos Alberto Alvarez Henao</td>\n",
    "</table>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3352bab9",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/Normal.PNG?raw=true\" width=\"350\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2373f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                # biblioteca numérica\n",
    "import pandas as pd               # biblioteca para analítica de datos\n",
    "import seaborn as sns             # biblioteca para graficación\n",
    "import matplotlib.pyplot as plt   # biblioteca para graficación\n",
    "\n",
    "import scipy.stats as stats       # biblioteca para estadística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c145a0",
   "metadata": {},
   "source": [
    "## Análisis de Normalidad y Exploración de Modelos Probabilísticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382d4831",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae81f0",
   "metadata": {},
   "source": [
    "En el mundo de la estadística, es fundamental comprender cómo los datos se distribuyen y qué modelos probabilísticos subyacen a ellos. Esto nos permite realizar inferencias, tomar decisiones informadas y construir modelos predictivos sólidos. En este tema, exploraremos el concepto de normalidad y otros modelos explicativos de la incertidumbre detrás de los datos, utilizando herramientas del ecosistema de Python, como NumPy, Pandas, Matplotlib y Seaborn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce83026",
   "metadata": {},
   "source": [
    "### Análisis de Normalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4ea2a",
   "metadata": {},
   "source": [
    "#### Definición de la Distribución Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c15053",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/C02_04_Normal_Distribution.jpg?raw=true\" width=\"150\" />\n",
    "</p>\n",
    "\n",
    "La [distribución normal](https://en.wikipedia.org/wiki/Normal_distribution), también conocida como distribución gaussiana, es una de las distribuciones más importantes en estadística. Se caracteriza por su forma de campana y es ampliamente utilizada debido al [Teorema Central del Límite](https://en.wikipedia.org/wiki/Central_limit_theorem), que establece que las sumas de variables aleatorias independientes tienden a seguir una distribución normal. Está completamente definida por dos parámetros: la media ($\\mu$) y la desviación estándar ($\\sigma$). Se denota como N($\\mu$, $\\sigma^2$), donde $\\mu$ es la media y $\\sigma^2$ es la varianza. \n",
    "\n",
    "En estadísticas, una distribución normal o distribución gaussiana es un tipo de distribución de probabilidad continua para una variable aleatoria de valores reales. La forma general de su función de densidad de probabilidad es:\n",
    "\n",
    "$$f(x)=\\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{1}{2} \\left(\\frac{x-\\mu}{\\sigma} \\right)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e6ae70",
   "metadata": {},
   "source": [
    "#### Características Importantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9a24b5",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/C02_05Standard_deviation_diagram_micro.svg?raw=true\" width=\"350\" />\n",
    "</p>\n",
    "\n",
    "Fuente: https://upload.wikimedia.org/wikipedia/commons/8/8c/Standard_deviation_diagram.svg\n",
    "\n",
    "- ***Forma Simétrica:*** La distribución normal es simétrica respecto a su media, $\\mu$. Esto significa que la mitad de la curva se encuentra a la izquierda y la otra mitad a la derecha de la media, y ambas partes son idénticas en forma.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Media, Mediana y Moda Igual:*** En una distribución normal, la mediana y la moda coinciden en el valor de la media ($\\mu$), lo que demuestra su simetría.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***68-95-99.7 Regla:*** Aproximadamente el $68\\%$ de los datos se encuentran dentro de una desviación estándar de la media, $[\\mu-\\sigma, \\mu +\\sigma]$. Alrededor del $95\\%$ dentro de dos desviaciones estándar,$[\\mu-2\\sigma, \\mu +2\\sigma]$, y aproximadamente el $99.7\\%$ dentro de tres desviaciones estándar, $[\\mu-3\\sigma, \\mu +3\\sigma]$.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Distribución Estándar:*** La [distribución normal estándar ($Z$)](https://en.wikipedia.org/wiki/Standard_normal_table) es una versión especial con media $0$ y desviación estándar $1$. Cualquier distribución normal puede ser transformada en la distribución normal estándar mediante la fórmula \n",
    "\n",
    "$$Z = \\frac{(x - \\mu)}{\\sigma}$$\n",
    "\n",
    "Emplearemos la función [`random.normal(loc=, scale=, size=)`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html) del módulo `numpy` de python, donde, `loc` es la media del conjunto de los datos, `scale` es la desviación estándar, y `size` es el tamaño de la muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b9409",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parámetros de la distribución normal estandard\n",
    "mu = 0     # Media\n",
    "sigma = 1  # Desviación estándar\n",
    "\n",
    "# Generar datos de la distribución normal\n",
    "datos = np.random.normal(mu, sigma, 1000)\n",
    "\n",
    "# Crear el histograma\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(datos, bins=30, density=True, alpha=0.6, color='b', label='Histograma')\n",
    "\n",
    "# Crear la curva de densidad de probabilidad teórica\n",
    "x = np.linspace(-4.0, 4.0, 100)\n",
    "pdf = stats.norm.pdf(x, mu, sigma)\n",
    "plt.plot(x, pdf, 'r-', label='Distribución Normal')\n",
    "\n",
    "# Línea vertical para la media\n",
    "plt.axvline(mu, color='k', linestyle='dashed', linewidth=1, label='$\\mu (media)$')\n",
    "\n",
    "# Líneas verticales para ±1 desviación estándar\n",
    "std_dev = sigma\n",
    "plt.axvline(mu - std_dev, color='g', linestyle='dashed', linewidth=1, label='$\\mu \\pm \\sigma$')\n",
    "plt.axvline(mu + std_dev, color='g', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(mu - 2*std_dev, color='b', linestyle='dashed', linewidth=1, label='$\\mu \\pm 2\\sigma$')\n",
    "plt.axvline(mu + 2*std_dev, color='b', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(mu - 3*std_dev, color='r', linestyle='dashed', linewidth=1, label='$\\mu \\pm 3\\sigma$')\n",
    "plt.axvline(mu + 3*std_dev, color='r', linestyle='dashed', linewidth=1)\n",
    "\n",
    "# Configurar el gráfico\n",
    "plt.title('Distribución Normal')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Densidad de Probabilidad')\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d70cb99",
   "metadata": {},
   "source": [
    "La *media* determina el centro de la curva. Esto significa que la *media* es el punto en el que la curva alcanza su punto más alto y se simetriza. Si aumentamos la *media*, la curva se moverá hacia la derecha en el eje horizontal.\n",
    "\n",
    "Por otro lado, la *desviación estándar*, $\\sigma$ estira o comprime la curva. Cuando la *desviación estándar* es pequeña, la curva resultante será estrecha y puntiaguda, lo que indica que la mayoría de los datos se encuentran cerca de la media. Por el contrario, si la *desviación estándar* es grande, la curva se ensanchará, lo que sugiere que los datos están más dispersos alrededor de la media.\n",
    "\n",
    "En resumen, estos dos parámetros, la media y la desviación estándar, son fundamentales para describir cómo se distribuyen los datos en una distribución normal y cómo se relaciona la forma de la curva con esos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Parámetros de las distribuciones normales\n",
    "params = [\n",
    "    {\"mean\": 0, \"std\": 1, \"label\": \"$\\mu=0, \\sigma = 1:$ Standar Normal\"},\n",
    "    {\"mean\": 0, \"std\": 0.5, \"label\": \"$\\mu=0, \\sigma = 0.5:$ Squeezed\"},\n",
    "    {\"mean\": 0, \"std\": 2, \"label\": \"$\\mu=0, \\sigma = 2:$ Stretched\"},\n",
    "    {\"mean\": 1, \"std\": 1, \"label\": \"$\\mu=1, \\sigma = 1:$ Shifted Right\"},\n",
    "    {\"mean\": -1, \"std\": 1, \"label\": \"$\\mu=-1, \\sigma = 1:$ Shifted Left\"},\n",
    "]\n",
    "\n",
    "# Crear un rango de valores x\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "\n",
    "# Configurar la figura\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.title(\"Distribuciones Normales\")\n",
    "plt.xlabel(\"Valor\")\n",
    "plt.ylabel(\"Densidad de Probabilidad\")\n",
    "\n",
    "# Graficar cada distribución normal\n",
    "for param in params:\n",
    "    y = norm.pdf(x, loc=param[\"mean\"], scale=param[\"std\"])\n",
    "    plt.plot(x, y, label=param[\"label\"])\n",
    "\n",
    "# Mostrar leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar la figura\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe8a19",
   "metadata": {},
   "source": [
    "### Indicadores de Normalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfac5d36",
   "metadata": {},
   "source": [
    "|<p float=\"center\"><img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/MemeNormal01.jpeg?raw=true\" width=\"200\"/></p>|<p float=\"center\"><img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/MemeNormal02.jpeg?raw=true\" width=\"200\" /></p>|\n",
    "|:--:|:---:|\n",
    "| | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab632b8f",
   "metadata": {},
   "source": [
    "#### Histograma y Gráficos de Densidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad988f",
   "metadata": {},
   "source": [
    "El histograma es una representación gráfica de la distribución de frecuencias de los datos. Divide el rango de valores en intervalos (llamados \"bins\") y muestra cuántos datos caen en cada intervalo. Los gráficos de densidad muestran la estimación de la densidad de probabilidad de los datos, proporcionando una visión suave de la distribución.\n",
    "\n",
    "***Uso:*** Estos gráficos permiten visualizar la forma general de la distribución y detectar signos de simetría o asimetría, además de ayudar a identificar valores atípicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos simulados con distribución normal\n",
    "np.random.seed(42)\n",
    "data = np.random.normal(loc=0, scale=2, size=1000)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Histograma y Gráfico de Densidad\n",
    "fig, ax = plt.subplots()\n",
    "ax.remove()\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(data, bins=20, kde=True)\n",
    "plt.title(\"Histograma\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.kdeplot(data)\n",
    "plt.title(\"Gráfico de Densidad\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a32aa",
   "metadata": {},
   "source": [
    "#### Gráfico Cuantil-Cuantil (Q-Q plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd05eee",
   "metadata": {},
   "source": [
    "Compara los cuantiles observados de los datos con los cuantiles esperados de una distribución teórica (como la normal). Si los puntos en el gráfico se ajustan aproximadamente a una línea diagonal, los datos son consistentes con la distribución teórica.\n",
    "\n",
    "***Uso:*** Es una herramienta visual para evaluar la normalidad de los datos y detectar desviaciones significativas de la distribución normal.\n",
    "\n",
    "Se usará la función [`qqplot()`](https://www.statsmodels.org/stable/generated/statsmodels.graphics.gofplots.qqplot.html) de la biblioteca [`statsmodels` ](https://www.statsmodels.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacde24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Generar datos simulados con distribución normal\n",
    "plt.figure(figsize=(6, 4))\n",
    "np.random.seed(42)\n",
    "data = np.random.normal(loc=0, scale=1, size=1000)\n",
    "\n",
    "# Gráfico Cuantil-Cuantil\n",
    "sm.qqplot(data, line='45')\n",
    "plt.title(\"Gráfico Cuantil-Cuantil\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6d8555",
   "metadata": {},
   "source": [
    "#### Prueba de Normalidad Shapiro-Wilk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc14f99",
   "metadata": {},
   "source": [
    "La prueba de [Shapiro-Wilk](https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test) es una prueba de hipótesis que evalúa si un conjunto de datos sigue una distribución normal. La hipótesis nula ($H0$) es que los datos siguen una distribución normal. La estadística de prueba en esta prueba es el estadístico de Shapiro-Wilk ($W$).\n",
    "\n",
    "El estadístico $W$ se obtiene como la relación entre dos estimaciones de la varianza de los datos: una estimación basada en los valores ordenados y otra basada en los valores esperados bajo la hipótesis de normalidad. La fórmula completa es bastante compleja y utiliza coeficientes especiales calculados a partir de una matriz de covarianza y términos de regresión. Sin embargo, la versión simplificada proporciona una idea general del cálculo:\n",
    "\n",
    "El estadístico de prueba de Shapiro-Wilk ($W$) se calcula de la siguiente manera:\n",
    "\n",
    "1. Los datos observados se ordenan en orden ascendente y se denotan como $x_{(1)}, x_{(2)}, \\ldots, x_{(n)}$, donde $n$ es el tamaño de la muestra.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "2. Se calcula un vector de coeficientes $a$ basado en los valores ordenados y se denota como $a_1, a_2, \\ldots, a_n$.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "3. Se calcula un vector de coeficientes $b$ basado en el tamaño de la muestra $n$ y se denota como $b_1, b_2, \\ldots, b_n$.\n",
    "<p>&nbsp;</p>\n",
    "4. El estadístico $W$ se calcula como la suma de productos cruzados de los coeficientes $a$ y $b$:\n",
    "\n",
    "$$\n",
    "W = \\frac{\\left(\\sum_{i=1}^{n} a_i x_{(i)}\\right)^2}{\\sum_{i=1}^{n} (x_{(i)} - \\bar{x})^2}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $x_{(i)}$ son los valores ordenados de los datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- $\\bar{x}$ es la media de los datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- $a_i$ y $b_i$ son los coeficientes calculados a partir de los valores ordenados y el tamaño de la muestra.\n",
    "\n",
    "La fórmula completa y los coeficientes $a$ y $b$ involucran cálculos más complejos, pero esta versión simplificada del estadístico $W$ es una aproximación que proporciona una idea general del proceso de cálculo.\n",
    "\n",
    "En este curso emplearemos la fuunción [`stats.shapiro`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html) de la biblioteca `scipy` para realizar la prueba de Shapiro-Wilk y calcular el valor $p$ sin necesidad de conocer la fórmula completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b457849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos simulados con distribución normal\n",
    "np.random.seed(42)\n",
    "data = np.random.normal(loc=0, scale=1, size=1000)\n",
    "\n",
    "# data = pd.DataFrame('Data/datos.csv') # cuando los datos provienen de un file\n",
    "\n",
    "# Prueba de Normalidad Shapiro-Wilk\n",
    "shapiro_stat, shapiro_p_value = stats.shapiro(data)\n",
    "print(f\"Estadístico de Shapiro-Wilk: {shapiro_stat}\")\n",
    "print(f\"p-valor de Shapiro-Wilk: {shapiro_p_value}\")\n",
    "\n",
    "if shapiro_p_value > 0.05:\n",
    "    print(\"Los datos siguen una distribución normal (no se rechaza H0)\")\n",
    "else:\n",
    "    print(\"Los datos no siguen una distribución normal (se rechaza H0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c966c6f9",
   "metadata": {},
   "source": [
    "#### Prueba de Normalidad Anderson-Darling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3f0bf4",
   "metadata": {},
   "source": [
    "La prueba de [Anderson-Darling](https://en.wikipedia.org/wiki/Anderson%E2%80%93Darling_test) es una prueba de hipótesis que evalúa si un conjunto de datos sigue una distribución normal. La hipótesis nula ($H_0$) es que los datos son normalmente distribuidos. La estadística de prueba es el estadístico de Anderson-Darling $(A^2$).\n",
    "\n",
    "Ecuación del estadístico de Anderson-Darling:\n",
    "$$\n",
    "A^2 = -n - \\frac{1}{n}\\sum_{i=1}^{n}(2i-1)[\\ln(F(X_i)) + \\ln(1 - F(X_{n+1-i}))]\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $n$ es el tamaño de la muestra.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- $X_i$ son los datos ordenados.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- $F(X_i)$ es la función de distribución acumulativa (CDF) empírica de los datos.\n",
    "\n",
    "***Usos:*** La prueba de Anderson-Darling es útil para verificar la normalidad y puede detectar desviaciones de la normalidad en las colas de la distribución.\n",
    "\n",
    "***Limitaciones:*** La interpretación de los resultados puede ser más complicada que otras pruebas, y la prueba puede ser sensible al tamaño de la muestra.\n",
    "\n",
    "***Ejemplo:*** Se usará la función [`anderson`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.anderson.html) de la biblioteca [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import anderson\n",
    "\n",
    "# Generar datos aleatorios con distribución normal\n",
    "np.random.seed(0)\n",
    "data = np.random.normal(loc=0, scale=1, size=100)\n",
    "\n",
    "# Prueba de Anderson-Darling\n",
    "result = anderson(data)\n",
    "\n",
    "print(\"Estadístico de Anderson-Darling:\", result.statistic)\n",
    "print(\"Valores críticos:\", result.critical_values)\n",
    "print(\"Niveles de significancia:\", result.significance_level)\n",
    "\n",
    "if result.statistic < result.critical_values[2]:\n",
    "    print(\"Los datos siguen una distribución normal (no se rechaza H0)\")\n",
    "else:\n",
    "    print(\"Los datos no siguen una distribución normal (se rechaza H0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac7784d",
   "metadata": {},
   "source": [
    "***Análisis de resultados:***\n",
    "\n",
    "Dado que el valor del estadístico de *Anderson-Darling* ($0.18098$) es mucho menor que el valor crítico más restrictivo ($1.053$) para todos los niveles de significancia proporcionados, no se rechaza la hipótesis nula. Esto sugiere que los datos se ajustan bien a una distribución normal. Cuanto menor sea el estadístico en relación con los valores críticos, mayor será la evidencia a favor de la normalidad de los datos.\n",
    "\n",
    "En resumen, los resultados indican que, según la prueba de *Anderson-Darling*, no hay suficiente evidencia para concluir que los datos no siguen una distribución normal. Los datos parecen seguir una distribución normal dentro de los límites de significancia especificados en el análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a8013d",
   "metadata": {},
   "source": [
    "#### Prueba de Jarque-Bera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afac466",
   "metadata": {},
   "source": [
    "La prueba de [Jarque-Bera](https://en.wikipedia.org/wiki/Jarque%E2%80%93Bera_test) es una prueba de normalidad que evalúa si un conjunto de datos sigue una distribución normal basándose en sus momentos de tercer y cuarto orden, es decir, la asimetría (skewness) y la curtosis (kurtosis) de los datos. Fue desarrollada por Carlos Jarque y Anil Bera en 1987. Esta prueba es útil para identificar desviaciones de la normalidad debido a asimetría o curtosis en los datos.\n",
    "\n",
    "El estadístico de prueba de *Jarque-Bera* se calcula utilizando las siguientes fórmulas:\n",
    "\n",
    "1. ***Asimetría (Skewness):***\n",
    "   - Asimetría (skewness) muestral ($S$) se calcula como:\n",
    "     $$\n",
    "     S = \\frac{\\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^3}{\\left(\\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\\right)^{\\frac{3}{2}}}\n",
    "     $$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "   - Donde $x_i$ son los valores de la muestra, $\\bar{x}$ es la media de la muestra y $n$ es el tamaño de la muestra.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "2. ***Curtosis (Kurtosis):***\n",
    "   - Curtosis (kurtosis) muestral $(K$) se calcula como:\n",
    "     $$\n",
    "     K = \\frac{\\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^4}{\\left(\\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\\right)^2} - 3\n",
    "     $$\n",
    "<p>&nbsp;</p>\n",
    "3. ***Estadístico de Jarque-Bera ($JB$):***\n",
    "   - El estadístico de Jarque-Bera se calcula como:\n",
    "     $$\n",
    "     JB = \\frac{n}{6} \\left(S^2 + \\frac{1}{4}(K - 3)^2\\right)\n",
    "     $$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "   - Donde $n$ es el tamaño de la muestra, $S$ es la asimetría y $K$ es la curtosis.\n",
    "\n",
    "***Interpretación de Resultados***\n",
    "\n",
    "Para interpretar los resultados de la prueba de Jarque-Bera, se compara el estadístico de *Jarque-Bera* $(JB$) con un valor crítico basado en la distribución *chi-cuadrado*. Bajo la hipótesis nula de que los datos siguen una distribución normal, el estadístico $JB$ sigue una *distribución chi-cuadrado* con $2$ grados de libertad.\n",
    "\n",
    "- Si el estadístico $JB$ es significativamente menor que el valor crítico de *chi-cuadrado*, no se rechaza la hipótesis nula, lo que sugiere que los datos pueden ser aproximadamente normales en términos de asimetría y curtosis.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Si el estadístico $JB$ es significativamente mayor que el valor crítico de *chi-cuadrado*, se rechaza la hipótesis nula, lo que indica que los datos no siguen una distribución normal en términos de asimetría y curtosis.\n",
    "\n",
    "***Usos:***\n",
    "- La prueba de *Jarque-Bera* se utiliza comúnmente en la econometría y las finanzas para verificar la normalidad de los residuos en modelos de regresión y series temporales.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Es útil para detectar desviaciones de la normalidad debido a asimetría o curtosis en los datos.\n",
    "\n",
    "***Limitaciones:***\n",
    "- La prueba de *Jarque-Bera* se centra en asimetría y curtosis y no aborda otras posibles desviaciones de la normalidad, como colas pesadas.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Como muchas pruebas de normalidad, su capacidad para detectar desviaciones de la normalidad puede verse afectada por el tamaño de la muestra.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Puede ser sensible a valores atípicos en los datos.\n",
    "\n",
    "En resumen, la prueba de *Jarque-Bera* es una herramienta útil para evaluar la normalidad de los datos basándose en asimetría y curtosis. Sin embargo, como con cualquier prueba de normalidad, es importante considerar el contexto y las limitaciones antes de interpretar los resultados.\n",
    "\n",
    "Se usará la función [`jarque_bera`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.jarque_bera.html) de la biblioteca `scipy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bb58e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import jarque_bera\n",
    "\n",
    "# Generar datos aleatorios con distribución normal\n",
    "np.random.seed(0)\n",
    "data = np.random.normal(loc=0, scale=1, size=100)\n",
    "\n",
    "# Prueba de Jarque-Bera\n",
    "statistic, p_value = jarque_bera(data)\n",
    "\n",
    "print(\"Estadístico de Jarque-Bera:\", statistic)\n",
    "print(\"Valor p:\", p_value)\n",
    "\n",
    "if p_value > 0.05:\n",
    "    print(\"Los datos siguen una distribución normal (no se rechaza H0)\")\n",
    "else:\n",
    "    print(\"Los datos no siguen una distribución normal (se rechaza H0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d559f768",
   "metadata": {},
   "source": [
    "#### Prueba de Lilliefors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce727c4",
   "metadata": {},
   "source": [
    "El estadístico de prueba de [Lilliefors](https://en.wikipedia.org/wiki/Lilliefors_test) ($D$) es similar al estadístico de *Kolmogorov-Smirnov*, *KS* (que será visto más adelante en las pruebas no paramétricas) pero se ajusta específicamente para evaluar la normalidad de los datos. El estadístico de Lilliefors se calcula utilizando la siguiente fórmula::\n",
    "\n",
    "$$\n",
    "D = \\max \\left[ \\max_{1 \\leq i \\leq n} \\left( \\frac{i}{n} - F(X_{(i)}) \\right), \\max_{1 \\leq i \\leq n} \\left( F(X_{(i)}) - \\frac{i-1}{n} \\right) \\right]\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $D$ es el estadístico de Lilliefors.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- $n$ es el tamaño de la muestra.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- $F(X_{(i)})$ es la *función de distribución acumulativa* (*CDF*) empírica en el $i$-ésimo valor ordenado.\n",
    "\n",
    "***Usos***\n",
    "- Verificar si un conjunto de datos sigue una distribución normal sin hacer suposiciones sobre los parámetros de esa distribución.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Es especialmente útil cuando se quiere evaluar la normalidad de los datos sin especificar una media y desviación estándar teóricas.\n",
    "\n",
    "***Limitaciones***\n",
    "- Al igual que la prueba de KS, la prueba de Lilliefors puede ser sensible al tamaño de la muestra, lo que significa que en muestras grandes, pequeñas desviaciones de la distribución normal pueden llevar al rechazo de la hipótesis nula.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- La prueba es adecuada principalmente para distribuciones continuas y puede no ser tan eficaz para datos discretos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- La prueba no proporciona información sobre los parámetros específicos de la distribución normal.\n",
    "\n",
    "***Interpretación de Resultados***\n",
    "\n",
    "La interpretación de los resultados de la prueba de *Lilliefors* es similar a la de la prueba de *KS*. Se compara el estadístico $D$ calculado con un valor crítico obtenido de tablas o mediante métodos computacionales. Las hipótesis son las siguientes:\n",
    "\n",
    "1. ***Hipótesis Nula ($H_0$):*** Los datos siguen una distribución normal.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "2. ***Hipótesis Alternativa ($H_1$):*** Los datos no siguen una distribución normal.\n",
    "\n",
    "Si el valor calculado del estadístico $D$ es menor o igual al valor crítico para un nivel de significancia dado, no se rechaza la hipótesis nula, lo que sugiere que los datos pueden seguir una distribución normal. En cambio, si el valor calculado de $D$ es mayor que el valor crítico, se rechaza la hipótesis nula, indicando que los datos difieren significativamente de la distribución normal.\n",
    "\n",
    "En resumen, la prueba de *Lilliefors* es una variante de la prueba de *Kolmogorov-Smirnov* específicamente diseñada para evaluar la normalidad de los datos. Su capacidad para detectar desviaciones de la normalidad depende del tamaño de la muestra y del nivel de significancia elegido, al igual que la prueba de *KS*.\n",
    "\n",
    "Se usará la función [`lilliefors`](https://www.statsmodels.org/devel/generated/statsmodels.stats.diagnostic.lilliefors.html) de la biblioteca `scipy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1caac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "\n",
    "# Generar datos aleatorios con distribución normal\n",
    "np.random.seed(0)\n",
    "data = np.random.normal(loc=0, scale=1, size=100)\n",
    "\n",
    "# Prueba de Lilliefors\n",
    "statistic, p_value = lilliefors(data)\n",
    "\n",
    "print(\"Estadístico de Lilliefors:\", statistic)\n",
    "print(\"Valor p:\", p_value)\n",
    "\n",
    "if p_value > 0.05:\n",
    "    print(\"Los datos siguen una distribución normal (no se rechaza H0)\")\n",
    "else:\n",
    "    print(\"Los datos no siguen una distribución normal (se rechaza H0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dbfe24",
   "metadata": {},
   "source": [
    "### Distribuciones de Probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0376f6",
   "metadata": {},
   "source": [
    "Las [distribuciones de probabilidad](https://en.wikipedia.org/wiki/Probability_distribution) son un pilar fundamental en la estadística y la analítica de datos. Estas distribuciones son herramientas que nos permiten describir y comprender el comportamiento de las variables aleatorias y modelar la incertidumbre en una amplia gama de situaciones en la vida real. Desde la predicción de eventos futuros hasta la toma de decisiones en condiciones de incertidumbre, las distribuciones de probabilidad desempeñan un papel esencial.\n",
    "\n",
    "Una variable aleatoria es un concepto central en este contexto, y puede tomar un conjunto de valores posibles, donde cada valor tiene una probabilidad asociada. Las distribuciones de probabilidad describen cómo se distribuyen estas probabilidades entre los valores posibles de una variable aleatoria. Comprender y caracterizar estas distribuciones es crucial para resolver preguntas fundamentales, como:\n",
    "\n",
    "1. ¿Cuál es la probabilidad de que un evento ocurra en una situación dada?\n",
    "2. ¿Cuál es el valor esperado de una variable aleatoria?\n",
    "3. ¿Cuál es la variabilidad asociada con una medición o proceso?\n",
    "\n",
    "Existen diferentes tipos de distribuciones de probabilidad, cada una con propiedades y aplicaciones únicas. Algunas de las distribuciones más conocidas incluyen la distribución normal, la distribución binomial, la distribución de Poisson y la distribución exponencial, por nombrar algunas. Cada una de estas distribuciones modela un tipo específico de fenómeno o proceso y se utiliza para resolver una variedad de problemas en diversos campos, como la ciencia, la ingeniería, la economía y la salud.\n",
    "\n",
    "<div class=\"alert alert alert-info\">\n",
    "Por lo vasto del tema, se ha generado el documento <a href=\"./CrashCourse07_DistribucionesProbabilidad.ipynb\">CrashCourse07_DistribucionesProbabilidad</a> en donde encontrará una discusión más ámplia sobre distribuciones de probabilidad.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a17cd6",
   "metadata": {},
   "source": [
    "## Estimación Puntual de Indicadores y margen de error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076294b1",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba6dc31",
   "metadata": {},
   "source": [
    "En estadística, uno de los objetivos fundamentales es obtener información confiable y útil sobre una población a partir de una muestra de datos. La estimación puntual y la construcción de intervalos de confianza son herramientas esenciales para lograr esto. En este capítulo, exploraremos cómo estimar parámetros poblacionales a partir de muestras y cómo medir la incertidumbre asociada a estas estimaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd516e",
   "metadata": {},
   "source": [
    "### Estimación Puntual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6309dae4",
   "metadata": {},
   "source": [
    "La Estimación Puntual se refiere a la técnica de calcular un valor numérico para un parámetro poblacional utilizando información de una muestra de datos. El objetivo es encontrar el mejor valor posible para el parámetro, basándose en la información que tenemos disponible. \n",
    "\n",
    "Uno de los estimadores más simples y ampliamente utilizados es la [***media muestral***](https://es.wikipedia.org/wiki/Estad%C3%ADstico_muestral), que es el valor promedio de una [muestra](https://es.wikipedia.org/wiki/Muestreo_(estad%C3%ADstica)) específica tomada de una población más grande. Dado que generalmente no tenemos acceso a toda la población, trabajamos con muestras para inferir información sobre la población en su conjunto. La media muestral se calcula de la misma manera que la <a href=\"#mean\">media aritmética</a>,</div> pero se utiliza en el contexto de una muestra y se denota a menudo como $\\bar{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a57293f",
   "metadata": {},
   "source": [
    "### Intervalos de Confianza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d57ec5c",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/IntervaloConfianza.avif?raw=true\" width=\"300\" />\n",
    "</p>\n",
    "\n",
    "[![@akshay_pachaar](https://img.shields.io/twitter/url/https/twitter.com/akshay_pachaar.svg?style=social&label=Follow%20%40akshay_pachaar)](https://twitter.com/akshay_pachaar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc86a0",
   "metadata": {},
   "source": [
    "#### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d32d483",
   "metadata": {},
   "source": [
    "La Estimación Puntual es valiosa, pero también queremos cuantificar la incertidumbre asociada a nuestras estimaciones. Aquí es donde entran en juego los [*Intervalos de Confianza*](https://en.wikipedia.org/wiki/Confidence_interval). Estos intervalos proporcionan un rango de valores dentro del cual es probable que se encuentre el <font color=\"blue\">verdadero valor del parámetro poblacional</font>.\n",
    "\n",
    "Un intervalo de confianza generalmente tiene la forma: $\\text{Estimación Puntual} \\pm \\text{Margen de Error}$.\n",
    "\n",
    "El [***Margen de Error***](https://en.wikipedia.org/wiki/Margin_of_error) depende de dos factores principales: el *nivel de confianza deseado* y *la variabilidad de los datos*. Un nivel de confianza típico es del $95\\%$, lo que significa que si repitiéramos el proceso de muestreo y cálculo muchas veces, aproximadamente el $95\\%$ de los intervalos de confianza construidos contendrían el verdadero parámetro poblacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470d6bb0",
   "metadata": {},
   "source": [
    "#### Construcción de Intervalos de Confianza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3625dd",
   "metadata": {},
   "source": [
    "Supongamos que estamos interesados en construir un intervalo de confianza para la media muestral ($\\bar{x}$) basado en una muestra de datos. Si asumimos que los datos siguen una [distribución normal](https://en.wikipedia.org/wiki/Normal_distribution), el intervalo de confianza se calcula usando la fórmula:\n",
    "\n",
    "$$\\text{Intervalo de Confianza}=\\bar{x} \\pm Z \\cdot \\frac{\\sigma}{\\sqrt{n}}$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $\\bar{x}$ es la media muestral.\n",
    "- $Z$ es el valor crítico de la distribución normal estándar correspondiente al nivel de confianza.\n",
    "- $\\sigma$ es la desviación estándar muestral.\n",
    "- $n$ es el tamaño de la muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179158d7",
   "metadata": {},
   "source": [
    "***Ejemplo: Estimación de la Altura Promedio***\n",
    "\n",
    "Supongamos que queremos estimar la altura promedio de los estudiantes en una universidad. Tomamos una muestra aleatoria de 50 estudiantes y obtenemos las siguientes alturas (en centímetros):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909327b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(42)\n",
    "altura_muestra = np.random.normal(165, 10, 50)  # Media: 165 cm, Desviación estándar: 10 cm\n",
    "\n",
    "altura_muestra_rounded = np.around(altura_muestra, decimals=2)\n",
    "#print(altura_muestra_rounded)\n",
    "\n",
    "media = np.mean(altura_muestra, dtype=np.float64)\n",
    "media_rounded = round(media, 2)  # Redondear a dos cifras decimales\n",
    "print(media_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcab478",
   "metadata": {},
   "source": [
    "La media muestral es $\\bar{x} = 162.75$ cm. Ahora, construyamos un intervalo de confianza al $95\\%$ para la altura promedio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba22f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "nivel_confianza = 0.975\n",
    "grados_libertad = 49  # n - 1\n",
    "\n",
    "z_score = stats.norm.ppf(1 - (1 - nivel_confianza) / 2)  # Valor crítico\n",
    "\n",
    "margen_error = z_score * altura_muestra.std() / np.sqrt(len(altura_muestra))\n",
    "intervalo_confianza = (altura_muestra.mean() - margen_error, altura_muestra.mean() + margen_error)\n",
    "\n",
    "print(\"Intervalo de Confianza: [{0:.2f}, {1:.2f}]\".format(intervalo_confianza[0], intervalo_confianza[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa1beb6",
   "metadata": {},
   "source": [
    "### Tamaño de la muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc84e4d",
   "metadata": {},
   "source": [
    "La [fórmula de Cochran](https://en.wikipedia.org/wiki/Sample_size_determination) es una fórmula utilizada para calcular el tamaño de muestra necesario en una encuesta o estudio de investigación cuando se trabaja con poblaciones finitas. Su objetivo es asegurar que la muestra sea lo suficientemente grande para proporcionar estimaciones precisas y confiables de una característica de la población, como una proporción o una media. La *fórmula de Cochran* se utiliza en situaciones en las que se conoce el tamaño de la población y se desea tomar una muestra representativa de esa población.\n",
    "\n",
    "La *fórmula de Cochran* se expresa de la siguiente manera:\n",
    "\n",
    "$$n = \\frac{N \\cdot Z^2 \\cdot p \\cdot (1-p)}{N \\cdot E^2 + Z^2 \\cdot p \\cdot (1-p)}$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $n$ es el tamaño de la muestra necesario.\n",
    "- $N$ es el tamaño de la población.\n",
    "- $Z$ es el valor crítico correspondiente al nivel de confianza deseado. Este valor se obtiene de una tabla de distribución de probabilidad (por ejemplo, la tabla $Z$) y depende del nivel de confianza seleccionado.\n",
    "- $p$ es la estimación de la proporción de la población que se espera que tenga una cierta característica. Esta estimación puede basarse en datos previos o suposiciones.\n",
    "- $E$ es el margen de error deseado, que representa la máxima diferencia permitida entre la estimación de la muestra y la verdadera característica de la población.\n",
    "\n",
    "La *fórmula de Cochran* se utiliza para calcular el tamaño de muestra necesario de manera que el margen de error sea consistente con el nivel de confianza deseado y la variabilidad esperada en la población (representada por \n",
    "$p\\cdot(1−p)$). Es importante notar que esta fórmula se aplica principalmente en situaciones en las que la población es relativamente pequeña en comparación con el tamaño de la muestra, es decir, cuando se trabaja con poblaciones finitas.\n",
    "\n",
    "Para utilizar la fórmula de Cochran en un estudio específico, debes conocer el tamaño de la población ($N$), el nivel de confianza deseado, la estimación de la proporción ($p$), y el margen de error tolerable ($E$). Con estos valores, puedes calcular el tamaño de muestra necesario ($n$) para obtener resultados confiables en tu investigación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calcular_tamano_muestra(N, p, E, nivel_confianza):\n",
    "    # Calcular el valor crítico Z para el nivel de confianza deseado\n",
    "    valor_critico = stats.norm.ppf((1 + nivel_confianza) / 2)\n",
    "   \n",
    "    # Calcular el tamaño de la muestra\n",
    "    numerador = N * valor_critico**2 * p * (1 - p)\n",
    "    denominador = N * E**2 + valor_critico**2 * p * (1 - p)\n",
    "    \n",
    "    tamanio_muestra = numerador / denominador\n",
    "    \n",
    "    return math.ceil(tamanio_muestra)  # Redondear hacia arriba a un número entero\n",
    "\n",
    "# Ejemplo de uso\n",
    "N = 15000000          # Tamaño de la población\n",
    "p = 0.5                 # Estimación de la proporción\n",
    "E = 0.05                # Margen de error deseado (5%)\n",
    "nivel_confianza = 0.95  # Nivel de confianza del 95%\n",
    "\n",
    "tamanio_muestra = calcular_tamano_muestra(N, p, E, nivel_confianza)\n",
    "print(f\"El tamaño de muestra necesario es: {tamanio_muestra}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85514c",
   "metadata": {},
   "source": [
    "## Validación estadística de conjeturas empresariales (Pruebas de hipótesis paramétricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43767eff",
   "metadata": {},
   "source": [
    "### Definición de Pruebas de Hipótesis Paramétricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e725198",
   "metadata": {},
   "source": [
    "Las [pruebas de hipótesis](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing) son una parte esencial de la [inferencia estadística](https://en.wikipedia.org/wiki/Statistical_inference). Se utilizan para tomar decisiones basadas en datos observados y evaluar si los resultados son consistentes con una afirmación específica. En el contexto empresarial, estas pruebas nos permiten validar conjeturas y tomar decisiones informadas.\n",
    "\n",
    "Las pruebas estadísticas de hipótesis se basan en una declaración llamada [hipótesis nula, $H0$](https://en.wikipedia.org/wiki/Null_hypothesis), que asume que no ocurre nada interesante entre las variables que se están probando. La forma exacta de la hipótesis nula varía según el tipo de prueba que se esté realizando; por ejemplo, si se está probando si los grupos difieren, la hipótesis nula afirma que los grupos son iguales. El propósito de una prueba de hipótesis es determinar si la hipótesis nula es probablemente cierta dado los datos de la muestra. Si hay poca evidencia en contra de la hipótesis nula, se acepta; si es improbable dado los datos, se podría rechazar en favor de la [hipótesis alternativa, $H1$](https://en.wikipedia.org/wiki/Alternative_hypothesis). El [nivel de significancia,  $\\alpha$](https://en.wikipedia.org/wiki/Statistical_significance), se elige para determinar cuándo rechazar la *hipótesis nula*, y el [valor $p$](https://en.wikipedia.org/wiki/P-value) se utiliza para medir la probabilidad de obtener un resultado tan extremo o más extremo que el observado debido al azar. El $t-test$ es una prueba estadística utilizada para determinar si una muestra de datos numéricos difiere significativamente de la población o si dos muestras difieren entre sí."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8b49e",
   "metadata": {},
   "source": [
    "### Conceptos Clave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcedbbf3",
   "metadata": {},
   "source": [
    "- ***Hipótesis Nula ($H0$):*** Es una afirmación que asumimos como verdadera inicialmente. Se representa como \"$H0$\" y generalmente sostiene que no hay diferencia o efecto.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Hipótesis Alternativa ($H1$):*** Es la afirmación opuesta a la hipótesis nula. Representada como \"$H1$\", suele afirmar que hay una diferencia o efecto significativo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Nivel de Significancia ($\\alpha$):*** Es la probabilidad máxima que estamos dispuestos a aceptar para cometer un error de tipo $I$ (rechazar incorrectamente $H0$). Usualmente, se elige un valor como $0.05$ o $0.01$.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Estadístico de Prueba:*** Es una medida calculada a partir de los datos que se utiliza para tomar una decisión sobre si rechazar o no la *hipótesis nula*.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Región Crítica:*** Es el rango de valores del estadístico de prueba que conduciría al rechazo de la *hipótesis nula*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28890131",
   "metadata": {},
   "source": [
    "### Cómo funciona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5131662c",
   "metadata": {},
   "source": [
    "#### Hipótesis Nula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51524b9e",
   "metadata": {},
   "source": [
    "Establecemos dos hipótesis, $H0$ (hipótesis nula) y $H1$ (hipótesis alternativa).\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/HypothesisTesting.PNG?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "Podemos tomar cuatro decisiones diferentes con la prueba de hipótesis:\n",
    "\n",
    "- Rechazar $H0$ y $H0$ no es verdadero (*sin error*)\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- No rechace $H0$ y $H0$ es verdadera (*sin error*)\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Rechace $H0$ y $H0$ es verdadero (*Error tipo $I$*)\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- No rechace $H0$ y $H0$ no es verdadera (*error tipo $II$*)\n",
    "\n",
    "El *error tipo $I$* también se denomina *error $\\alpha$*. El *error de tipo $II$* también se denomina *error $\\beta$*.\n",
    "\n",
    "|            | Decisión                       |                                |\n",
    "|:----------:|:------------------------------:|:------------------------------:|\n",
    "|            | ***Aceptar $H0$***             | ***Rechazar $H0$***            |\n",
    "|$H0$ (True) | Decisión correcta              | Error Tipo $I$ (error $\\alpha$)|\n",
    "|$H0$ (False)| Error Tipo $II$ (error $\\beta$)| Decisión correcta              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2a52b0",
   "metadata": {},
   "source": [
    "####  Valor p (p-value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996b1803",
   "metadata": {},
   "source": [
    "El valor $p$ es la probabilidad de encontrar resultados iguales o más extremos cuando la *hipótesis nula* ($H0$) es verdadera. En otras palabras, un valor $p$ bajo significa que tenemos evidencia sólida para rechazar la *hipótesis nula*.\n",
    "\n",
    "Si el valor $p$ es menor que el $5\\%$ ($p < 0.05$), a menudo *rechazamos* $H0$ y aceptamos que $H1$ es verdadera. Decimos que $p < 0.05$ es estadísticamente significativo, porque hay menos del $5\\%$ de probabilidad de que estemos equivocados al rechazar la *hipótesis nula*.\n",
    "\n",
    "Una forma de calcular el valor $p$ es mediante una prueba $t$. Podemos utilizar la función [`ttest_ind`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) de `Scipy` para calcular la prueba $t$ de las medias de dos muestras independientes de puntajes. En este ejemplo, calculamos la estadística $t$ y el valor $p$ de dos muestras aleatorias $10$ veces.\n",
    "\n",
    "Observamos que el valor $p$ a veces es muy bajo, pero esto no significa necesariamente que estas dos muestras aleatorias estén correlacionadas. Por eso, es importante tener cuidado al depender demasiado de los valores $p$. Si se repite un experimento varias veces, es posible caer en la ilusión de que hay correlación cuando en realidad solo hay aleatoriedad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0481db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-test and compute p value of two random samples\n",
    "print('T-statistics and p-values of two random samples.')\n",
    "for _ in range(10):\n",
    "    rand_sample1 = np.random.random_sample(10)\n",
    "    rand_sample2 = np.random.random_sample(10)\n",
    "    print(stats.ttest_ind(rand_sample1, rand_sample2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ee367",
   "metadata": {},
   "source": [
    "### Indicadores y Técnicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5472351",
   "metadata": {},
   "source": [
    "En esta sección, exploraremos algunas de las pruebas de hipótesis paramétricas más comunes y cómo aplicarlas en situaciones empresariales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6617d36c",
   "metadata": {},
   "source": [
    "#### Prueba t de Student"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af3ced",
   "metadata": {},
   "source": [
    "##### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa889cd6",
   "metadata": {},
   "source": [
    "La prueba [*$t$ de Student*](https://en.wikipedia.org/wiki/Student%27s_t-distribution) es una técnica estadística que se utiliza para comparar las medias de dos grupos independientes y determinar si las diferencias observadas entre las muestras son estadísticamente significativas o simplemente se deben a la variabilidad aleatoria. Fue desarrollada por *William Sealy Gosset* y se utiliza ampliamente en la investigación y en el análisis de datos en diversas áreas, incluyendo negocios, ciencias sociales y ciencias naturales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60957f41",
   "metadata": {},
   "source": [
    "##### Cuándo Emplear la Prueba t de Student"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6833c",
   "metadata": {},
   "source": [
    "La prueba [*$t$ de Student*](https://en.wikipedia.org/wiki/Student%27s_t-distribution) es apropiada cuando se cumplen ciertas condiciones y supuestos, que son los siguientes:\n",
    "\n",
    "- ***Independencia de las Muestras:*** Las muestras que se están comparando deben ser independientes entre sí. Esto significa que las observaciones en un grupo no deben estar relacionadas o influenciarse por las observaciones en el otro grupo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Distribución Normal:*** Cada grupo debe seguir una distribución normal (gaussiana). Sin embargo, para muestras grandes (generalmente $n > 30$), la prueba *t de Student* puede ser robusta ante pequeñas desviaciones de la normalidad debido al [*Teorema del Límite Central*](https://en.wikipedia.org/wiki/Central_limit_theorem).\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Homogeneidad de Varianza:*** Los grupos deben tener varianzas similares. Si las varianzas son significativamente diferentes, se deben considerar pruebas alternativas como la prueba [*$t$ de Welch*](https://en.wikipedia.org/wiki/Welch%27s_t-test)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbef592",
   "metadata": {},
   "source": [
    "##### Proceso de Realización de la Prueba t de Student"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda75deb",
   "metadata": {},
   "source": [
    "- ***Formulación de Hipótesis:***\n",
    "\n",
    "  - ***Hipótesis Nula (H0):*** Las medias de los dos grupos son iguales.\n",
    "  - ***Hipótesis Alternativa (H1):*** Las medias de los dos grupos son diferentes.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cálculo del Estadístico de Prueba:*** Calculamos el valor $t$ utilizando la fórmula: \n",
    "\n",
    "$$t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sigma_{pooled} \\times \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}$$\n",
    "\n",
    "\n",
    "  donde $\\bar{x}_1$ y $\\bar{x}_2$ son las medias de los dos grupos, $n_1$ y $n_2$ son los tamaños de las muestras y $\\sigma_{pooled}$ es la estimación de la desviación estándar combinada.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Grados de Libertad:*** Los grados de libertad se calculan como $dof = n_1 + n_2 - 2$.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cálculo del Valor $p$:*** Utilizamos los grados de libertad y el estadístico $t$ para calcular el valor $p$ asociado. El valor $p$ representa la probabilidad de obtener un estadístico de prueba tan extremo o más extremo que el observado, asumiendo que la hipótesis nula es verdadera.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Toma de Decisiones:*** Comparamos el valor $p$ con el nivel de significancia ($\\alpha$) predefinido. Si el valor $p < \\alpha$, rechazamos la hipótesis nula y concluimos que hay diferencias significativas entre las medias de los grupos. Si el valor $p > \\alpha$, no tenemos suficiente evidencia para rechazar la hipótesis nula.\n",
    "\n",
    "\n",
    "***Ejemplo:***\n",
    "\n",
    "Supongamos que una empresa de telecomunicaciones desea determinar si hay una diferencia significativa en la satisfacción del cliente entre dos planes de servicio, $A$ y $B$. Han recopilado muestras aleatorias de $30$ clientes para cada plan y han medido su satisfacción en una escala del $1$ al $10$.\n",
    "\n",
    "Para resolverlo, se usará la función [`ttest_ind`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) de la biblioteca `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a466e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Generar datos de ejemplo\n",
    "np.random.seed(42)\n",
    "plan_a = np.random.randint(5, 10, 30)\n",
    "plan_b = np.random.randint(6, 11, 30)\n",
    "\n",
    "plana_mean = plan_a.mean()\n",
    "print('media plan A: ', plana_mean)\n",
    "planb_mean = plan_b.mean()\n",
    "print('media plan B: ', planb_mean)\n",
    "\n",
    "# Prueba t de Student\n",
    "t_stat, p_valor = ttest_ind(plan_a, plan_b)\n",
    "\n",
    "print(\"Estadístico t:\", t_stat)\n",
    "print(\"Valor p:\", p_valor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25002328",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plan_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15345b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plan_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf506ac",
   "metadata": {},
   "source": [
    "En este ejemplo, el valor del estadístico $t=-1.9476$. Este valor representa la magnitud de la diferencia entre las medias de los dos grupos (plan $A$ y plan $B$) en términos de desviaciones estándar combinadas. Un valor negativo indica que la media del plan $B$ es mayor que la del plan $A$ en esta muestra específica.\n",
    "\n",
    "El valor $p$ es una medida de la evidencia en contra de la hipótesis nula. Cuanto menor sea el valor $p$, más evidencia tendremos para rechazar la hipótesis nula. El valor $p = 0.0563$ está ligeramente por encima del nivel de significancia común ($\\alpha = 0.05$). Esto significa que no tenemos evidencia suficiente para rechazar la hipótesis nula en este nivel de significancia. Sin embargo, es importante tener en cuenta que existe una tendencia hacia una diferencia en las medias.\n",
    "\n",
    "Basándonos en los resultados obtenidos, no podemos afirmar con confianza que hay una diferencia significativa en la satisfacción del cliente entre los planes $A$ y $B$. Sin embargo, debido a la proximidad del valor $p$ al nivel de significancia, podríamos considerar realizar más investigaciones o recolectar más datos para obtener una conclusión más sólida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f331067d",
   "metadata": {},
   "source": [
    "Recuerda que las pruebas estadísticas son herramientas que proporcionan evidencia, pero las conclusiones deben tomarse con precaución y en contexto. En este caso, podríamos considerar ajustar el tamaño de la muestra, explorar más sobre la distribución de los datos o utilizar otros enfoques si es necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef0d6f0",
   "metadata": {},
   "source": [
    "#### ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c4cce",
   "metadata": {},
   "source": [
    "##### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec1763a",
   "metadata": {},
   "source": [
    "La [Prueba de Análisis de Varianza (ANOVA)](https://en.wikipedia.org/wiki/Analysis_of_variance) es una técnica estadística utilizada para comparar las medias de tres o más grupos independientes y determinar si al menos uno de esos grupos difiere significativamente de los demás. La *ANOVA* se basa en la idea de descomponer la variación total en los datos en dos componentes: la *variación entre grupos* y la *variación dentro de los grupos*. Esta descomposición permite evaluar si las diferencias observadas entre los grupos son significativas o simplemente se deben a la variabilidad aleatoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab57182",
   "metadata": {},
   "source": [
    "##### Cuándo emplear ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d071ca47",
   "metadata": {},
   "source": [
    "La Prueba de *ANOVA* es apropiada en las siguientes situaciones:\n",
    "\n",
    "- ***Tres o Más Grupos:*** Se utiliza cuando se comparan tres o más grupos independientes. Si solo se están comparando dos grupos, la prueba *t de Student* es más adecuada.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Independencia de las Muestras:*** Los datos de cada grupo deben ser independientes entre sí, y no debe haber relación ni influencia entre los grupos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Distribución Normal:*** Cada grupo debe seguir una distribución normal. Al igual que en la prueba *t*, para tamaños de muestra grandes, el *ANOVA* puede ser robusto ante pequeñas desviaciones de la normalidad debido al *Teorema del Límite Central*.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Homogeneidad de Varianza:*** Los grupos deben tener varianzas aproximadamente iguales. Si las varianzas son significativamente diferentes, podría ser más adecuado utilizar un *ANOVA* con corrección para varianzas desiguales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19032409",
   "metadata": {},
   "source": [
    "##### Proceso de Realización de la Prueba de ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f78e4",
   "metadata": {},
   "source": [
    "A continuación, se presenta un proceso general para llevar a cabo una prueba de ANOVA:\n",
    "\n",
    "- ***Formulación de Hipótesis:***\n",
    "\n",
    "  - ***Hipótesis Nula (H0):*** Las medias de todos los grupos son iguales.\n",
    "  - ***Hipótesis Alternativa (H1):*** Al menos una de las medias de los grupos es diferente.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cálculo de la Variación Total:*** Se calcula la suma total de cuadrados ($SST$) para medir la variación total en los datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cálculo de la Variación Entre Grupos:*** Se calcula la suma de cuadrados entre grupos ($SSG$) para medir la variación entre las medias de los grupos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cálculo de la Variación Dentro de los Grupos:*** Se calcula la suma de cuadrados dentro de los grupos ($SSE$) para medir la variación dentro de cada grupo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cálculo del Estadístico $F$:*** Se calcula el [estadístico $F$](https://en.wikipedia.org/wiki/F-test) utilizando la relación $F = {SSG \\over (k-1)} \\bigl/ {SSE \\over (N-k)}$, donde $k$ es el número de grupos y $N$ es el tamaño total de la muestra.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cálculo del Valor $p$:*** Utilizamos los grados de libertad y el estadístico $F$ para calcular el valor $p$ asociado. Si el valor $p$ es menor que el nivel de significancia ($\\alpha$), rechazamos la hipótesis nula.\n",
    "\n",
    "***Ejemplo:***\n",
    "\n",
    "Supongamos que una empresa de alimentos ha desarrollado tres formulaciones diferentes de un producto y quiere determinar si existe una diferencia significativa en la satisfacción del cliente. Han recopilado muestras aleatorias de $50$ clientes para cada formulación y han medido su satisfacción en una escala del $1$ al $10$. Para el cálculo se empleará la función [`stats.f_oneway`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html#scipy-stats-f-oneway) de `scipy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Generar datos de ejemplo\n",
    "np.random.seed(42)\n",
    "formulacion_1 = np.random.randint(5, 10, 50)\n",
    "formulacion_2 = np.random.randint(6, 11, 50)\n",
    "formulacion_3 = np.random.randint(6, 9, 50)\n",
    "\n",
    "# Prueba de ANOVA\n",
    "f_stat, p_valor = f_oneway(formulacion_1, formulacion_2, formulacion_3)\n",
    "\n",
    "print(\"Estadístico F:\", f_stat)\n",
    "print(\"Valor p:\", p_valor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a937a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(formulacion_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f45ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(formulacion_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c9adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(formulacion_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d404000e",
   "metadata": {},
   "source": [
    "En el ejemplo proporcionado y los resultados de la prueba *ANOVA*, la interpretación de estos resultados se basa en la comparación del valor $p$ con un nivel de significancia ($\\alpha$) predefinido (como $0.05$).\n",
    "\n",
    "***Interpretación:***\n",
    "\n",
    "- ***Estadístico F:*** El valor del estadístico $F = 6.2834$. Este valor indica la proporción de la variación entre grupos con respecto a la variación dentro de los grupos. Un valor $F$ mayor sugiere una mayor variación entre grupos en relación con la variación dentro de los grupos.\n",
    "\n",
    "- ***Valor p:*** El valor $p = 0.0024$. El valor $p$ representa la probabilidad de obtener un estadístico de prueba $F$ tan extremo o más extremo que el observado, asumiendo que la hipótesis nula de igualdad de medias es verdadera.\n",
    "\n",
    "***Toma de Decisión:***\n",
    "\n",
    "Para tomar una decisión basada en los resultados de la prueba *ANOVA*, comparamos el valor $p$ con el nivel de significancia $\\alpha$. Si $p < \\alpha (0.05)$ en muchos casos, rechazamos la hipótesis nula y concluimos que al menos uno de los grupos tiene una media significativamente diferente de los demás. Si el valor $p > \\alpha$, no tenemos suficiente evidencia para rechazar la hipótesis nula.\n",
    "\n",
    "En este caso, el valor $p =0.0024$ es considerablemente menor que el nivel de significancia $\\alpha =0.05$. Por lo tanto, podemos concluir que hay suficiente evidencia para rechazar la hipótesis nula y afirmar que al menos un grupo tiene una media significativamente diferente de los demás. En otras palabras, existe una diferencia significativa en la satisfacción del cliente entre al menos dos de las formulaciones de productos evaluadas.\n",
    "\n",
    "***Conclusiones:***\n",
    "\n",
    "- Basándonos en los resultados de la prueba *ANOVA*, podemos concluir que existe una diferencia significativa en la satisfacción del cliente entre al menos dos de las formulaciones de productos. Este hallazgo puede ser útil para tomar decisiones empresariales informadas, como optimizar la producción o ajustar las estrategias de marketing para las formulaciones específicas que presentan diferencias significativas en la satisfacción del cliente.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- En el contexto del ejemplo de la *ANOVA* donde el estadístico $F$ es $6.2834$ y el valor $p$ es $0.0024$ (ambos indicativos de una diferencia significativa entre al menos dos grupos), es posible afirmar que existe una diferencia en las medias de satisfacción del cliente entre los tres grupos evaluados. Sin embargo, la prueba *ANOVA* en sí no proporciona información directa sobre cuál grupo específico tiene una mayor o menor satisfacción.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Cuando se obtiene una diferencia significativa en la *ANOVA*, es común realizar pruebas de comparaciones múltiples, también conocidas como [pruebas post hoc](https://en.wikipedia.org/wiki/Testing_hypotheses_suggested_by_the_data), para determinar qué grupos difieren entre sí. Algunas de las *pruebas post hoc* comunes son la [prueba de Tukey](https://en.wikipedia.org/wiki/Tukey%27s_range_test), la [prueba de Bonferroni](https://en.wikipedia.org/wiki/Bonferroni_correction), la [prueba de Scheffe](https://en.wikipedia.org/wiki/Scheff%C3%A9%27s_method) y otras.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Estas pruebas evalúan todas las combinaciones posibles de grupos para identificar cuáles de ellos tienen diferencias significativas en términos de sus medias. Estas comparaciones ayudarán a identificar cuál grupo tiene una mayor satisfacción en relación con otros grupos específicos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- En resumen, después de obtener una diferencia significativa en la *ANOVA*, el análisis no concluye directamente cuál grupo es el mejor o el peor. Las *pruebas post hoc* son necesarias para desentrañar las diferencias específicas entre los grupos. Estas pruebas adicionales permitirán una toma de decisiones más informada sobre qué grupos presentan diferencias significativas en términos de satisfacción del cliente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6140dae",
   "metadata": {},
   "source": [
    "## Pruebas de hipótesis no paramétricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf27d8",
   "metadata": {},
   "source": [
    "### Definición de pruebas de hipótesis no paramétricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca183bba",
   "metadata": {},
   "source": [
    "Las pruebas de hipótesis son herramientas estadísticas que nos permiten evaluar la validez de afirmaciones sobre poblaciones o datos en base a la evidencia de una muestra. Cuando se trata de datos que no cumplen los supuestos de normalidad u otras condiciones necesarias para los métodos paramétricos, las [pruebas de hipótesis no paramétricas](https://en.wikipedia.org/wiki/Nonparametric_statistics) son una alternativa valiosa.\n",
    "\n",
    "Las pruebas de hipótesis no paramétricas no hacen supuestos sobre la distribución subyacente de los datos, lo que las hace flexibles y aplicables a una amplia gama de situaciones. Estas pruebas se basan en rangos, medianas, diferencias entre medianas y otras estadísticas robustas para tomar decisiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73850eb8",
   "metadata": {},
   "source": [
    "### Uso y selección de pruebas no paramétricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fa9a64",
   "metadata": {},
   "source": [
    "A medida que exploramos el mundo de las pruebas de hipótesis no paramétricas, es fundamental comprender cuándo es apropiado utilizar cada una de ellas. La elección de la prueba correcta depende del tipo de datos y el objetivo del análisis. A continuación, se detallan algunas situaciones comunes en las que las pruebas no paramétricas son especialmente útiles:\n",
    "\n",
    "- ***Datos no normales:*** Cuando los datos no siguen una distribución normal, las pruebas no paramétricas son la elección preferida. Esto es común en muchas situaciones empresariales, ya que los datos pueden ser influenciados por diversos factores que desvían su distribución de la normalidad.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Pequeñas muestras:*** Las pruebas no paramétricas pueden proporcionar resultados más confiables en situaciones de muestras pequeñas, ya que son menos sensibles a la variabilidad y a los valores atípicos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Datos ordinales o categóricos:*** Si trabajas con datos que solo pueden ser ordenados o categorizados, las pruebas no paramétricas son una opción natural, ya que los métodos paramétricos generalmente requieren datos continuos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Comparaciones de medianas:*** Si estás interesado en comparar medianas o medidas de tendencia central robustas, las pruebas no paramétricas son una excelente elección."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d053b0f",
   "metadata": {},
   "source": [
    "### Ventajas de las pruebas no paramétricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2843f4",
   "metadata": {},
   "source": [
    " - ***Menos supuestos:*** No se requiere asumir una distribución específica de los datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Robustez:*** Las pruebas son menos sensibles a valores atípicos y desviaciones de la normalidad.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Amplia aplicabilidad:*** Pueden ser utilizadas con datos ordinales, nominales o intervalares, y no están limitadas a datos normales.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Pequeñas muestras:*** A menudo son útiles cuando la cantidad de datos es limitada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16977446",
   "metadata": {},
   "source": [
    "### Limitaciones de las pruebas no paramétricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87d385",
   "metadata": {},
   "source": [
    "Si bien las pruebas no paramétricas son valiosas en muchas situaciones, también tienen limitaciones que deben ser consideradas:\n",
    "\n",
    "- ***Menos potencia:*** En comparación con las pruebas paramétricas, las pruebas no paramétricas pueden tener menor capacidad para detectar diferencias sutiles en los datos. Esto puede ser especialmente relevante en muestras grandes.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Sensibilidad a la estructura de los datos:*** Algunas pruebas no paramétricas pueden ser sensibles a la estructura específica de los datos, lo que puede afectar sus resultados.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Mayor complejidad en la interpretación:*** En ocasiones, interpretar los resultados de las pruebas no paramétricas puede ser más desafiante debido a las diferencias en los supuestos y en las estadísticas utilizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b9d4d",
   "metadata": {},
   "source": [
    "### Ejemplos de pruebas de hipótesis no paramétricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67821bfb",
   "metadata": {},
   "source": [
    "#### Prueba Kolmogorov-Smirnov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d140bd",
   "metadata": {},
   "source": [
    "La prueba de [Kolmogorov-Smirnov](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test) (*KS*) es una prueba no paramétrica utilizada para evaluar si un conjunto de datos sigue una distribución de probabilidad específica, como una distribución normal o cualquier otra. Esta prueba es especialmente útil cuando se desea verificar si los datos provienen de una distribución teórica sin hacer suposiciones sobre los parámetros de esa distribución.\n",
    "\n",
    "El estadístico de prueba de *Kolmogorov-Smirnov* ($D$) se calcula utilizando la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "D = \\max \\left[ \\max_{1 \\leq i \\leq n} \\left( \\frac{i}{n} - F(X_{(i)}) \\right), \\max_{1 \\leq i \\leq n} \\left( F(X_{(i)}) - \\frac{i-1}{n} \\right) \\right]\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $D$ es el estadístico de Kolmogorov-Smirnov.\n",
    "- $n$ es el tamaño de la muestra.\n",
    "- $F(X_{(i)})$ es la *función de distribución acumulativa* (*CDF*) empírica en el $i$-ésimo valor ordenado.\n",
    "\n",
    "***Usos***\n",
    "- Verificar si un conjunto de datos sigue una distribución teórica, como una distribución normal o exponencial.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Comparar dos muestras para evaluar si provienen de la misma distribución.\n",
    "\n",
    "***Limitaciones***\n",
    "- La prueba de *KS* puede ser sensible al tamaño de la muestra, lo que significa que en muestras grandes, pequeñas desviaciones de la distribución teórica pueden llevar al rechazo de la hipótesis nula.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- La prueba de *KS* es adecuada principalmente para distribuciones continuas y puede no ser tan eficaz para datos discretos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- La prueba no proporciona información sobre los parámetros específicos de la distribución teórica.\n",
    "\n",
    "***Interpretación de Resultados***\n",
    "\n",
    "La prueba de *KS* compara el estadístico $D$ calculado con un valor crítico obtenido de tablas o mediante métodos computacionales. La idea central es que si los datos se ajustan bien a la distribución teórica especificada, el estadístico $D$ debería ser pequeño y no significativamente diferente del valor crítico. Por otro lado, si los datos difieren significativamente de la distribución teórica, el estadístico $D$ será grande y superará el valor crítico.\n",
    "\n",
    "La prueba de *KS* se utiliza para verificar dos hipótesis:\n",
    "\n",
    "1. ***Hipótesis Nula ($H_0$):*** Los datos siguen la distribución teórica especificada.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "2. ***Hipótesis Alternativa ($H_1$):*** Los datos no siguen la distribución teórica especificada.\n",
    "\n",
    "Si el valor calculado del estadístico $D$ es menor o igual al valor crítico para un nivel de significancia dado, no se rechaza la hipótesis nula, lo que sugiere que los datos pueden seguir la distribución teórica. En cambio, si el valor calculado de $D$ es mayor que el valor crítico, se rechaza la hipótesis nula, indicando que los datos difieren significativamente de la distribución teórica.\n",
    "\n",
    "En resumen, la prueba de *Kolmogorov-Smirnov* es una herramienta útil para evaluar si los datos siguen una distribución teórica específica. Su capacidad para detectar desviaciones de la distribución depende del tamaño de la muestra y del nivel de significancia elegido.\n",
    "\n",
    "Se usará la función [`kstest`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kstest.html#scipy.stats.kstest) de `scpy` para su cálculo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd004dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest, expon\n",
    "\n",
    "# Generar datos aleatorios a partir de una distribución exponencial\n",
    "np.random.seed(0)\n",
    "data = np.random.exponential(scale=1, size=100)\n",
    "\n",
    "# Realizar la prueba de Kolmogorov-Smirnov\n",
    "statistic, p_value = kstest(data, 'expon')\n",
    "\n",
    "# Definir la distribución exponencial teórica para comparación\n",
    "x = np.linspace(0, data.max(), 100)\n",
    "pdf = expon.pdf(x, scale=1)\n",
    "\n",
    "# Gráfica de los datos y la distribución exponencial teórica\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(data, bins=10, density=True, alpha=0.6, color='b', label='Histograma')\n",
    "plt.plot(x, pdf, 'r-', lw=2, label='PDF Exponencial Teórica')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(f'Prueba de Kolmogorov-Smirnov: Estadístico={statistic:.4f}, p-valor={p_value:.4f}')\n",
    "plt.show()\n",
    "\n",
    "if p_value > 0.05:\n",
    "    print(\"Los datos siguen una distribución exponencial (no se rechaza H0)\")\n",
    "else:\n",
    "    print(\"Los datos no siguen una distribución exponencial (se rechaza H0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bde0e2",
   "metadata": {},
   "source": [
    "#### Prueba de Wilcoxon (Mann-Whitney U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10128af",
   "metadata": {},
   "source": [
    "La Prueba de Wilcoxon, también conocida como la [prueba Mann-Whitney U](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test), es una prueba no paramétrica utilizada para comparar las distribuciones de dos muestras independientes y determinar si provienen de la misma población. Esta prueba se basa en la comparación de los rangos de las observaciones entre los dos grupos. La hipótesis nula es que no hay diferencia entre las medianas de las dos poblaciones, mientras que la hipótesis alternativa afirma que existe una diferencia significativa. La prueba calcula un valor $U$ y un valor $p$, donde un valor $p$ bajo sugiere evidencia de una diferencia significativa entre las muestras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb23155",
   "metadata": {},
   "source": [
    "Como ejemplo, supongamos que tienes datos de dos grupos y deseas saber si hay una diferencia significativa en las medianas de ambos grupos.\n",
    "\n",
    "- ***Datos:***\n",
    "  - ***Grupo A:*** Alturas de 30 empleados en una empresa.\n",
    "  - ***Grupo B:*** Alturas de 25 empleados en otra empresa.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Objetivo:*** Determinar si hay una diferencia significativa en las alturas promedio entre los dos grupos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Análisis:*** Aplicamos la Prueba de Wilcoxon (Mann-Whitney U) para comparar las dos muestras:\n",
    "\n",
    "Usaremos la función [`mannwhitneyu`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html#scipy-stats-mannwhitneyu) de `scipy` para determinar su valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47158bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "grupo_a = np.random.normal(170, 5, 30)\n",
    "grupo_b = np.random.normal(175, 5, 25)\n",
    "\n",
    "statistic, p_value = mannwhitneyu(grupo_a, grupo_b)\n",
    "print(\"statistic: \", statistic)\n",
    "print(\"p_value: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf55ff3",
   "metadata": {},
   "source": [
    "- ***Resultado y Conclusión:*** El valor $p$ obtenido es significativo ($p < 0.05$), lo que sugiere que hay una diferencia significativa en las alturas promedio entre los dos grupos. Por lo tanto, podemos concluir que existe evidencia suficiente para afirmar que las alturas de los empleados son diferentes entre las dos empresas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad07ebcc",
   "metadata": {},
   "source": [
    "#### Prueba de Kruskal-Wallis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30843fee",
   "metadata": {},
   "source": [
    "Si tienes más de dos grupos y deseas evaluar si al menos uno de los grupos tiene una distribución diferente, puedes usar la [prueba de Kruskal-Wallis](https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance). La Prueba de *Kruskal-Wallis* es una prueba no paramétrica utilizada para comparar las medianas de tres o más muestras independientes. Esta prueba generaliza la *Prueba de Wilcoxon* para dos muestras a más de dos grupos. Se basa en la comparación de los rangos de las observaciones en todos los grupos y busca determinar si hay diferencias significativas entre las distribuciones de las poblaciones subyacentes. Al igual que en otras pruebas no paramétricas, la hipótesis nula es que no hay diferencias significativas entre las medianas de los grupos y la hipótesis alternativa afirma lo contrario. El resultado de la prueba es un valor estadístico y un valor $p$, donde un valor $p$ bajo sugiere evidencia de diferencias significativas entre los grupos.\n",
    "\n",
    "Veamos el siguiente ejemplo:\n",
    "\n",
    "- ***Datos:*** Tres grupos de empleados en diferentes departamentos con respecto a sus salarios.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Objetivo:*** Evaluar si hay una diferencia significativa en los salarios promedio entre los tres departamentos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Análisis:*** Aplicamos la Prueba de [`Kruskal-Wallis`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kruskal.html#scipy.stats.kruskal) de `scipy` para comparar los tres grupos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b055ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "departamento_1 = np.random.normal(50000, 3000, 40)\n",
    "departamento_2 = np.random.normal(55000, 4000, 35)\n",
    "departamento_3 = np.random.normal(52000, 3500, 45)\n",
    "\n",
    "statistic, p_value = kruskal(departamento_1, departamento_2, departamento_3)\n",
    "print(\"statistic: \", statistic)\n",
    "print(\"p_value: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40bcc05",
   "metadata": {},
   "source": [
    "- ***Resultado y Conclusión:*** El valor $p$ obtenido es significativo ($p < 0.05$), lo que sugiere que hay una diferencia significativa en los salarios promedio entre al menos uno de los departamentos. Por lo tanto, podemos concluir que existe evidencia suficiente para afirmar que los salarios son diferentes entre al menos dos de los departamentos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77163112",
   "metadata": {},
   "source": [
    "#### Prueba de Wilcoxon para muestras relacionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f24a37",
   "metadata": {},
   "source": [
    "La [Prueba de Wilcoxon para muestras relacionadas](https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test), también conocida como la *Prueba de los Rangos con Signo de Wilcoxon*, es utilizada cuando se comparan mediciones repetidas de un mismo grupo bajo diferentes condiciones o momentos en el tiempo. Esta prueba se basa en la diferencia entre los pares de observaciones relacionadas y evalúa si estas diferencias provienen de una distribución simétrica alrededor de cero. La hipótesis nula afirma que no hay diferencia significativa entre las mediciones antes y después, mientras que la hipótesis alternativa sugiere que existe una diferencia. La prueba calcula un valor $W$ y un valor $p$, donde un valor $p$ bajo indica evidencia de una diferencia significativa entre las mediciones.\n",
    "\n",
    "Como ejemplo se tiene:\n",
    "\n",
    "- ***Datos:*** Mediciones de la satisfacción de los empleados antes y después de la implementación de un nuevo programa de bienestar.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Objetivo:*** Determinar si hay una diferencia significativa en la satisfacción de los empleados debido al nuevo programa.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Análisis:*** Aplicamos la Prueba de [`Wilcoxon`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html#scipy.stats.wilcoxon)  para muestras relacionadas de `scipy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e724bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "np.random.seed(4)\n",
    "\n",
    "antes = np.random.normal(75, 10, 25)\n",
    "despues = np.random.normal(80, 8, 25)\n",
    "\n",
    "statistic, p_value = wilcoxon(antes, despues)\n",
    "print(\"statistic: \", statistic)\n",
    "print(\"p_value: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c0066",
   "metadata": {},
   "source": [
    "- ***Resultado y Conclusión:*** El valor $p$ obtenido es significativo ($p < 0.05$), lo que sugiere que hay una diferencia significativa en la satisfacción de los empleados antes y después de la implementación del nuevo programa. Por lo tanto, podemos concluir que existe evidencia suficiente para afirmar que el programa de bienestar ha tenido un impacto positivo en la satisfacción de los empleados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc63f347",
   "metadata": {},
   "source": [
    "### Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27573d1e",
   "metadata": {},
   "source": [
    "- Las pruebas de hipótesis no paramétricas son herramientas valiosas en la estadística cuando se trabaja con datos que no cumplen los supuestos de los métodos paramétricos. Son especialmente útiles en situaciones donde se tienen datos no normales, muestras pequeñas o datos ordinales. Sin embargo, es importante tener en cuenta sus limitaciones, como una menor potencia en comparación con las pruebas paramétricas. Al aplicar estas pruebas a situaciones empresariales reales, es crucial interpretar los resultados con cuidado y considerar el contexto específico de los datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Estas descripciones teóricas proporcionan una base para comprender el propósito y la lógica detrás de cada una de las pruebas no paramétricas mencionadas en los ejemplos. Es importante recordar que, al aplicar estas pruebas en situaciones reales, es necesario considerar las condiciones específicas de los datos y su contexto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6915f69",
   "metadata": {},
   "source": [
    "## Resumen del Capitulo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eacb0fe",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/HypothesisTest.PNG?raw=true\" width=\"700\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fdf7a9",
   "metadata": {},
   "source": [
    "# Ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de15c07f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert alert-info\">\n",
    "Ver ejemplo en el archivo <a href=\"./Ejemplos_C01_1_VentaSmartphone.ipynb\">Ejemplos_C01_1_VentaSmartphone</a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
