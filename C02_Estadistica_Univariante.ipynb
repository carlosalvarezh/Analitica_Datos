{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d9048b9",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Analítica de datos para la toma de decisiones empresariales</h1>\n",
    "<h1 align=\"center\">Estadística Univariante</h1>\n",
    "<h1 align=\"center\">Centro de Educación Continua</h1>\n",
    "<h1 align=\"center\">EAFIT</h1>\n",
    "<h1 align=\"center\">2023</h1>\n",
    "<h1 align=\"center\">MEDELLÍN - COLOMBIA </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd250d",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://github.com/carlosalvarezh/CFD_Applied/blob/master/figs/CC-BY.png?raw=true\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license.(c) Carlos Alberto Alvarez Henao</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3352bab9",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/C02_02_WordCloudStatistics.jpg?raw=true\" width=\"500\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f5d061",
   "metadata": {},
   "source": [
    "## Definiciones  y conceptos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e27708",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16491ad3",
   "metadata": {},
   "source": [
    "La capacidad de tomar decisiones informadas y estratégicas es esencial en el entorno empresarial actual, y la estadística desempeña un papel fundamental en este proceso. Exploraremos cómo la estadística univariante, en particular el análisis univariante, puede proporcionarnos información valiosa y confiable a partir de los datos, permitiéndonos tomar decisiones más efectivas y fundamentadas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01512dcb",
   "metadata": {},
   "source": [
    "### Qués la Estadística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc055d3",
   "metadata": {},
   "source": [
    "La [estadística](https://en.wikipedia.org/wiki/Statistics) es la ciencia que nos permite recopilar, organizar, analizar e interpretar [datos](https://en.wikipedia.org/wiki/Data) para tomar decisiones basadas en evidencia. Es un puente crucial entre la información cruda y el conocimiento accionable.\n",
    "\n",
    "Veamos el siguiente conjunto de datos:\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/C02_01_Tabla.PNG?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "Puede inferir algo de esta tabla?\n",
    "\n",
    "La estadística nos permitirá convertir esos datos \"inconexos\" en información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6d5140",
   "metadata": {},
   "source": [
    "### Ramas de la estadística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d51e21",
   "metadata": {},
   "source": [
    "La estadística suele ser dividida en dos grandes ramas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815b7d56",
   "metadata": {},
   "source": [
    "#### Estadística descriptiva "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ae5ada",
   "metadata": {},
   "source": [
    "La [estadística descriptiva](https://en.wikipedia.org/wiki/Descriptive_statistics) se centra en la recopilación, organización, resumen y presentación de datos de manera informativa. Su objetivo principal es describir las características esenciales de un conjunto de datos sin realizar inferencias o generalizaciones más allá de los datos en sí. Calcula los parámetros estadísticos que describen el conjunto estudiado. Algunos conceptos y técnicas asociadas con la estadística descriptiva incluyen:\n",
    "\n",
    "- ***Medidas de tendencia central:*** como la media, mediana y moda, que resumen la ubicación promedio de los datos.  \n",
    "<p>&nbsp;</p>\n",
    "- ***Medidas de dispersión:*** como la desviación estándar y el rango intercuartílico, que indican cuánto se dispersan los datos alrededor de las medidas de tendencia central.  \n",
    "<p>&nbsp;</p>\n",
    "- ***Gráficos y diagramas:*** como histogramas, gráficos de barras y gráficos de dispersión, que visualizan los patrones y la distribución de los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c33f80",
   "metadata": {},
   "source": [
    "#### Estadistica inferencial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7cc57f",
   "metadata": {},
   "source": [
    "La [estadística inferencial](https://en.wikipedia.org/wiki/Statistical_inference), también conocida como estadística diferencial, se refiere al proceso de hacer inferencias o conclusiones sobre una población basándose en los datos de una muestra seleccionada de esa población. Esta rama se utiliza para sacar conclusiones más allá de los datos observados y para tomar decisiones informadas sobre hipótesis y afirmaciones. Algunos conceptos y técnicas asociadas con la estadística inferencial incluyen:\n",
    "\n",
    "- ***Estimación de parámetros:*** Utiliza los datos de la muestra para estimar los parámetros poblacionales desconocidos, como la media o la proporción.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Pruebas de hipótesis:*** Evalúa si ciertas afirmaciones sobre la población son compatibles con los datos de la muestra o si deberían rechazarse en favor de otra afirmación.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Intervalos de confianza:*** Proporcionan un rango de valores dentro del cual se espera que se encuentre un parámetro poblacional con un cierto nivel de confianza.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Regresión y correlación:*** Modelan relaciones entre variables y permiten hacer predicciones y análisis de causalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8b994",
   "metadata": {},
   "source": [
    "### Probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5474ee",
   "metadata": {},
   "source": [
    "Mientras que, como se dijo, la estadística se enfoca en la recopilación, organización, análisis e interpretación de datos, la [probabilidad](https://en.wikipedia.org/wiki/Probability) es la medida cuantitativa de la incertidumbre. Se utiliza para cuantificar la posibilidad de que ocurra un evento específico. En esencia, la probabilidad es una forma de asignar un valor numérico a la chance de que un evento suceda, y estos valores generalmente se encuentran en el rango de 0 (evento imposible) a 1 (evento seguro). También puede ser visto como un porcentaje (0% - 100%). La teoría de la probabilidad se basa en modelos matemáticos que describen cómo se distribuyen las posibilidades en diferentes situaciones. La probabilidad se aplica en diversas áreas, como la toma de decisiones bajo incertidumbre, estadísticas, teoría de juegos, análisis de riesgos y más."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b79e13",
   "metadata": {},
   "source": [
    "En resumen, la probabilidad se relaciona con la cuantificación de la incertidumbre, mientras que la estadística se refiere al análisis y la interpretación de datos para tomar decisiones informadas. Aunque son conceptos distintos, a menudo se interrelacionan en campos como la teoría de la probabilidad, la estadística matemática y la inferencia estadística."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d86f37b",
   "metadata": {},
   "source": [
    "### Actividades en un análisis estadístico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dd9b3a",
   "metadata": {},
   "source": [
    "El análisis estadístico implica una serie de actividades fundamentales para comprender, resumir y extraer información útil de los datos. Estas actividades básicas son esenciales para llevar a cabo una investigación o análisis de datos de manera efectiva. Aquí están algunas de las actividades básicas del análisis estadístico:\n",
    "\n",
    "- ***Recopilación de Datos:*** Esta es la fase inicial en la que se reúnen los datos relevantes para el estudio. Los datos pueden ser recolectados a través de encuestas, experimentos, observaciones, registros u otras fuentes.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Organización y Limpieza de Datos:*** Los datos recopilados a menudo pueden ser desordenados o contener errores. En esta etapa, los datos se organizan en una forma adecuada para el análisis y se eliminan o corrigen los errores obvios.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Descripción de Datos:*** En esta etapa, se utilizan técnicas de estadística descriptiva para resumir y presentar los datos. Esto puede incluir cálculos de medidas de tendencia central (como la media, mediana y moda) y medidas de dispersión (como la desviación estándar y el rango).\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Visualización de Datos:*** Se crean gráficos para visualizar patrones, distribuciones y relaciones en los datos. Ejemplos de esto son histogramas, diagramas de dispersión y gráficos de barras.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Análisis Exploratorio de Datos:*** Esta fase implica explorar más a fondo los datos para identificar patrones interesantes o relaciones. Se pueden utilizar técnicas como análisis de clusters o análisis de componentes principales para encontrar estructuras subyacentes en los datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Inferencia Estadística:*** En esta etapa, se aplican técnicas de estadística inferencial para hacer generalizaciones sobre una población más amplia basadas en los datos de muestra. Esto incluye la estimación de parámetros poblacionales y la realización de pruebas de hipótesis.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Modelado y Predicción:*** Se utilizan modelos matemáticos y estadísticos para describir y predecir relaciones entre variables. Esto puede implicar el uso de regresión, análisis de series temporales u otras técnicas de modelado.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Validación y Verificación:*** Se evalúa la confiabilidad y validez de los resultados obtenidos. Esto puede involucrar el uso de técnicas como validación cruzada y pruebas de sensibilidad.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Comunicación de Resultados:*** Los resultados y conclusiones del análisis se presentan de manera clara y comprensible para las personas interesadas. Esto puede incluir informes, presentaciones y visualizaciones.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Toma de Decisiones:*** Finalmente, los resultados del análisis estadístico se utilizan para tomar decisiones informadas, hacer recomendaciones o llevar a cabo acciones basadas en la comprensión de los datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Estas actividades básicas no son necesariamente lineales y a menudo se superponen en diferentes etapas del proceso de análisis. El análisis estadístico es un proceso iterativo en el que se pueden ajustar y refinar enfoques a medida que se adquiere una comprensión más profunda de los datos y los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f589b6e",
   "metadata": {},
   "source": [
    "### Rol de la Analítica de Datos en la Toma de Decisiones Empresariales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cd5111",
   "metadata": {},
   "source": [
    "La analítica de datos se ha convertido en una herramienta indispensable para las empresas modernas. Desde la identificación de patrones hasta la detección de tendencias, la analítica de datos nos proporciona una visión profunda y valiosa que influye en las decisiones estratégicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e27ae7e",
   "metadata": {},
   "source": [
    "### Bibliotecas para tratamiento de datos estadísticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aed67f",
   "metadata": {},
   "source": [
    "Python tiene una extensa variedad de bibliotecas que ayudan en el trabajo con datos. A continuación se presentará un compendio de las más utilizadas (algunas ya las hemos visto):\n",
    "\n",
    "- ***[numpy](https://www.numpy.org/):*** El popular paquete matemático de Python, se utiliza tanto que mucha gente ya lo considera parte integral del lenguaje. Nos proporciona algunas funciones estadísticas que podemos aplicar fácilmente sobre los arrays de Numpy.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***[scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html#module-scipy.stats):*** Este submodulo del paquete científico Scipy es el complemento perfecto para Numpy, las funciones estadisticas que no encontremos en uno, las podemos encontrar en el otro.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***[statsmodels](https://statsmodels.sourceforge.net/):*** Esta librería nos brinda un gran número de herramientas para explorar datos, estimar modelos estadísticos, realizar pruebas estadísticas y muchas cosas más.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***[matplotlib](https://matplotlib.org/):*** Es la librería más popular en Python para visualizaciones y gráficos. Ella nos va a permitir realizar los gráficos de las distintas distribuciones de datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***[seaborn](https://stanford.edu/~mwaskom/software/seaborn/):*** Esta librería es un complemento ideal de matplotlib para realizar gráficos estadísticos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***[pandas](https://pandas.pydata.org/):*** Esta es la librería más popular para análisis de datos y financieros. Posee algunas funciones muy útiles para realizar estadística descriptiva sobre nuestros datos y nos facilita sobremanera el trabajar con series de tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d067050",
   "metadata": {},
   "source": [
    "## Estadística descriptiva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4537d0ba",
   "metadata": {},
   "source": [
    "La [estadística descriptiva](https://en.wikipedia.org/wiki/Descriptive_statistics) es una rama fundamental de la estadística que se enfoca en la descripción, resumen y organización de los [datos](https://en.wikipedia.org/wiki/Data) de manera que podamos entender mejor su estructura, patrones y características principales. Su objetivo principal es proporcionar una visión clara y concisa de un conjunto de datos, lo que permite identificar tendencias, patrones, distribuciones y resaltar aspectos clave sin realizar inferencias más allá de los datos presentes. Veamos los componentes esenciales de la estadística descriptiva y cómo se aplican a través de ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9bdc5a",
   "metadata": {},
   "source": [
    "### Medidas de Tendencia Central"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c4ed8",
   "metadata": {},
   "source": [
    "Las medidas de tendencia central se utilizan para identificar el valor central o típico en un conjunto de datos. Ejemplos de medidas de tendencia central incluyen:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd7491",
   "metadata": {},
   "source": [
    "<a id='mean'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad12c187",
   "metadata": {},
   "source": [
    "#### Media aritmética"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8918a5bf",
   "metadata": {},
   "source": [
    "La [media aritmética](https://en.wikipedia.org/wiki/Arithmetic_mean) es la suma de todos los valores dividida por el número total de valores. Se suele representar con la letra griega $\\mu$. Si tenemos una muestra de $n$ valores, $x_i$, la media aritmética, $\\mu$, es la suma de los valores divididos por el numero de elementos; en otras palabras:\n",
    "\n",
    "$$\\mu = \\frac{1}{n}\\sum_i^n{x_i}=\\frac{x_1+x_2+x_3+\\ldots+x_n}{n}$$\n",
    "\n",
    "***Ejemplo:*** En un conjunto de calificaciones de estudiantes $(85, 90, 78, 92, 88)$, la media sería \n",
    "\n",
    "$$\\frac{(85 + 90 + 78 + 92 + 88)} {5} = 86.6$$\n",
    "\n",
    "veamos diferentes formas de cómo sería empleando un lenguaje de programación (python). Empecemos por la forma más básica hasta avanzar a la forma \"correcta\":"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2f1f20",
   "metadata": {},
   "source": [
    "La primera forma es emplear Python como simple calculadora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0654f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python como simple calculadora\n",
    "media = (85 + 90 + 78 + 92 + 88) / 5\n",
    "media"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5915e5",
   "metadata": {},
   "source": [
    "Supongamos que no tenemos 5 datos, sino miles, millones de datos. Avancemos un poco y ahora usemos algunas de las estructuras de programación vistas en el mini-curso. Creemos una lista con los datos y usemos las funcionalidades que tiene python para extraer información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d7175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos\n",
    "#data = [85, 90, 78, 92, 88]    # lista con datos\n",
    "data = [25, 30, 32, 38, 40, 45]\n",
    "n = len(data)                  # determina la cantidad de datos en la lista"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c43c3f",
   "metadata": {},
   "source": [
    "Con los datos ya almacenados en memoria, podemos emplear un ciclo `for` para ir generando la suma acumulada de cada uno de los elementos de la lista y después obtener el valor de la media:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d4a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empleando un ciclo for que recorra todo el vector de datos x\n",
    "\n",
    "suma = 0\n",
    "\n",
    "for i in data:\n",
    "    suma += i\n",
    "\n",
    "media = suma / n\n",
    "print(media)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7594e36b",
   "metadata": {},
   "source": [
    "Ahora vamos un paso más adelante y empleemos las funciones predefinidas que posee Python para obtener de forma rápida y eficiente algunos valores. Veamos primero cuáles son esas funciones predefinidas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702caee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "\n",
    "print(dir(builtins))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1487b",
   "metadata": {},
   "source": [
    "Observemos que ya hay una función `sum` predefinida. Veamos qué hace esa función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fb3df2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670845f1",
   "metadata": {},
   "source": [
    "Ahora usemos la función predefinida en nuestros cálculos,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2747165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empleando la función suma (más eficiente)\n",
    "\n",
    "suma = sum(data)\n",
    "media = suma / n\n",
    "print(media)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903c04c7",
   "metadata": {},
   "source": [
    "Ya no es necesario usar un ciclo para determinar la suma. Python ya trae por defecto dicha operación (además, de ser más eficiente computacionalmente). \n",
    "\n",
    "Por último, empleemos las bibliotecas que contiene Python para facilitar el trabajo. Empecemos con la biblioteca [`Numpy`](https://numpy.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3947a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empleando el módulo Numpy y sus funciones - la opción correcta!\n",
    "import numpy as np\n",
    "\n",
    "media = np.mean(data)\n",
    "print(media)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80269665",
   "metadata": {},
   "source": [
    "Observése que, aprovechando las funcionalidades del lenguaje, se logra una mayor eficiencia en el trabajo. Para los siguientes cálculos emplearemos en lo posible el llamado a bibliotecas y funciones predefinidas en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8df883",
   "metadata": {},
   "source": [
    "#### Mediana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b235955",
   "metadata": {},
   "source": [
    "La mediana es el valor que divide el conjunto de datos en dos partes iguales. \n",
    "\n",
    "- ***Ejemplo:*** En un conjunto de datos $(25, 30, 32, 40, 45)$, la mediana sería el valor que está en la mitad, en este caso $32$. Obsérvese que este conjunto de datos tiene una cantidad impar de datos, por lo que el dato que ocupa la mitad es la mediana. Si fuera un conjunto de datos con una cantidad par, por ejemplo $(25, 30, 32, 38, 40, 45)$, la mediana sería el promedio entre los datos $32$ y $38$, es decir: $(32 + 38) / 2 = 35.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71127b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cuentas con \"calculadora\"\n",
    "(32 + 38) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f6d94f",
   "metadata": {},
   "source": [
    "Programemos en python nuestra propia función para calcular la mediana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3dd563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediana(x):\n",
    "    n = len(x)\n",
    "    x_sort = sorted(x)\n",
    "\n",
    "    if n % 2 == 0:\n",
    "        low = n // 2 - 1\n",
    "        high = n // 2\n",
    "        mediana = (x_sort[low] + x_sort[high]) / 2\n",
    "    else:\n",
    "        indice_mediana = n // 2\n",
    "        mediana = x_sort[indice_mediana]\n",
    "\n",
    "    print(\"La mediana es:\", mediana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4843a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "\n",
    "data = [25, 30, 32, 38, 40, 45]  # cantidad par de datos\n",
    "#data = [25, 30, 32, 40, 45]  # cantidad impar de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llamado a la función mediana\n",
    "\n",
    "mediana(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90052a61",
   "metadata": {},
   "source": [
    "O, podemos emplear la función `median` de `numpy`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac2262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.median(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b2fcb",
   "metadata": {},
   "source": [
    "#### Moda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96a045",
   "metadata": {},
   "source": [
    "La moda es el valor que ocurre con mayor frecuencia en un conjunto de datos. \n",
    "\n",
    "- ***Ejemplo:*** Sea el siguiente conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80604a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [5, 8, 7, 5, 12, 7, 5, 8, 8, 5, 12, 7, 5, 4, 6, 7, 5, 8, 4, 5, 7, 5]\n",
    "\n",
    "frecuencias = {}\n",
    "for dato in data:\n",
    "    if dato in frecuencias:\n",
    "        frecuencias[dato] += 1\n",
    "    else:\n",
    "        frecuencias[dato] = 1\n",
    "\n",
    "moda = []\n",
    "frecuencia_maxima = max(frecuencias.values())\n",
    "\n",
    "for dato, frecuencia in frecuencias.items():\n",
    "    if frecuencia == frecuencia_maxima:\n",
    "        moda.append(dato)\n",
    "\n",
    "print(\"La moda es:\", moda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22f644c",
   "metadata": {},
   "source": [
    "veamos qué se almacenó en el diccionario `frecuencias`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frecuencias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7937f902",
   "metadata": {},
   "source": [
    "`Numpy` no incluye una función directa para calcular la moda. Sin embargo, podemos lograrlo importando otra biblioteca llamada [`scipy`](https://scipy.org/), que se basa en `Numpy` para ofrecer funcionalidades adicionales en tareas científicas y de ingeniería."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ae99c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35bc68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(stats.mode(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b25ed63",
   "metadata": {},
   "source": [
    "### Indicadores de Dispersión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c184a18f",
   "metadata": {},
   "source": [
    "#### Varianza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4ef1df",
   "metadata": {},
   "source": [
    "La varianza es una medida de la dispersión o variabilidad de un conjunto de datos. Indica qué tan alejados están los valores individuales del valor promedio (media) del conjunto. Una varianza más alta indica que los valores están más dispersos, mientras que una varianza más baja indica que los valores están más agrupados alrededor de la media. Se representa con el símbolo $\\sigma^2$, y su fórmula general para un conjunto de datos es:\n",
    "\n",
    "$$\\sigma^2=\\frac{\\sum \\limits_{i=1}^n \\left(x_i - \\mu \\right)^2}{n}$$\n",
    "\n",
    "un código en Python para calcular la varianza podría ser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b77f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = [25, 30, 32, 38, 40, 45]\n",
    "#data = [1,2,2,2,1,1,3,2,2,2]\n",
    "#data = [100,101,101,100,103,101,102,101,100,103,100,102,102]\n",
    "\n",
    "n = len(data)\n",
    "media = sum(data) / n\n",
    "\n",
    "diferencias_cuadradas = [(x - media) ** 2 for x in data]    # list comprenhension para evitar el ciclo for\n",
    "varianza = sum(diferencias_cuadradas) / n\n",
    "\n",
    "print(\"La varianza es:\", varianza)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9231ab4f",
   "metadata": {},
   "source": [
    "Empleando la biblioteca `Numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cb68b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece86c71",
   "metadata": {},
   "source": [
    "#### Desviación estándar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde5eb8d",
   "metadata": {},
   "source": [
    "La [desviación estándar](https://en.wikipedia.org/wiki/Standard_deviation) es una medida estadística que indica cuánto se desvían los valores individuales de un conjunto de datos con respecto a su media. En otras palabras, mide la dispersión o variabilidad de los valores con respecto a la media. Una desviación estándar mayor indica que los valores están más dispersos, mientras que una desviación estándar menor indica que los valores están más cerca de la media. Matemáticamente, la desviación estándar es la raíz cuadrada de la varianza:\n",
    "\n",
    "$$\\sigma=\\sqrt{\\frac{\\sum \\limits_{i=1}^n \\left(x_i - \\mu \\right)^2}{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab495bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd73c4",
   "metadata": {},
   "source": [
    "### Indicadores de Forma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9648df8",
   "metadata": {},
   "source": [
    "#### Asimetría (Skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08e6319",
   "metadata": {},
   "source": [
    "Mide la [asimetría](https://en.wikipedia.org/wiki/Skewness) de la distribución. Un valor positivo indica que la distribución se extiende más hacia la derecha, mientras que un valor negativo indica que se extiende más hacia la izquierda.\n",
    "\n",
    "La asimetría mide la falta de simetría en una distribución. Una distribución simétrica tiene valores iguales a ambos lados de la medida central (media o mediana), mientras que una distribución asimétrica tiene valores que se extienden más hacia uno de los lados. La asimetría se calcula como:\n",
    "\n",
    "$$Asimetria=\\frac{3 \\left( \\text{Media}-\\text{Mediana}\\right)}{\\text{Desv. Estándar}}$$\n",
    "\n",
    "- Un valor positivo de asimetría indica una cola derecha (distribución con valores más bajos extendiéndose hacia la izquierda y valores más altos hacia la derecha).\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Un valor negativo de asimetría indica una cola izquierda (distribución con valores más bajos hacia la derecha y valores más altos hacia la izquierda).\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Un valor cercano a cero indica una distribución aproximadamente simétrica.\n",
    "\n",
    "***Uso:*** La asimetría es útil para comprender cómo se distribuyen los datos alrededor de la media o mediana. Por ejemplo, en finanzas, la asimetría se utiliza para analizar los rendimientos de inversión y evaluar el riesgo asociado con ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5ce934",
   "metadata": {},
   "source": [
    "#### Curtosis (Kurtosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf718b9",
   "metadata": {},
   "source": [
    "La [curtosis](https://en.wikipedia.org/wiki/Kurtosis) mide la concentración de los datos en las colas de la distribución en comparación con una distribución normal. Una distribución con alta curtosis tiene colas más pesadas y valores extremos, mientras que una distribución con baja curtosis tiene colas más livianas.\n",
    "\n",
    "- Kurtosis estándar (mesocúrtica) = 3: que se resta del valor calculado para ajustar la distribución normal.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Kurtosis > 3: Colas más pesadas que la distribución normal (distribución leptocúrtica).\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Kurtosis < 3: Colas más livianas que la distribución normal (distribución platicúrtica).\n",
    "\n",
    "***Uso:*** La curtosis nos ayuda a identificar la proporción de valores extremos en una distribución. Por ejemplo, en análisis financiero, la curtosis puede utilizarse para evaluar si una inversión es más o menos volátil en comparación con una distribución normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf5aeb",
   "metadata": {},
   "source": [
    "#### Momentos Estadísticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61adbfab",
   "metadata": {},
   "source": [
    "Además de la asimetría y la curtosis, se pueden calcular momentos de mayor orden (más allá del segundo momento) para obtener información detallada sobre la forma de la distribución. Los momentos de tercer y cuarto orden están relacionados con la asimetría y la curtosis, respectivamente.\n",
    "\n",
    "- ***Momento de Tercer Orden (Skewness Absoluto):*** Mide la asimetría absoluta de la distribución.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Momento de Cuarto Orden (Kurtosis Exceso):*** Similar a la curtosis, pero ya se ha restado el valor de la curtosis estándar.\n",
    "\n",
    "***Uso:*** Los momentos de mayor orden proporcionan detalles adicionales sobre la forma de la distribución y pueden ser útiles en análisis más profundos y especializados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Crear un conjunto de datos de ejemplo\n",
    "np.random.seed(42)\n",
    "data = np.random.normal(loc=0, scale=1, size=1000)\n",
    "\n",
    "# Crear un DataFrame de Pandas\n",
    "df = pd.DataFrame({'Data': data})\n",
    "\n",
    "# Calcular la asimetría utilizando Pandas y Scipy\n",
    "data_skew = skew(df['Data'])\n",
    "\n",
    "# Calcular la curtosis utilizando Pandas y Scipy\n",
    "data_kurtosis = kurtosis(df['Data'])\n",
    "\n",
    "# Calcular el momento de tercer orden (Skewness Absoluto)\n",
    "skew_abs = np.mean((df['Data'] - df['Data'].mean())**3) / np.power(df['Data'].std(), 3)\n",
    "\n",
    "# Calcular el momento de cuarto orden (Kurtosis Exceso)\n",
    "kurt_excess = np.mean((df['Data'] - df['Data'].mean())**4) / np.power(df['Data'].std(), 4) - 3\n",
    "\n",
    "# Visualizar la distribución y los indicadores\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Histograma con KDE\n",
    "sns.histplot(data=df['Data'], bins=30, kde=True)\n",
    "\n",
    "# Líneas verticales para los indicadores\n",
    "plt.axvline(df['Data'].mean(), color='r', linestyle='dashed', linewidth=1, label='Media')\n",
    "plt.axvline(np.median(df['Data']), color='g', linestyle='dashed', linewidth=1, label='Mediana')\n",
    "plt.legend()\n",
    "\n",
    "# Anotaciones para los indicadores\n",
    "plt.annotate(f\"Asimetría: {data_skew:.2f}\", xy=(0.05, 0.9), xycoords='axes fraction')\n",
    "plt.annotate(f\"Curtosis: {data_kurtosis:.2f}\", xy=(0.05, 0.85), xycoords='axes fraction')\n",
    "plt.annotate(f\"Skewness Absoluto: {skew_abs:.2f}\", xy=(0.05, 0.8), xycoords='axes fraction')\n",
    "plt.annotate(f\"Kurtosis Exceso: {kurt_excess:.2f}\", xy=(0.05, 0.75), xycoords='axes fraction')\n",
    "\n",
    "plt.xlabel('Valor')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Distribución de Datos y Indicadores de Forma')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d4ef84",
   "metadata": {},
   "source": [
    "De la gráfica y los valores indicados, se puede interpretar lo siguiente:\n",
    "\n",
    "- ***Asimetría (Skewness):*** Con un valor de asimetría de $0.12$, la distribución muestra una ligera asimetría hacia la derecha. Esto significa que la mayoría de los valores se concentran en el lado izquierdo de la distribución, mientras que la cola derecha se extiende más lejos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Curtosis (Kurtosis):*** Un valor de curtosis de $0.07$ indica que la distribución tiene colas más ligeras y menos concentración en los valores extremos en comparación con una distribución normal. Esta distribución es menos puntiaguda en el centro y las colas, lo que sugiere menos probabilidad de valores atípicos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Skewness Absoluto:*** El valor de $0.12$ para el skewness absoluto confirma la ligera asimetría hacia la derecha, similar a lo que se observa en el valor de asimetría.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Kurtosis Exceso:*** Con un valor de kurtosis exceso de 0.06, la distribución muestra una ligera cantidad de colas más ligeras que las de la distribución normal. Esto sugiere que la distribución tiene una concentración razonable de valores cerca de la media y colas menos densas.\n",
    "\n",
    "En resumen, la distribución de datos en este caso parece ser relativamente simétrica, con colas más ligeras y menos concentración en los valores extremos. Esto podría indicar que los datos tienden a agruparse en el centro y tienen menos presencia de valores atípicos en comparación con una distribución normal. Es importante recordar que estas interpretaciones se hacen en relación con los valores de referencia (como una distribución normal), y las interpretaciones pueden variar según el contexto del análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0135e3cc",
   "metadata": {},
   "source": [
    "### Generación de números aleatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a289c0ee",
   "metadata": {},
   "source": [
    "#### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc860688",
   "metadata": {},
   "source": [
    "Los [números aleatorios](https://en.wikipedia.org/wiki/Random_number_generation) son fundamentales en la simulación, el análisis estadístico y muchas otras aplicaciones en ciencias de datos. NumPy es una biblioteca numérica que nos proporciona herramientas eficientes para generar secuencias de números pseudoaleatorios con diversas distribuciones y propiedades.\n",
    "\n",
    "NumPy proporciona un módulo llamado [`numpy.random`](https://numpy.org/doc/stable/reference/random/index.html) que contiene una variedad de funciones para la generación de números aleatorios. Estos números no son verdaderamente aleatorios, sino que se generan utilizando algoritmos deterministas, lo que los hace pseudoaleatorios. Esto es útil para la reproducibilidad y el control experimental."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc85f49",
   "metadata": {},
   "source": [
    "#### Funciones principales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bcaeac",
   "metadata": {},
   "source": [
    "- `numpy.random.rand()` genera números aleatorios en el rango `[0, 1)` con [distribución uniforme](https://en.wikipedia.org/wiki/Discrete_uniform_distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b54a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "uniform_random_nums = np.random.rand(5)  # Genera 5 números aleatorios uniformes\n",
    "#print(uniform_random_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c31f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(uniform_random_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bab19b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(uniform_random_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e81071",
   "metadata": {},
   "source": [
    "- `numpy.random.randn()` genera números aleatorios con [distribución normal estándar](https://en.wikipedia.org/wiki/Normal_distribution) (media 0 y desviación estándar 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ac12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_random_nums = np.random.randn(5)  # Genera 5 números aleatorios con distribución normal\n",
    "#print(normal_random_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ea5779",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(normal_random_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acfac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(normal_random_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81feecf2",
   "metadata": {},
   "source": [
    "- `numpy.random.randint()`: Genera números enteros aleatorios en un rango específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a70656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_integers = np.random.randint(10, 20, size=100)  # Genera 5 enteros aleatorios entre 1 y 9\n",
    "print(random_integers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989dae1d",
   "metadata": {},
   "source": [
    "- `numpy.random.choice()`: Genera una muestra aleatoria de valores a partir de una secuencia dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855aa3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['manzana', 'banana', 'cereza', 'dátil', 'uva', 'papaya', 'mango', 'lulo', 'curuba']\n",
    "random_fruit = np.random.choice(options, size=4, replace=False)  # Elige 2 frutas sin reemplazo\n",
    "print(random_fruit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745deee",
   "metadata": {},
   "source": [
    "- `numpy.random.shuffle()`: Mezcla una secuencia en su lugar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deck_of_cards = np.arange(1, 53)\n",
    "print(deck_of_cards)\n",
    "\n",
    "a = np.random.shuffle(deck_of_cards)  # Mezcla las cartas del mazo\n",
    "print(deck_of_cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ec68d2",
   "metadata": {},
   "source": [
    "- `numpy.random.seed()`: Establece una semilla para generar números pseudoaleatorios, lo que permite la reproducibilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba470a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # Fija la semilla para reproducibilidad\n",
    "random_nums = np.random.rand(5)  \n",
    "print(random_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78995f43",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750a36ec",
   "metadata": {},
   "source": [
    "#### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bd9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de estadistica descriptiva con python\n",
    "\n",
    "import numpy as np # importando numpy\n",
    "from scipy import stats # importando scipy.stats\n",
    "import pandas as pd # importando pandas\n",
    "\n",
    "np.random.seed(2131982) # para poder replicar el random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c844611",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = np.random.randn(5, 4) # datos normalmente distribuidos\n",
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f68dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# media arítmetica\n",
    "datos.mean() # Calcula la media aritmetica de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c738bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(datos) # Mismo resultado desde la funcion de numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.mean(axis=1) # media aritmetica de cada fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee95e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.mean(axis=0) # media aritmetica de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684f256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(datos) # mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c24d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(datos, 0) # media aritmetica de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778fa37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(datos) # Desviación típica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42859703",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(datos, 0) # Desviación típica de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(datos) # varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601716ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(datos, 0) # varianza de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moda\n",
    "stats.mode(datos) # Calcula la moda de cada columna\n",
    "# el 2do array devuelve la frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2074d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos2 = np.array([1, 2, 3, 6, 6, 1, 2, 4, 2, 2, 6, 6, 8, 10, 6])\n",
    "stats.mode(datos2) # aqui la moda es el 6 porque aparece 5 veces en el vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c24ba28",
   "metadata": {},
   "source": [
    "#### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(datos, index=['a', 'b', 'c', 'd', 'e'], \n",
    "                        columns=['col1', 'col2', 'col3', 'col4'])\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419d8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe() # resumen estadistadistico con pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d39a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.sum() # sumando las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5152d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.sum(axis=1) # sumando filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09541265",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.cumsum() # acumulados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bfeaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.mean() # media aritmetica de cada columna con pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e3327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.mean(axis=1) # media aritmetica de cada fila con pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0491fae5",
   "metadata": {},
   "source": [
    "## Descripción gráfica de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e417056",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9312e795",
   "metadata": {},
   "source": [
    "En la estadística descriptiva, una parte fundamental es la capacidad de visualizar y comprender los datos mediante gráficos. Los gráficos nos permiten resumir, analizar y presentar de manera efectiva la información contenida en un conjunto de datos. En esta sesión, exploraremos los gráficos más empleados para la descripción de los datos y cómo interpretarlos correctamente.\n",
    "\n",
    "La descripción gráfica de los datos es esencial para comprender la distribución, patrones y relaciones dentro de un conjunto de datos. Los histogramas, diagramas de barras, gráficos de dispersión, diagramas de caja, gráficos de torta y gráficos de líneas son herramientas valiosas que nos ayudan a visualizar y comunicar la información contenida en los datos de manera efectiva. Cada tipo de gráfico tiene su propia utilidad y puede proporcionar información única sobre los datos que estamos analizando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e41f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cc2bef",
   "metadata": {},
   "source": [
    "### Histograma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83662725",
   "metadata": {},
   "source": [
    "#### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55837b26",
   "metadata": {},
   "source": [
    "El histograma es una herramienta esencial para comprender la distribución de los datos en un conjunto. Se utiliza para representar la frecuencia con la que ocurren diferentes valores en un rango de valores continuos. En el eje horizontal se ubican los intervalos (llamados \"clases\") y en el eje vertical se muestra la frecuencia o la densidad de observaciones en cada intervalo.\n",
    "\n",
    "***Interpretación:*** Un histograma puede ayudarnos a identificar si los datos siguen una distribución normal, si presentan sesgos hacia algún extremo o si hay valores atípicos (outliers) presentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc74b7c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Genera datos aleatorios para el ejemplo\n",
    "data = np.random.normal(0, 1, 10000)\n",
    "\n",
    "# Crear un histograma\n",
    "plt.hist(data, bins=20, edgecolor='black')\n",
    "plt.title('Histograma')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a7aa1",
   "metadata": {},
   "source": [
    "#### Construcción de un Histograma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb094026",
   "metadata": {},
   "source": [
    "Para crear un histograma, seguimos los siguientes pasos:\n",
    "\n",
    "- ***División en Intervalos:*** Definimos los intervalos o \"bins\" en los cuales agruparemos los datos. Estos intervalos deben ser apropiados para la naturaleza de los datos y la pregunta de investigación. La regla de Sturges es una fórmula comúnmente utilizada para determinar el número de bins, pero también se pueden emplear otros enfoques.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "\n",
    "- ***Conteo de Frecuencias:*** Contamos cuántas observaciones caen en cada intervalo y representamos esta frecuencia en el eje vertical.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "\n",
    "- ***Visualización:*** Dibujamos las barras correspondientes a cada intervalo en el gráfico, donde la altura de cada barra representa la frecuencia o proporción de observaciones en ese intervalo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d455d",
   "metadata": {},
   "source": [
    "#### Interpretación del Histograma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a426f666",
   "metadata": {},
   "source": [
    "##### Simétrico y Unimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee459e9",
   "metadata": {},
   "source": [
    "Un histograma es simétrico si una mitad del histograma es un reflejo especular de la otra mitad. Esto indica que los valores tienden a distribuirse de manera uniforme alrededor de un valor central. Si el histograma presenta un solo pico o moda, se dice que es unimodal. Veamos un ejemplo en Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e27676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos con distribución normal simétrica\n",
    "data = np.random.normal(loc=0, scale=1, size=1000)\n",
    "\n",
    "# Crear histograma\n",
    "plt.hist(data, bins=20, color='blue', alpha=0.7)\n",
    "plt.title('Histograma Simétrico y Unimodal')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556406e",
   "metadata": {},
   "source": [
    "##### Asimetría Positiva y Negativa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550114cd",
   "metadata": {},
   "source": [
    "Un histograma tiene asimetría positiva (sesgo a la derecha) cuando la cola derecha es más larga que la izquierda. Por otro lado, tiene asimetría negativa (sesgo a la izquierda) cuando la cola izquierda es más larga que la derecha. Esto indica que la distribución de los datos se inclina hacia un lado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db55441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generar datos con asimetría positiva (sesgo a la derecha)\n",
    "data_positive_skew = np.random.gamma(shape=2, scale=1, size=1000)\n",
    "\n",
    "# Generar datos con asimetría negativa (sesgo a la izquierda)\n",
    "data_negative_skew = -np.random.gamma(shape=2, scale=1, size=1000)\n",
    "\n",
    "# Crear histogramas\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data_positive_skew, bins=20, color='green', alpha=0.7)\n",
    "plt.title('Histograma Asimetría Positiva')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data_negative_skew, bins=20, color='orange', alpha=0.7)\n",
    "plt.title('Histograma Asimetría Negativa')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe7b7de",
   "metadata": {},
   "source": [
    "##### Bimodal y Multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916107b7",
   "metadata": {},
   "source": [
    "Un histograma es bimodal si presenta dos picos o modas claramente distinguibles. Si tiene más de dos picos, se considera multimodal. Estos casos pueden indicar la presencia de subgrupos o diferentes fenómenos en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos bimodales y multimodales\n",
    "data_bimodal = np.concatenate([np.random.normal(loc=-2, scale=1, size=500),\n",
    "                               np.random.normal(loc=2, scale=1, size=500)])\n",
    "data_multimodal = np.concatenate([np.random.normal(loc=-2, scale=1, size=300),\n",
    "                                  np.random.normal(loc=0, scale=1, size=300),\n",
    "                                  np.random.normal(loc=2, scale=1, size=300)])\n",
    "\n",
    "# Crear histogramas\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data_bimodal, bins=30, color='purple', alpha=0.7)\n",
    "plt.title('Histograma Bimodal')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data_multimodal, bins=30, color='red', alpha=0.7)\n",
    "plt.title('Histograma Multimodal')\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e432925",
   "metadata": {},
   "source": [
    "### Diagrama de Barras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d158525",
   "metadata": {},
   "source": [
    "El diagrama de barras es un gráfico que representa las frecuencias de diferentes categorías o clases. A diferencia del histograma, las categorías en un diagrama de barras no son continuas, sino discretas. Cada categoría se muestra en el eje horizontal, mientras que la altura de la barra representa la frecuencia o la cantidad asociada con esa categoría.\n",
    "\n",
    "- ***Interpretación:*** El diagrama de barras es útil para comparar diferentes categorías y visualizar la distribución de los datos categóricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed08ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con datos categóricos\n",
    "data = {'Categoría': ['A', 'B', 'C', 'D'],\n",
    "        'Frecuencia': [25, 40, 15, 30]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Crear el diagrama de barras\n",
    "plt.bar(df['Categoría'], df['Frecuencia'])\n",
    "plt.title('Diagrama de Barras')\n",
    "plt.xlabel('Categoría')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef2c37a",
   "metadata": {},
   "source": [
    "### Gráfico de dispersión (scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74afcb0c",
   "metadata": {},
   "source": [
    "El gráfico de dispersión es una herramienta valiosa para explorar la relación entre dos variables continuas. Cada punto en el gráfico representa una observación y su posición en los ejes X e Y está determinada por los valores de esas dos variables. Este gráfico nos permite identificar patrones, tendencias y posibles correlaciones entre las variables.\n",
    "\n",
    "- ***Interpretación:*** Al observar un gráfico de dispersión, es posible identificar si existe una relación positiva, negativa o nula entre las variables, así como la presencia de puntos atípicos que podrían indicar valores inusuales o errores en la medición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989cb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos aleatorios para el ejemplo\n",
    "n = 50\n",
    "x = np.random.rand(n)\n",
    "y = 2 * x + np.random.normal(0, 0.1, n)\n",
    "\n",
    "# Crear el gráfico de dispersión\n",
    "plt.scatter(x, y)\n",
    "plt.title('Gráfico de Dispersión')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a29335",
   "metadata": {},
   "source": [
    "### Diagrama de Caja (Boxplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8c1129",
   "metadata": {},
   "source": [
    "#### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149b6e1d",
   "metadata": {},
   "source": [
    "El diagrama de caja, o boxplot, proporciona una representación visual de la distribución de los datos y resalta información sobre la mediana, cuartiles y posibles valores atípicos. Consiste en un rectángulo que abarca el rango intercuartílico (IQR) y líneas (bigotes) que se extienden hacia los valores mínimo y máximo dentro de ciertos límites.\n",
    "\n",
    "- ***Interpretación:*** El diagrama de caja es excelente para identificar la simetría de la distribución, la presencia de valores atípicos y la concentración de los datos alrededor de la mediana."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9623939f",
   "metadata": {},
   "source": [
    "#### Componentes del Diagrama de Caja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86799f03",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/C02_03_BoxPlot.png?raw=true\" width=\"750\" />\n",
    "</p>\n",
    "\n",
    "- ***Mediana ($Q2$):*** Es el valor que divide a los datos en dos partes iguales. La mitad de los datos están por encima de la mediana y la otra mitad por debajo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cuartiles ($Q1$ y $Q3$):*** Los cuartiles dividen los datos en cuatro partes iguales. El primer cuartil ($Q1$) es el valor que deja el $25%$ de los datos por debajo (*25th percentile*) y el tercer cuartil ($Q3$) es el valor que deja el $75%$ de los datos por debajo (*75th percentile*).\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Rango Intercuartílico ($IQR$):*** Es la diferencia entre el tercer cuartil ($Q3$) y el primer cuartil ($Q1$). Representa el rango en el que se encuentra el $50%$ central de los datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Bigotes (Whiskers):*** Los bigotes representan el rango de datos considerados \"normales\" y se extienden hasta los valores mínimo y máximo que caen dentro de $1.5$ veces el $IQR$ desde el primer y tercer cuartil respectivamente. Cualquier valor fuera de esta distancia se considera un valor atípico (outlier).\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Valor mínimo:*** se determina mediante la fórmula $Q1-1.5 \\times IQR$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Valor máximo:*** se determina mediante la fórmula $Q3+1.5 \\times IQR$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Valores Atípicos (Outliers):*** Son valores que se encuentran significativamente lejos del resto de los datos y pueden indicar situaciones inusuales o errores en la medición.\n",
    "\n",
    "Ahora veamos cómo se genera un diagrama de caja empleando la biblioteca `numpy` de python :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd62dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generar datos aleatorios para el ejemplo\n",
    "data = np.random.normal(0, 1, 100)\n",
    "\n",
    "# Crear el diagrama de caja\n",
    "plt.boxplot(data)\n",
    "plt.title('Diagrama de Caja')\n",
    "plt.ylabel('Valores')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab48316",
   "metadata": {},
   "source": [
    "El siguiente ejemplo es empleando `DataFrames` de `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf76781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar un DataFrame con datos aleatorios\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'Grupo A': np.random.normal(60, 10, 100),\n",
    "    'Grupo B': np.random.normal(70, 5, 100),\n",
    "    'Grupo C': np.random.normal(80, 8, 100)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Crear un diagrama de caja\n",
    "plt.figure(figsize=(10, 6))\n",
    "df.boxplot()\n",
    "plt.title('Diagrama de Caja - Comparación de Grupos')\n",
    "plt.ylabel('Valores')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cfb918",
   "metadata": {},
   "source": [
    "En este ejemplo, hemos generado tres grupos de datos ficticios (Grupo A, Grupo B y Grupo C) y los hemos combinado en un DataFrame de Pandas. Luego, hemos creado un diagrama de caja que muestra la comparación de las distribuciones entre los tres grupos.\n",
    "\n",
    "Cada caja representa la distribución de datos en un grupo, mostrando la mediana, cuartiles y el rango intercuartílico (IQR). Los bigotes se extienden hasta los valores mínimo y máximo dentro de 1.5 veces el IQR desde los cuartiles. Cualquier punto fuera de los bigotes se considera un valor atípico.\n",
    "\n",
    "Este ejemplo más complejo ilustra cómo el diagrama de caja puede ser utilizado para comparar múltiples conjuntos de datos y destacar diferencias en sus distribuciones y valores atípicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713a507c",
   "metadata": {},
   "source": [
    "#### Cuándo usar un Diagrama de Caja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fbf561",
   "metadata": {},
   "source": [
    "Un diagrama de caja puede ser útil cuando necesitas más información acerca de un conjunto/distribución de datos que solo las medidas de tendencia central (media, mediana y moda). Los diagramas de caja pueden ilustrar la variabilidad o dispersión de todos los puntos de datos presentes en un conjunto, dando una buena indicación de valores atípicos y qué tan simétricos son los datos.\n",
    "\n",
    "Aunque los diagramas de caja pueden parecer más simples en comparación con un histograma o un gráfico de densidad, tienen la ventaja de ocupar menos espacio, lo cual es útil al comparar distribuciones entre varios grupos o conjuntos de datos.\n",
    "\n",
    "Qué define un valor atípico, \"mínimo\" o \"máximo\" puede no estar claro todavía. La siguiente sección tratará de aclararte ese punto.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb1d54",
   "metadata": {},
   "source": [
    "#### Comparación entre un diagrama de caja y la distribución normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bcc875",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/C02_03_BoxPlot02.png?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7cbce9",
   "metadata": {},
   "source": [
    "La figura superior presenta una comparativa entre un gráfico de caja con intervalos y la [función de densidad de probabilidad](https://en.wikipedia.org/wiki/Probability_density_function) (PDF) de una distribución casi normal. La razón detrás de esta ilustración radica en el hecho de que la observación de una distribución estadística es más habitual que el análisis de un gráfico de caja. Este enfoque podría contribuir a una mejor comprensión del diagrama de caja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220722e0",
   "metadata": {},
   "source": [
    "### Gráfico de Torta (Pie Chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980458b",
   "metadata": {},
   "source": [
    "El gráfico de torta es ideal para representar proporciones y porcentajes dentro de un conjunto de categorías. Cada categoría se muestra como una porción de un círculo, donde el tamaño de cada porción está relacionado con la frecuencia relativa de esa categoría.\n",
    "\n",
    "- ***Interpretación:*** El gráfico de torta es útil para mostrar la composición de un conjunto de datos en términos de porcentajes y comparar proporciones entre categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad930462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos para el gráfico de torta\n",
    "labels = ['A', 'B', 'C', 'D']\n",
    "sizes = [30, 20, 15, 35]\n",
    "\n",
    "# Crear el gráfico de torta\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Gráfico de Torta')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8176a6",
   "metadata": {},
   "source": [
    "### Gráfico de Líneas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd03a6ff",
   "metadata": {},
   "source": [
    "El gráfico de líneas se utiliza para representar la evolución de una variable a lo largo del tiempo o algún otro orden secuencial. Conecta puntos de datos con líneas rectas, lo que facilita la observación de tendencias y patrones temporales.\n",
    "\n",
    "- ***Interpretación:*** Un gráfico de líneas nos permite identificar cambios a lo largo del tiempo y evaluar la dirección y la magnitud de las tendencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e097d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos aleatorios para el ejemplo\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Crear el gráfico de líneas\n",
    "plt.plot(x, y)\n",
    "plt.title('Gráfico de Líneas')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4e3c17",
   "metadata": {},
   "source": [
    "### Gráfico de Violín"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b1e23",
   "metadata": {},
   "source": [
    "#### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af2667c",
   "metadata": {},
   "source": [
    "El [gráfico de violín](https://en.wikipedia.org/wiki/Violin_plot) es una herramienta de visualización que combina las características del diagrama de caja y el gráfico de densidad en una sola representación. Proporciona información detallada sobre la distribución de los datos, incluyendo medidas de tendencia central, dispersión y densidad.\n",
    "\n",
    "En comparación con los gráficos mencionados anteriormente, el gráfico de violín ofrece una representación más completa de la distribución de los datos, incluyendo información sobre la forma de la distribución y su densidad. Si bien los otros gráficos son valiosos en sus propios contextos, el gráfico de violín puede proporcionar una perspectiva adicional que puede ser especialmente útil en situaciones en las que se busca una comprensión más detallada de la distribución de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47037d5f",
   "metadata": {},
   "source": [
    "#### Usos del gráfico de Violín"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe26334c",
   "metadata": {},
   "source": [
    "- ***Visualización de Distribución:*** Al igual que el diagrama de caja, el gráfico de violín es útil para visualizar la distribución de datos, incluyendo la concentración, simetría y la presencia de valores atípicos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "\n",
    "- ***Comparación entre Grupos:*** Puede emplearse para comparar la distribución de múltiples grupos en una sola representación, lo que puede ser más eficiente que crear múltiples gráficos de caja separados.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "\n",
    "- ***Densidad de Datos:*** El ancho del violín refleja la densidad de datos en diferentes valores, lo que permite obtener una idea de la concentración de los datos en distintas partes de la distribución."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fa5536",
   "metadata": {},
   "source": [
    "#### Componentes del Gráfico de Violín"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde0f15",
   "metadata": {},
   "source": [
    "- ***Violines Dobles:*** Los violines aparecen en pares, uno para cada categoría o grupo que deseamos comparar en el eje $X$. La forma de cada violín refleja la distribución de datos en ese grupo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Área Rellena:*** El área del violín muestra la densidad de datos en diferentes valores a lo largo del eje $X$. Un violín más ancho indica una mayor densidad de datos en esa región, mientras que uno más estrecho indica menos densidad.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Línea Central:*** Una línea en el centro de cada violín representa la mediana, lo que nos proporciona una medida de tendencia central.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Puntos o Marcas:*** Algunos gráficos de violín también incluyen puntos o marcas que indican valores individuales, lo que puede ser útil para identificar valores atípicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef06d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generar un DataFrame con datos aleatorios\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'Grupo A': np.random.normal(60, 10, 100),\n",
    "    'Grupo B': np.random.normal(70, 5, 100),\n",
    "    'Grupo C': np.random.normal(80, 8, 100)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Crear un gráfico de violín\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(data=df)\n",
    "plt.title('Gráfico de Violín - Comparación de Grupos')\n",
    "plt.ylabel('Valores')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcff8952",
   "metadata": {},
   "source": [
    "En este ejemplo, hemos utilizado la biblioteca Seaborn para crear un gráfico de violín que muestra la comparación de las distribuciones entre tres grupos ficticios (Grupo A, Grupo B y Grupo C). Cada violín representa la distribución de datos en un grupo, y el área del violín muestra la densidad de los valores a lo largo del eje $X$. La línea central en cada violín representa la mediana."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561145c7",
   "metadata": {},
   "source": [
    "## Análisis de Normalidad y Exploración de Modelos Probabilísticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dc3a79",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45198e25",
   "metadata": {},
   "source": [
    "En el mundo de la estadística, es fundamental comprender cómo los datos se distribuyen y qué modelos probabilísticos subyacen a ellos. Esto nos permite realizar inferencias, tomar decisiones informadas y construir modelos predictivos sólidos. En este tema, exploraremos el concepto de normalidad y otros modelos explicativos de la incertidumbre detrás de los datos, utilizando herramientas del ecosistema de Python, como NumPy, Pandas, Matplotlib y Seaborn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5cf9f7",
   "metadata": {},
   "source": [
    "### Análisis de Normalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91779a07",
   "metadata": {},
   "source": [
    "#### Definición de la Distribución Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e16b28",
   "metadata": {},
   "source": [
    "La [distribución normal](https://en.wikipedia.org/wiki/Normal_distribution), también conocida como distribución gaussiana, es una de las distribuciones más importantes en estadística. Se caracteriza por su forma de campana y es ampliamente utilizada debido al [Teorema Central del Límite](https://en.wikipedia.org/wiki/Central_limit_theorem), que establece que las sumas de variables aleatorias independientes tienden a seguir una distribución normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad982eb",
   "metadata": {},
   "source": [
    "#### Indicadores de Normalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871066fe",
   "metadata": {},
   "source": [
    "##### Histograma y Gráficos de Densidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2180f5",
   "metadata": {},
   "source": [
    "Visualización de la forma de la distribución. El histograma es una representación gráfica de la distribución de frecuencias de los datos. Divide el rango de valores en intervalos (llamados \"bins\") y muestra cuántos datos caen en cada intervalo. Los gráficos de densidad muestran la estimación de la densidad de probabilidad de los datos, proporcionando una visión suave de la distribución.\n",
    "\n",
    "***Uso:*** Estos gráficos permiten visualizar la forma general de la distribución y detectar signos de simetría o asimetría, además de ayudar a identificar valores atípicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a10ebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generar datos simulados con distribución normal\n",
    "np.random.seed(42)\n",
    "data = np.random.normal(loc=0, scale=1, size=1000)\n",
    "\n",
    "# Histograma y Gráfico de Densidad\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(data, bins=20, kde=True)\n",
    "plt.title(\"Histograma\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.kdeplot(data)\n",
    "plt.title(\"Gráfico de Densidad\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d456b309",
   "metadata": {},
   "source": [
    "##### Gráfico Cuantil-Cuantil (Q-Q plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4983d1",
   "metadata": {},
   "source": [
    "Compara los cuantiles observados de los datos con los cuantiles esperados de una distribución teórica (como la normal). Si los puntos en el gráfico se ajustan aproximadamente a una línea diagonal, los datos son consistentes con la distribución teórica.\n",
    "\n",
    "***Uso:*** Es una herramienta visual para evaluar la normalidad de los datos y detectar desviaciones significativas de la distribución normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5268d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Generar datos simulados con distribución normal\n",
    "np.random.seed(42)\n",
    "data = np.random.normal(loc=0, scale=1, size=1000)\n",
    "\n",
    "# Gráfico Cuantil-Cuantil\n",
    "sm.qqplot(data, line='45')\n",
    "plt.title(\"Gráfico Cuantil-Cuantil\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2bf3e0",
   "metadata": {},
   "source": [
    "##### Prueba de Normalidad (Shapiro-Wilk, Anderson-Darling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e9c76e",
   "metadata": {},
   "source": [
    "Las pruebas de normalidad son métodos estadísticos que evalúan si una muestra de datos se ajusta a una distribución normal. Dos pruebas comunes son la prueba de Shapiro-Wilk y la prueba de Anderson-Darling.\n",
    "\n",
    "- La prueba de [Shapiro-Wilk](https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test) calcula un estadístico W que se compara con valores críticos para determinar si los datos son normales.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- La prueba de [Anderson-Darling](https://en.wikipedia.org/wiki/Anderson%E2%80%93Darling_test) calcula una estadística $A^2$ que se compara con valores críticos para evaluar la normalidad.\n",
    "\n",
    "***Uso:*** Estas pruebas proporcionan evidencia estadística de la normalidad de los datos, pero deben usarse junto con el análisis visual y el contexto del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019c7e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Generar datos simulados con distribución normal\n",
    "np.random.seed(42)\n",
    "data = np.random.normal(loc=0, scale=1, size=1000)\n",
    "\n",
    "# Prueba de Normalidad Shapiro-Wilk\n",
    "shapiro_stat, shapiro_p_value = stats.shapiro(data)\n",
    "print(f\"Estadístico de Shapiro-Wilk: {shapiro_stat}\")\n",
    "print(f\"P-valor de Shapiro-Wilk: {shapiro_p_value}\")\n",
    "\n",
    "# Prueba de Normalidad Anderson-Darling\n",
    "anderson_stat, anderson_critical_values, anderson_significance_levels = stats.anderson(data)\n",
    "print(f\"Estadístico de Anderson-Darling: {anderson_stat}\")\n",
    "print(f\"Valores Críticos de Anderson-Darling: {anderson_critical_values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96c3b79",
   "metadata": {},
   "source": [
    "De estos resultados podemos concluir:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422fc68d",
   "metadata": {},
   "source": [
    "***Prueba de Shapiro-Wilk:***\n",
    "\n",
    "- El estadístico de $Shapiro-Wilk = 0.9986080527305603$ proporciona una medida de cuán cerca están los datos de una distribución normal. Cuanto más cerca esté este valor de 1, más normales se consideran los datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- El $\\text{p-valor de Shapiro-Wilk} = 0.6264819502830505$ representa la probabilidad de obtener un estadístico de prueba tan extremo como el observado, dado que los datos provienen de una distribución normal. Un p-valor alto sugiere que no hay suficiente evidencia para rechazar la hipótesis nula de que los datos son normales.\n",
    "\n",
    "***Interpretación:***\n",
    "\n",
    "- Si el estadístico de *Shapiro-Wilk* está cerca de $1$ y el *p-valor* es mayor que un nivel de significancia predefinido (como $0.05$), no podemos rechazar la hipótesis de que los datos provienen de una distribución normal. En este caso, los datos pueden considerarse aproximadamente normales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7613dd",
   "metadata": {},
   "source": [
    "***Prueba de Anderson-Darling:***\n",
    "\n",
    "- El estadístico de $Anderson-Darling = 0.3474697767348971$ se compara con valores críticos específicos para diferentes niveles de significancia. Un estadístico más bajo sugiere una mejor ajuste a la distribución normal.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Los valores críticos de $Anderson-Darling: [0.574, 0.653, 0.784, 0.914, 1.088]$ son umbrales que indican qué tan pequeño debe ser el estadístico de *Anderson-Darling* para considerar que los datos siguen una distribución normal a un nivel de significancia específico.\n",
    "\n",
    "***Interpretación:***\n",
    "\n",
    "- Si el estadístico de *Anderson-Darling* es menor que el valor crítico correspondiente al nivel de significancia deseado, no hay evidencia suficiente para rechazar la hipótesis nula de normalidad. En este caso, los datos pueden considerarse aproximadamente normales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d313c",
   "metadata": {},
   "source": [
    "***Nota:*** *Recuerda que la interpretación puede variar según el contexto y el nivel de significancia elegido. En general, es importante considerar tanto el estadístico como el p-valor y compararlos con umbrales de referencia para tomar decisiones informadas sobre la normalidad de los datos.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9865c9",
   "metadata": {},
   "source": [
    "### Modelos Probabilísticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b878c0",
   "metadata": {},
   "source": [
    "#### Distribución Uniforme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f14c7d",
   "metadata": {},
   "source": [
    "La distribución uniforme es un modelo en el que todos los valores dentro de un intervalo tienen la misma probabilidad de ocurrencia. En otras palabras, todos los valores son igualmente probables.\n",
    "\n",
    "***Uso:*** La distribución uniforme se utiliza en situaciones donde no hay razón para esperar que un valor sea más probable que otro dentro de un rango dado.\n",
    "\n",
    "***Parámetros:***\n",
    "\n",
    "- ***low:*** Valor más bajo del intervalo.\n",
    "<p>&nbsp;</p>\n",
    "- ***high:*** Valor más alto del intervalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66490d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generar datos simulados con distribución uniforme\n",
    "uniform_data = np.random.uniform(low=0, high=10, size=1000)\n",
    "\n",
    "# Histograma de la Distribución Uniforme\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(uniform_data, bins=20, density=True, alpha=0.7)\n",
    "plt.title(\"Distribución Uniforme\")\n",
    "plt.xlabel(\"Valores\")\n",
    "plt.ylabel(\"Densidad de Probabilidad\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f259b",
   "metadata": {},
   "source": [
    "#### Distribución Exponencial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcdfd10",
   "metadata": {},
   "source": [
    "La distribución exponencial modela el tiempo entre eventos en un proceso de Poisson, donde los eventos ocurren de manera constante en el tiempo. Es útil para describir tiempos de espera y tasas de decaimiento.\n",
    "\n",
    "***Uso:*** Se utiliza para modelar el tiempo entre eventos o la duración hasta el próximo evento en procesos que ocurren de manera constante.\n",
    "\n",
    "***Parámetros:***\n",
    "\n",
    "- ***scale (o beta):*** Inverso de la tasa de eventos. Mayor valor indica eventos menos frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a91aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generar datos simulados con distribución exponencial\n",
    "exponential_data = np.random.exponential(scale=2, size=1000)\n",
    "\n",
    "# Histograma de la Distribución Exponencial\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(exponential_data, bins=20, density=True, alpha=0.7)\n",
    "plt.title(\"Distribución Exponencial\")\n",
    "plt.xlabel(\"Valores\")\n",
    "plt.ylabel(\"Densidad de Probabilidad\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f3c363",
   "metadata": {},
   "source": [
    "#### Distribución Poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76232c8b",
   "metadata": {},
   "source": [
    "La distribución de Poisson modela la cantidad de eventos que ocurren en un intervalo de tiempo o espacio, cuando los eventos son raros y aleatorios, pero tienen una tasa promedio conocida.\n",
    "\n",
    "***Uso:*** Se utiliza para modelar el número de eventos que ocurren en un intervalo específico, como el número de llamadas telefónicas en un período de tiempo.\n",
    "\n",
    "***Parámetros:***\n",
    "\n",
    "- ***$\\mu$:*** Tasa media de ocurrencia de eventos en el intervalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd271d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generar datos simulados con distribución de Poisson\n",
    "poisson_data = np.random.poisson(lam=3, size=1000)\n",
    "\n",
    "# Histograma de la Distribución de Poisson\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(poisson_data, bins=10, density=True, alpha=0.7)\n",
    "plt.title(\"Distribución de Poisson\")\n",
    "plt.xlabel(\"Valores\")\n",
    "plt.ylabel(\"Densidad de Probabilidad\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e499c8",
   "metadata": {},
   "source": [
    "## Estimación Puntual de Indicadores y margen de error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bd43df",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867dd716",
   "metadata": {},
   "source": [
    "En estadística, uno de los objetivos fundamentales es obtener información confiable y útil sobre una población a partir de una muestra de datos. La estimación puntual y la construcción de intervalos de confianza son herramientas esenciales para lograr esto. En este capítulo, exploraremos cómo estimar parámetros poblacionales a partir de muestras y cómo medir la incertidumbre asociada a estas estimaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593a3ef",
   "metadata": {},
   "source": [
    "### Estimación Puntual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a386e0",
   "metadata": {},
   "source": [
    "La Estimación Puntual se refiere a la técnica de calcular un valor numérico para un parámetro poblacional utilizando información de una muestra de datos. El objetivo es encontrar el mejor valor posible para el parámetro, basándose en la información que tenemos disponible. \n",
    "\n",
    "Uno de los estimadores más simples y ampliamente utilizados es la ***media muestral***, es el valor promedio de una muestra específica tomada de una población más grande. Dado que generalmente no tenemos acceso a toda la población, trabajamos con muestras para inferir información sobre la población en su conjunto. La media muestral se calcula de la misma manera que la <a href=\"#mean\">media aritmética</a>,</div> pero se utiliza en el contexto de una muestra y se denota a menudo como $\\bar{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbdfb7d",
   "metadata": {},
   "source": [
    "### Intervalos de Confianza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e760d91f",
   "metadata": {},
   "source": [
    "#### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0515e6a7",
   "metadata": {},
   "source": [
    "La Estimación Puntual es valiosa, pero también queremos cuantificar la incertidumbre asociada a nuestras estimaciones. Aquí es donde entran en juego los Intervalos de Confianza. Estos intervalos proporcionan un rango de valores dentro del cual es probable que se encuentre el verdadero valor del parámetro poblacional.\n",
    "\n",
    "Un intervalo de confianza generalmente tiene la forma: $\\text{Estimación Puntual} \\pm \\text{Margen de Error}$.\n",
    "\n",
    "El ***Margen de Error*** depende de dos factores principales: el *nivel de confianza deseado* y *la variabilidad de los datos*. Un nivel de confianza típico es del $95\\%$, lo que significa que si repitiéramos el proceso de muestreo y cálculo muchas veces, aproximadamente el $95\\%$ de los intervalos de confianza construidos contendrían el verdadero parámetro poblacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8cadb",
   "metadata": {},
   "source": [
    "#### Construcción de Intervalos de Confianza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14ac28",
   "metadata": {},
   "source": [
    "Supongamos que estamos interesados en construir un intervalo de confianza para la media poblacional ($\\mu$) basado en una muestra de datos. Si asumimos que los datos siguen una distribución normal, el intervalo de confianza se calcula usando la fórmula:\n",
    "\n",
    "$$\\text{Intervalo de Confianza}=\\bar{x} \\pm Z \\times \\frac{\\sigma}{\\sqrt{n}}$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $\\bar{x}$ es la media muestral.\n",
    "- $Z$ es el valor crítico de la distribución normal estándar correspondiente al nivel de confianza.\n",
    "- $\\sigma$ es la desviación estándar muestral.\n",
    "- $n$ es el tamaño de la muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4450ff66",
   "metadata": {},
   "source": [
    "***Ejemplo: Estimación de la Altura Promedio***\n",
    "\n",
    "Supongamos que queremos estimar la altura promedio de los estudiantes en una universidad. Tomamos una muestra aleatoria de 50 estudiantes y obtenemos las siguientes alturas (en centímetros):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be776a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "altura_muestra = np.random.normal(165, 10, 50)  # Media: 165 cm, Desviación estándar: 10 cm\n",
    "\n",
    "altura_muestra_rounded = np.around(altura_muestra, decimals=2)\n",
    "print(altura_muestra_rounded)\n",
    "\n",
    "media = np.mean(altura_muestra, dtype=np.float64)\n",
    "media_rounded = round(media, 2)  # Redondear a dos cifras decimales\n",
    "print(media_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994feb5a",
   "metadata": {},
   "source": [
    "La media muestral es $\\bar{x} = 162.75$ cm. Ahora, construyamos un intervalo de confianza al $95\\%$ para la altura promedio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c659d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "nivel_confianza = 0.95\n",
    "grados_libertad = 49  # n - 1\n",
    "\n",
    "z_score = stats.norm.ppf(1 - (1 - nivel_confianza) / 2)  # Valor crítico\n",
    "\n",
    "margen_error = z_score * altura_muestra.std() / np.sqrt(len(altura_muestra))\n",
    "intervalo_confianza = (altura_muestra.mean() - margen_error, altura_muestra.mean() + margen_error)\n",
    "\n",
    "print(\"Intervalo de Confianza: ({0:.2f}, {1:.2f})\".format(intervalo_confianza[0], intervalo_confianza[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c980605f",
   "metadata": {},
   "source": [
    "## Validación estadística de conjeturas empresariales (Pruebas de hipótesis paramétricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc26b0ad",
   "metadata": {},
   "source": [
    "### Definición de Pruebas de Hipótesis Paramétricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad407e5",
   "metadata": {},
   "source": [
    "Las [pruebas de hipótesis](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing) son una parte esencial de la [inferencia estadística](https://en.wikipedia.org/wiki/Statistical_inference). Se utilizan para tomar decisiones basadas en datos observados y evaluar si los resultados son consistentes con una afirmación específica. En el contexto empresarial, estas pruebas nos permiten validar conjeturas y tomar decisiones informadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b66eb1c",
   "metadata": {},
   "source": [
    "### Conceptos Clave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cb606c",
   "metadata": {},
   "source": [
    "- ***Hipótesis Nula (H0):*** Es una afirmación que asumimos como verdadera inicialmente. Se representa como \"H0\" y generalmente sostiene que no hay diferencia o efecto.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Hipótesis Alternativa (H1):*** Es la afirmación opuesta a la hipótesis nula. Representada como \"H1\", suele afirmar que hay una diferencia o efecto significativo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Nivel de Significancia ($\\alpha$):*** Es la probabilidad máxima que estamos dispuestos a aceptar para cometer un error de tipo I (rechazar incorrectamente H0). Usualmente, se elige un valor como $0.05$ o $0.01$.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Estadístico de Prueba:*** Es una medida calculada a partir de los datos que se utiliza para tomar una decisión sobre si rechazar o no la hipótesis nula.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Región Crítica:*** Es el rango de valores del estadístico de prueba que conduciría al rechazo de la hipótesis nula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd53b9a",
   "metadata": {},
   "source": [
    "### Indicadores y Técnicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef4d23",
   "metadata": {},
   "source": [
    "En esta sección, exploraremos algunas de las pruebas de hipótesis paramétricas más comunes y cómo aplicarlas en situaciones empresariales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2675f484",
   "metadata": {},
   "source": [
    "#### Prueba t de Student"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5865c",
   "metadata": {},
   "source": [
    "##### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09392595",
   "metadata": {},
   "source": [
    "La prueba [t de Student](https://en.wikipedia.org/wiki/Student%27s_t-distribution) es una técnica estadística que se utiliza para comparar las medias de dos grupos independientes y determinar si las diferencias observadas entre las muestras son estadísticamente significativas o simplemente se deben a la variabilidad aleatoria. Fue desarrollada por *William Sealy Gosset* y se utiliza ampliamente en la investigación y en el análisis de datos en diversas áreas, incluyendo negocios, ciencias sociales y ciencias naturales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0deb7fc",
   "metadata": {},
   "source": [
    "##### Cuándo Emplear la Prueba t de Student"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ddb7fe",
   "metadata": {},
   "source": [
    "La prueba *t de Student* es apropiada cuando se cumplen ciertas condiciones y supuestos, que son los siguientes:\n",
    "\n",
    "- ***Independencia de las Muestras:*** Las muestras que se están comparando deben ser independientes entre sí. Esto significa que las observaciones en un grupo no deben estar relacionadas o influenciarse por las observaciones en el otro grupo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Distribución Normal:*** Cada grupo debe seguir una distribución normal (gaussiana). Sin embargo, para muestras grandes (generalmente $n > 30$), la prueba *t de Student* puede ser robusta ante pequeñas desviaciones de la normalidad debido al Teorema del Límite Central.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Homogeneidad de Varianza:*** Los grupos deben tener varianzas similares. Si las varianzas son significativamente diferentes, se deben considerar pruebas alternativas como la prueba *t de Welch*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff65a12",
   "metadata": {},
   "source": [
    "##### Proceso de Realización de la Prueba t de Student"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b100d403",
   "metadata": {},
   "source": [
    "- ***Formulación de Hipótesis:***\n",
    "\n",
    "  - ***Hipótesis Nula (H0):*** Las medias de los dos grupos son iguales.\n",
    "  - ***Hipótesis Alternativa (H1):*** Las medias de los dos grupos son diferentes.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cálculo del Estadístico de Prueba:*** Calculamos el valor $t$ utilizando la fórmula: \n",
    "\n",
    "$$t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sigma_{pooled} \\times \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}$$\n",
    "\n",
    "\n",
    "  donde $\\bar{x}_1$ y $\\bar{x}_2$ son las medias de los dos grupos, $n_1$ y $n_2$ son los tamaños de las muestras y $\\sigma_{pooled}$ es la estimación de la desviación estándar combinada.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Grados de Libertad:*** Los grados de libertad se calculan como $dof = n_1 + n_2 - 2$.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cálculo del Valor p:*** Utilizamos los grados de libertad y el estadístico $t$ para calcular el valor $p$ asociado. El valor $p$ representa la probabilidad de obtener un estadístico de prueba tan extremo o más extremo que el observado, asumiendo que la hipótesis nula es verdadera.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Toma de Decisiones:*** Comparamos el valor p con el nivel de significancia ($\\alpha$) predefinido. Si el valor $p < \\alpha$, rechazamos la hipótesis nula y concluimos que hay diferencias significativas entre las medias de los grupos. Si el valor $p > \\alpha$, no tenemos suficiente evidencia para rechazar la hipótesis nula.\n",
    "\n",
    "\n",
    "***Ejemplo:***\n",
    "\n",
    "Supongamos que una empresa de telecomunicaciones desea determinar si hay una diferencia significativa en la satisfacción del cliente entre dos planes de servicio, $A$ y $B$. Han recopilado muestras aleatorias de $30$ clientes para cada plan y han medido su satisfacción en una escala del $1$ al $10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce35506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Generar datos de ejemplo\n",
    "np.random.seed(42)\n",
    "plan_a = np.random.randint(5, 10, 30)\n",
    "plan_b = np.random.randint(6, 11, 30)\n",
    "\n",
    "# Prueba t de Student\n",
    "t_stat, p_valor = ttest_ind(plan_a, plan_b)\n",
    "\n",
    "print(\"Estadístico t:\", t_stat)\n",
    "print(\"Valor p:\", p_valor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316318a5",
   "metadata": {},
   "source": [
    "En este ejemplo, el valor del estadístico $t=-1.9476$. Este valor representa la magnitud de la diferencia entre las medias de los dos grupos (plan $A$ y plan $B$) en términos de desviaciones estándar combinadas. Un valor negativo indica que la media del plan $B$ es mayor que la del plan $A$ en esta muestra específica.\n",
    "\n",
    "El valor $p$ es una medida de la evidencia en contra de la hipótesis nula. Cuanto menor sea el valor $p$, más evidencia tendremos para rechazar la hipótesis nula. El valor $p = 0.0563$ está ligeramente por encima del nivel de significancia común ($\\alpha = 0.05$). Esto significa que no tenemos evidencia suficiente para rechazar la hipótesis nula en este nivel de significancia. Sin embargo, es importante tener en cuenta que existe una tendencia hacia una diferencia en las medias.\n",
    "\n",
    "Basándonos en los resultados obtenidos, no podemos afirmar con confianza que hay una diferencia significativa en la satisfacción del cliente entre los planes $A$ y $B$. Sin embargo, debido a la proximidad del valor $p$ al nivel de significancia, podríamos considerar realizar más investigaciones o recolectar más datos para obtener una conclusión más sólida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef459df",
   "metadata": {},
   "source": [
    "Recuerda que las pruebas estadísticas son herramientas que proporcionan evidencia, pero las conclusiones deben tomarse con precaución y en contexto. En este caso, podríamos considerar ajustar el tamaño de la muestra, explorar más sobre la distribución de los datos o utilizar otros enfoques si es necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b0dfec",
   "metadata": {},
   "source": [
    "#### ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be73951",
   "metadata": {},
   "source": [
    "##### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96494c16",
   "metadata": {},
   "source": [
    "La [Prueba de Análisis de Varianza (ANOVA)](https://en.wikipedia.org/wiki/Analysis_of_variance) es una técnica estadística utilizada para comparar las medias de tres o más grupos independientes y determinar si al menos uno de esos grupos difiere significativamente de los demás. El *ANOVA* se basa en la idea de descomponer la variación total en los datos en dos componentes: la variación entre grupos y la variación dentro de los grupos. Esta descomposición permite evaluar si las diferencias observadas entre los grupos son significativas o simplemente se deben a la variabilidad aleatoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e37e957",
   "metadata": {},
   "source": [
    "##### Cuándo emplear ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceed9bf",
   "metadata": {},
   "source": [
    "La Prueba de *ANOVA* es apropiada en las siguientes situaciones:\n",
    "\n",
    "- ***Tres o Más Grupos:*** Se utiliza cuando se comparan tres o más grupos independientes. Si solo se están comparando dos grupos, la prueba *t de Student* es más adecuada.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Independencia de las Muestras:*** Los datos de cada grupo deben ser independientes entre sí, y no debe haber relación ni influencia entre los grupos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Distribución Normal:*** Cada grupo debe seguir una distribución normal. Al igual que en la prueba *t*, para tamaños de muestra grandes, el *ANOVA* puede ser robusto ante pequeñas desviaciones de la normalidad debido al *Teorema del Límite Central*.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Homogeneidad de Varianza:*** Los grupos deben tener varianzas aproximadamente iguales. Si las varianzas son significativamente diferentes, podría ser más adecuado utilizar un *ANOVA* con corrección para varianzas desiguales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0738103",
   "metadata": {},
   "source": [
    "##### Proceso de Realización de la Prueba de ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d98896b",
   "metadata": {},
   "source": [
    "A continuación, se presenta un proceso general para llevar a cabo una prueba de ANOVA:\n",
    "\n",
    "- ***Formulación de Hipótesis:***\n",
    "\n",
    "  - ***Hipótesis Nula (H0):*** Las medias de todos los grupos son iguales.\n",
    "  - ***Hipótesis Alternativa (H1):*** Al menos una de las medias de los grupos es diferente.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cálculo de la Variación Total:*** Se calcula la suma total de cuadrados ($SST$) para medir la variación total en los datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cálculo de la Variación Entre Grupos:*** Se calcula la suma de cuadrados entre grupos ($SSG$) para medir la variación entre las medias de los grupos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cálculo de la Variación Dentro de los Grupos:*** Se calcula la suma de cuadrados dentro de los grupos ($SSE$) para medir la variación dentro de cada grupo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cálculo del Estadístico $F$:*** Se calcula el estadístico $F$ utilizando la relación $F = \\frac{SSG / (k-1)}{SSE / (N-k)}$, donde k es el número de grupos y N es el tamaño total de la muestra.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cálculo del Valor p:*** Utilizamos los grados de libertad y el estadístico F para calcular el valor p asociado. Si el valor p es menor que el nivel de significancia ($\\alpha$), rechazamos la hipótesis nula.\n",
    "\n",
    "***Ejemplo:***\n",
    "\n",
    "Supongamos que una empresa de alimentos ha desarrollado tres formulaciones diferentes de un producto y quiere determinar si existe una diferencia significativa en la satisfacción del cliente. Han recopilado muestras aleatorias de $50$ clientes para cada formulación y han medido su satisfacción en una escala del $1$ al $10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e872d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Generar datos de ejemplo\n",
    "np.random.seed(42)\n",
    "formulacion_1 = np.random.randint(5, 10, 50)\n",
    "formulacion_2 = np.random.randint(6, 11, 50)\n",
    "formulacion_3 = np.random.randint(6, 9, 50)\n",
    "\n",
    "# Prueba de ANOVA\n",
    "f_stat, p_valor = f_oneway(formulacion_1, formulacion_2, formulacion_3)\n",
    "\n",
    "print(\"Estadístico F:\", f_stat)\n",
    "print(\"Valor p:\", p_valor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992e782c",
   "metadata": {},
   "source": [
    "En el ejemplo proporcionado y los resultados de la prueba *ANOVA*, la interpretación de estos resultados se basa en la comparación del valor $p$ con un nivel de significancia ($\\alpha$) predefinido (como $0.05$).\n",
    "\n",
    "***Interpretación:***\n",
    "\n",
    "- ***Estadístico F:*** El valor del estadístico $F = 6.2834$. Este valor indica la proporción de la variación entre grupos con respecto a la variación dentro de los grupos. Un valor $F$ mayor sugiere una mayor variación entre grupos en relación con la variación dentro de los grupos.\n",
    "\n",
    "- ***Valor p:*** El valor $p = 0.0024$. El valor $p$ representa la probabilidad de obtener un estadístico de prueba $F$ tan extremo o más extremo que el observado, asumiendo que la hipótesis nula de igualdad de medias es verdadera.\n",
    "\n",
    "***Toma de Decisión:***\n",
    "\n",
    "Para tomar una decisión basada en los resultados de la prueba *ANOVA*, comparamos el valor $p$ con el nivel de significancia $\\alpha$. Si $p < \\alpha (0.05)$ en muchos casos, rechazamos la hipótesis nula y concluimos que al menos uno de los grupos tiene una media significativamente diferente de los demás. Si el valor $p > \\alpha$, no tenemos suficiente evidencia para rechazar la hipótesis nula.\n",
    "\n",
    "En este caso, el valor $p =0.0024$ es considerablemente menor que el nivel de significancia $\\alpha =0.05$. Por lo tanto, podemos concluir que hay suficiente evidencia para rechazar la hipótesis nula y afirmar que al menos un grupo tiene una media significativamente diferente de los demás. En otras palabras, existe una diferencia significativa en la satisfacción del cliente entre al menos dos de las formulaciones de productos evaluadas.\n",
    "\n",
    "***Conclusión:***\n",
    "\n",
    "Basándonos en los resultados de la prueba *ANOVA*, podemos concluir que existe una diferencia significativa en la satisfacción del cliente entre al menos dos de las formulaciones de productos. Este hallazgo puede ser útil para tomar decisiones empresariales informadas, como optimizar la producción o ajustar las estrategias de marketing para las formulaciones específicas que presentan diferencias significativas en la satisfacción del cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c28bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "315.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
