{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca1cb9d",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Analítica de datos para la toma de decisiones empresariales</h1>\n",
    "<h1 align=\"center\">Serie de Tiempo: Pasajeros de avión</h1>\n",
    "<h1 align=\"center\">Centro de Educación Continua</h1>\n",
    "<h1 align=\"center\">EAFIT</h1>\n",
    "<h1 align=\"center\">2023</h1>\n",
    "<h1 align=\"center\">MEDELLÍN - COLOMBIA </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3039e83f",
   "metadata": {},
   "source": [
    "*** \n",
    "|![Gmail](https://img.shields.io/badge/Gmail-D14836?style=plastic&logo=gmail&logoColor=white)|<carlosalvarezh@gmail.com>|![Outlook](https://img.shields.io/badge/Microsoft_Outlook-0078D4?style=plastic&logo=microsoft-outlook&logoColor=white)|<calvar52@eafit.edu.co>|\n",
    "|-:|:-|--:|:--|\n",
    "|[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=plastic&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/carlosalvarez5/)|[![@alvarezhenao](https://img.shields.io/twitter/url/https/twitter.com/alvarezhenao.svg?style=social&label=Follow%20%40alvarezhenao)](https://twitter.com/alvarezhenao)|[![@carlosalvarezh](https://img.shields.io/badge/github-%23121011.svg?style=plastic&logo=github&logoColor=white)](https://github.com/carlosalvarezh)|[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/carlosalvarezh/Curso_CEC_EAFIT/blob/main/Ejemplos_C02_5_TimeSeriesAnalysis.ipynb)|\n",
    "\n",
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/CCLogoColorPop1.gif?raw=true\" width=\"25\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license.(c) Carlos Alberto Alvarez Henao</td>\n",
    "</table>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3516e7",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a58aa",
   "metadata": {},
   "source": [
    "En el mundo empresarial actual, la capacidad de tomar decisiones informadas y estratégicas es esencial para el éxito. Una valiosa herramienta para lograrlo es el análisis de datos de series temporales. En una amplia variedad de sectores, desde finanzas hasta marketing, las organizaciones recopilan información a lo largo del tiempo, como precios de acciones, consumo de energía y métricas de redes sociales. Este tipo de datos pueden revelar patrones, tendencias estacionales y pronósticos futuros que impulsan la generación de ganancias. Por ejemplo, al comprender cómo varía la demanda de productos a lo largo del año, las empresas pueden planificar estratégicamente promociones para optimizar las ventas. En este contexto, exploraremos un enfoque práctico utilizando el método ARIMA para analizar públicamente disponibles datos de pasajeros de aerolíneas en Python. A través de este ejemplo, aprenderemos a descomponer tendencias, identificar patrones y pronosticar eventos futuros, fortaleciendo así nuestras habilidades en la toma de decisiones basadas en datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2e0ed5",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515431d5",
   "metadata": {},
   "source": [
    "Empecemos el ejercicio con la importación de las bibliotecas a trabajar y la lectura de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc76cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "plt.rcParams.update({'figure.figsize': (6, 3), 'figure.dpi': 120})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6653073d",
   "metadata": {},
   "source": [
    "Los datos de una serie temporal normalmente se almacenan en archivos `.csv` u otros formatos de hoja de cálculo y contienen dos columnas: *la fecha* y *el valor medido*.\n",
    "\n",
    "Usaremos `read_csv()` del paquete `pandas` para leer el conjunto de datos de series temporales como un `dataset` de `pandas`. Agregar el argumento `parse_dates=['Month']` hará que la columna de fecha se analice como un campo de fecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d952d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/AirPassengers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bef2f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194e482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7d36c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0906b",
   "metadata": {},
   "source": [
    "Alternativamente, puedes importarlo como una serie de pandas con la fecha como índice. Sólo necesita especificar el argumento `index_col` en `pd.read_csv()` para hacerlo:\n",
    "\n",
    "```python\n",
    "serie = pd.read_csv(\"Data/AirPassengers.csv\", parse_dates=['Month'], index_col='Month')\n",
    "```\n",
    "\n",
    "Se deja como texto para evitar ponerlo en una línea celda ejecutable, ya que puede alterar los resultados del código de este documento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe411d2b",
   "metadata": {},
   "source": [
    " ## Análisis Exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce872b",
   "metadata": {},
   "source": [
    "Vamos a continuar trabajando con el DataFrame `df` creado. Podemos observar que los datos contienen una columna etiquetada como \"*Month*\" que contiene fechas. En esa columna, las fechas están formateadas como año-mes. También vemos que los datos comienzan en enero de $1949$ y van hasta diciembre de $1960$.\n",
    "\n",
    "La segunda columna está etiquetada como \"*#Passangers*\" y contiene el número de pasajeros para el año-mes.\n",
    "\n",
    "Veamos cuántos elementos contiene el dataset y cuántos son no-nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_data = df.isnull()\n",
    "null_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac67bc11",
   "metadata": {},
   "source": [
    "Si el dataset cuenta con valores faltantes y quisiéramos determinar en qué fila se encuentran, podemos ejecutar este código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcc32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_missing_indices = df[df.isna().any(axis=1)].index\n",
    "print(rows_with_missing_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baadda4a",
   "metadata": {},
   "source": [
    "O si lo que necesitamos es saber la posición exacta del elemento nulo, podemos emplear este código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355372ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la posición exacta de los valores nulos\n",
    "rows, cols = np.where(df.isna())\n",
    "\n",
    "# Crear una lista de tuplas con las posiciones\n",
    "null_positions = list(zip(rows, cols))\n",
    "\n",
    "print(null_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a163c78",
   "metadata": {},
   "source": [
    "En donde el primer elemento de la tupla corresponde a la fila y el segundo, a la columna."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085f12d6",
   "metadata": {},
   "source": [
    "Si al cargar los datos hemos obviado el argumento `parse_dates=['Month']`, que transforma la columna *Month* en fechas, lo podremos hacer con el método [`to_datetime()`](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html)  de `Pandas`. Adicionalmente empleamos el argumento `format='%Y-%m'`, para indicar el formato de fecha deseado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df42edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month'] = pd.to_datetime(df['Month'], format='%Y-%m')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a15eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca1cadd",
   "metadata": {},
   "source": [
    "Este proceso automáticamente inserta el primer día de cada mes, lo cual es básicamente un valor ficticio dado que no tenemos datos diarios de pasajeros.\n",
    "\n",
    "Observe también que el tipo de dato cambio de `object` a `datetime64[ns]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c824305e",
   "metadata": {},
   "source": [
    "Grafiquemos los datos del DataFrame utilizando el comando [`lineplot()`](https://seaborn.pydata.org/generated/seaborn.lineplot.html) de `seaborn`, que nos permite visualziar un gráfico de líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642576d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data = df, x=\"Month\", y = \"#Passengers\")\n",
    "plt.ylabel('Number of Passengers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86854a63",
   "metadata": {},
   "source": [
    "Dado que es una serie temporal mensual y sigue un cierto patrón repetitivo cada año, puedes trazar cada año como una línea separada en el mismo gráfico. Esto le permite comparar los patrones anuales uno al lado del otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc59c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cffebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# Prepare data\n",
    "df1['year'] = [d.year for d in df1[\"Month\"]]\n",
    "df1['Month'] = [d.strftime('%b') for d in df1[\"Month\"]]\n",
    "years = df1['year'].unique()\n",
    "\n",
    "# Prep Colors\n",
    "np.random.seed(100)\n",
    "mycolors = np.random.choice(list(mpl.colors.XKCD_COLORS.keys()), len(years), replace=False)\n",
    "\n",
    "# Draw Plot\n",
    "plt.figure(figsize=(10,6), dpi= 80)\n",
    "for i, y in enumerate(years):\n",
    "    if i > 0:        \n",
    "        plt.plot('Month', '#Passengers', data=df1.loc[df1.year==y, :], color=mycolors[i], label=y)\n",
    "        plt.text(df1.loc[df1.year==y, :].shape[0]-.9, df1.loc[df1.year==y, '#Passengers'][-1:].values[0], y, fontsize=12, color=mycolors[i])\n",
    "\n",
    "# Decoration\n",
    "xmin = -0.3\n",
    "xmax = df1['Month'].nunique()\n",
    "ymin = df1['#Passengers'].min()\n",
    "ymax = df1['#Passengers'].max()\n",
    "\n",
    "plt.gca().set(xlim=(xmin, xmax), ylim=(ymin, ymax), ylabel='#Passengers', xlabel='Month')\n",
    "plt.yticks(fontsize=12, alpha=.7)\n",
    "plt.title(\"#Passengers Time Series\", fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec24099",
   "metadata": {},
   "source": [
    "De la gráfica se observa que, a partir de $1954$, se presenta una leve caída en el número de pasajeros el mes de enero, y luego empieza a crecer sostenidamente hasta su máximo en julio, para irse en tendencia decreciente hasta noviembre y volver a subir un poco en diciembre. Este patrón se evidencia que se repite año a año."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db950fd4",
   "metadata": {},
   "source": [
    "***Diagrama de caja de distribución mensual (estacional) y anual (tendencia)***\n",
    "\n",
    "Ahora, agrupemos los datos en intervalos estacionales y ver cómo se distribuyen los valores dentro de un año o mes determinado y cómo se comparan a lo largo del tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872e5625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Draw Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20,7), dpi= 80)\n",
    "sns.boxplot(x='year', y='#Passengers', data=df1, ax=axes[0])\n",
    "sns.boxplot(x='Month', y='#Passengers', data=df1.loc[~df1.year.isin([1991, 2008]), :])\n",
    "\n",
    "# Set Title\n",
    "axes[0].set_title('Year-wise Box Plot\\n(The Trend)', fontsize=18); \n",
    "axes[1].set_title('Month-wise Box Plot\\n(The Seasonality)', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10106b",
   "metadata": {},
   "source": [
    "Los diagramas de caja hacen evidentes las distribuciones anuales y mensuales. Además, viendo en el diagrama de caja mensual, los meses de *junio*, *julio* y *agosto* claramente tienen mayores ventas de pasajes, lo que puede atribuirse a la temporada de vacaciones de verano en el hemisferio norte.\n",
    "\n",
    "Hasta ahora, hemos visto las similitudes para identificar el patrón. Ahora bien, ¿cómo descubrir cualquier desviación del patrón habitual?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca17b1f0",
   "metadata": {},
   "source": [
    "## Análisis de Estacionariedad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a8bbc7",
   "metadata": {},
   "source": [
    "La [estacionariedad](https://en.wikipedia.org/wiki/Stationary_process) es esencial en el análisis de series temporales, indicando que los cambios en los datos a lo largo del tiempo son constantes y no muestran tendencias ni patrones estacionales. Esto facilita la modelización y es un supuesto en muchos métodos de pronóstico. Utilizaremos la prueba [*Dickey Fuller*](https://en.wikipedia.org/wiki/Dickey%E2%80%93Fuller_test) para verificar la estacionariedad en nuestros datos, permitiéndonos aceptar o rechazar la hipótesis de no estacionariedad. Si rechazamos la hipótesis nula, confirmamos la existencia de estacionariedad, lo que es crucial para evaluar cómo los valores actuales se relacionan con los pasados en el conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9e2c9",
   "metadata": {},
   "source": [
    "### Media Móvil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113538cb",
   "metadata": {},
   "source": [
    "La [media móvil](https://en.wikipedia.org/wiki/Moving_average) se calcula como una técnica para suavizar las fluctuaciones en los datos y resaltar las tendencias subyacentes a lo largo del tiempo. Se utiliza en análisis de series temporales para reducir el ruido o variabilidad aleatoria en los datos, lo que facilita la identificación de patrones y tendencias más claras.\n",
    "\n",
    "La idea detrás de la media móvil es tomar un conjunto de valores consecutivos de una serie temporal y calcular su promedio. A medida que avanzamos en el tiempo, se va ajustando la ventana de valores que se promedian, lo que suaviza las fluctuaciones a corto plazo y revela las tendencias a largo plazo.\n",
    "\n",
    "La media móvil es especialmente útil para detectar patrones y tendencias en datos que pueden tener variaciones estacionales, cíclicas o aleatorias. Puede ser una herramienta efectiva para la exploración preliminar de datos y proporcionar una base para el análisis más profundo en el campo de la estadística y el análisis de series temporales.\n",
    "\n",
    "Para el ejemplo, calculemos una media móvil de siete meses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Month', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ee278",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mean = df.rolling(7).mean()\n",
    "rolling_std = df.rolling(7).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30370965",
   "metadata": {},
   "source": [
    "A continuación, vamos a superponer nuestra serie temporal con la media móvil de 7 meses y la desviación estándar móvil de siete meses. En primer lugar, creemos una gráfica utilizando Matplotlib de nuestra serie temporal, junto con la media móvil a 7 meses y su desviación estándar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e8ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df, color=\"blue\",label=\"Original Passenger Data\")\n",
    "plt.plot(rolling_mean, color=\"red\", label=\"Rolling Mean Passenger Number\")\n",
    "plt.plot(rolling_std, color=\"black\", label = \"Rolling Standard Deviation in Passenger Number\")\n",
    "\n",
    "plt.title(\"Passenger Time Series, Rolling Mean, Standard Deviation\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edee321",
   "metadata": {},
   "source": [
    "### Pruebas estadísticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04fc73d",
   "metadata": {},
   "source": [
    "A continuación, importemos la prueba aumentada [Dickey-Fuller](https://en.wikipedia.org/wiki/Dickey%E2%80%93Fuller_test) del paquete statsmodels. La documentación de la prueba se puede encontrar [aquí](https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.adfuller.html). Luego, pasemos nuestro *DataFrame* al método `adfuller`. Aquí, especificamos el parámetro `autolag` como \"`AIC`\", lo que significa que se elige el rezago para minimizar el criterio de información. Finalmente, almacenemos nuestros resultados en un *DataFrame* y lo mostremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7619ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "adft = adfuller(df,autolag=\"AIC\")\n",
    "\n",
    "adftValues = [adft[0],adft[1],adft[2],adft[3], adft[4]['1%'], adft[4]['5%'], adft[4]['10%']]\n",
    "\n",
    "metrics = [\"Test Statistics\",\"p-value\",\"No. of lags used\",\"Number of observations used\",\n",
    "           \"critical value (1%)\", \"critical value (5%)\", \"critical value (10%)\"]\n",
    "\n",
    "output_df = pd.DataFrame({\"Values\": adftValues, \"Metric\": metrics})\n",
    "print(output_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ef32c",
   "metadata": {},
   "source": [
    "Podemos observar que nuestros datos no son estacionarios debido a que nuestro valor $p> 5\\%$ y el estadístico de prueba es mayor al valor crítico. También podemos llegar a estas conclusiones al inspeccionar los datos, ya que podemos ver claramente una tendencia creciente en el número de pasajeros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee12d7",
   "metadata": {},
   "source": [
    "### Autocorrelación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0805fff8",
   "metadata": {},
   "source": [
    "Verificar la [autocorrelación](https://en.wikipedia.org/wiki/Autocorrelation) en los datos de series temporales en Python es otra parte importante del proceso analítico. Esto es una medida de cómo está correlacionada la serie temporal en un punto dado en el tiempo con los valores pasados, lo que tiene implicaciones significativas en diversas industrias. Por ejemplo, si nuestros datos de pasajeros tienen una fuerte autocorrelación, podemos asumir que un alto número de pasajeros hoy sugiere una alta probabilidad de que también sean altos mañana.\n",
    "\n",
    "Pandas tiene un método de autocorrelación que podemos utilizar para calcular la autocorrelación en nuestros datos de pasajeros. Hagámoslo para un rezago de uno, tres, seis y nueve meses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b5ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelation_lag1 = df['#Passengers'].autocorr(lag=1)\n",
    "print(\"One Month Lag: \", autocorrelation_lag1)\n",
    "\n",
    "autocorrelation_lag3 = df['#Passengers'].autocorr(lag=3)\n",
    "print(\"Three Month Lag: \", autocorrelation_lag3)\n",
    "\n",
    "autocorrelation_lag6 = df['#Passengers'].autocorr(lag=6)\n",
    "print(\"Six Month Lag: \", autocorrelation_lag6)\n",
    "\n",
    "autocorrelation_lag9 = df['#Passengers'].autocorr(lag=9)\n",
    "print(\"Nine Month Lag: \", autocorrelation_lag9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.autocorrelation_plot(df['#Passengers'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8769eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plot_acf(df['#Passengers'], lags=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cbe708",
   "metadata": {},
   "source": [
    "Vemos que, incluso con un retraso de nueve meses, los datos presentan una autocorrelación alta. Esto es una evidencia adicional de las tendencias a corto y largo plazo en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6705cda",
   "metadata": {},
   "source": [
    "### Descomposición"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53705e75",
   "metadata": {},
   "source": [
    "La [descomposición de tendencias](https://en.wikipedia.org/wiki/Decomposition_of_time_series) es una técnica utilizada en el análisis de series temporales para separar una serie temporal en sus componentes fundamentales, con el objetivo de comprender mejor la estructura subyacente de los datos. Esta técnica se utiliza para identificar y aislar las tendencias, las estacionalidades y los componentes residuales en una serie de tiempo.\n",
    "\n",
    "A continuación, se explican los tres componentes principales que se buscan en la descomposición de tendencias:\n",
    "\n",
    "1. ***Tendencia:*** La tendencia es la componente de una serie temporal que muestra la dirección general en la que los datos están cambiando a lo largo del tiempo. Puede ser una tendencia ascendente (crecimiento), descendente (decrecimiento) o lateral (sin cambio significativo). La descomposición de tendencias busca separar esta componente para identificar patrones a largo plazo en los datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "2. ***Estacionalidad:*** La estacionalidad es la componente que representa patrones recurrentes y predecibles que ocurren en la serie de tiempo a intervalos regulares. Por ejemplo, las ventas minoristas pueden experimentar un aumento estacional durante las vacaciones cada año. La descomposición de tendencias identifica estos patrones estacionales y los separa de la tendencia general.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "3. ***Residuos:*** Los residuos son la parte de la serie de tiempo que no se puede explicar mediante la tendencia y la estacionalidad. Representan la variabilidad no sistemática o aleatoria en los datos. Los residuos son importantes porque pueden contener información sobre eventos impredecibles o cambios no modelados en la serie temporal.\n",
    "\n",
    "La descomposición de tendencias se puede realizar utilizando diversos métodos, siendo dos de los más comunes:\n",
    "\n",
    "- ***Método aditivo:*** En este enfoque, se considera que la serie temporal es la suma de la tendencia, la estacionalidad y los residuos. La descomposición implica restar la tendencia y la estacionalidad a los datos originales para obtener los residuos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Método multiplicativo:*** En este enfoque, se considera que la serie temporal es el producto de la tendencia, la estacionalidad y los residuos. La descomposición implica dividir los datos originales por la tendencia y la estacionalidad para obtener los residuos.\n",
    "\n",
    "Una vez que se ha realizado la descomposición de tendencias, los analistas de series temporales pueden examinar cada componente por separado para comprender mejor las tendencias a largo plazo, los patrones estacionales y la variabilidad no sistemática en los datos. Esto es útil para la predicción y el modelado de series temporales, ya que permite abordar cada componente de manera individual y aplicar técnicas específicas a cada uno de ellos.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Para continuar, importemos `seasonal_decompose` del paquete `statsmodels`. Pasemos nuestro *DataFrame* al método `season_decompose` y grafiquemos el resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efda1c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decompose_add = seasonal_decompose(df['#Passengers'],model='additive', period=7)\n",
    "plt.rcParams.update({'figure.figsize': (10,5)})\n",
    "decompose_add.plot().suptitle('Additive Decompose', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5c260a",
   "metadata": {},
   "source": [
    "El código que se acaba de ejecutar se utiliza para realizar primero la descomposición estacional aditivaen una serie de tiempo contenida en un DataFrame de Pandas llamado `df`. Aquí está la explicación de cada parte del código:\n",
    "\n",
    "- `seasonal_decompose`: Este es un método que se utiliza para realizar la descomposición estacional de una serie de tiempo. Es parte de la biblioteca de Python llamada `statsmodels`. El método `seasonal_decompose` toma como entrada la serie de tiempo que se desea descomponer y varios parámetros para controlar el proceso de descomposición.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- `df['#Passengers']`: Aquí se accede a la columna llamada `#Passengers` en el DataFrame `df`. Se asume que esta columna contiene la serie de tiempo que deseas descomponer.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- `model='additive'`: Este parámetro especifica el tipo de modelo que se utilizará para la descomposición estacional. En este caso, se está utilizando el modelo aditivo, lo que significa que se asume que la serie de tiempo es la suma de la tendencia, la estacionalidad y los residuos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- `period=7`: Este parámetro indica el período de estacionalidad en la serie de tiempo. En este caso, se establece en 7, lo que sugiere que hay un patrón estacional que se repite cada 7 observaciones. Esto podría significar que estás trabajando con datos diarios y esperas una estacionalidad semanal.\n",
    "\n",
    "Después de ejecutar este código, la variable `decompose` contendrá un objeto que contiene la descomposición de la serie de tiempo en sus componentes principales, que son:\n",
    "\n",
    "- `decompose.trend`: La componente de tendencia, que representa la dirección general de los datos a lo largo del tiempo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- `decompose.seasonal`: La componente estacional, que muestra los patrones que se repiten a lo largo de un período determinado (en este caso, 7).\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- `decompose.resid`: Los residuos, que representan la variabilidad no sistemática o aleatoria en los datos.\n",
    "\n",
    "Se puede acceder a cada uno de estos componentes a través del objeto `decompose` para analizarlos o visualizarlos por separado. Esta descomposición puede ser útil para comprender mejor la estructura de la serie de tiempo y facilitar el modelado y la predicción de datos futuros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2597815f",
   "metadata": {},
   "source": [
    "La versión de la descomposición multiplicativa se muestra a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93124fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "decompose_mul = seasonal_decompose(df['#Passengers'],model='multiplicative', period=7)\n",
    "plt.rcParams.update({'figure.figsize': (10,5)})\n",
    "decompose_mul.plot().suptitle('Multiplicative Decompose', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773bfd3a",
   "metadata": {},
   "source": [
    "### Pronóstico (Forecasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca00b4e",
   "metadata": {},
   "source": [
    "El [pronóstico de series temporales](https://en.wikipedia.org/wiki/Time_series) nos permite predecir valores futuros en una serie temporal dada la información actual y pasada. Aquí, utilizaremos el método [ARIMA](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average) para pronosticar el número de pasajeros, lo que nos permitirá pronosticar valores futuros en función de una combinación lineal de valores pasados. Utilizaremos el paquete `auto_arima`, lo que nos evitará el proceso de ajuste de hiperparámetros que consume mucho tiempo.\n",
    "\n",
    "Primero, dividamos nuestros datos para entrenamiento y prueba, y visualicemos la división:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c36284",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = df.index\n",
    "train = df[df['Date'] < pd.to_datetime(\"1960-08\", format='%Y-%m')]\n",
    "train['train'] = train['#Passengers']\n",
    "del train['Date']\n",
    "del train['#Passengers']\n",
    "test = df[df['Date'] >= pd.to_datetime(\"1960-08\", format='%Y-%m')]\n",
    "del test['Date']\n",
    "test['test'] = test['#Passengers']\n",
    "del test['#Passengers']\n",
    "plt.plot(train, color = \"black\")\n",
    "plt.plot(test, color = \"red\")\n",
    "plt.title(\"Train/Test split for Passenger Data\")\n",
    "plt.ylabel(\"Passenger Number\")\n",
    "plt.xlabel('Year-Month')\n",
    "plt.grid(True)\n",
    "sns.set()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad238d",
   "metadata": {},
   "source": [
    "La línea negra corresponde a nuestros datos de entrenamiento (`train`) y la línea roja corresponde a nuestros datos de prueba (`test`).\n",
    "\n",
    "Importemos `auto_arima` del paquete `pdmarima`, entrenemos nuestro modelo y generemos predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57ec619",
   "metadata": {},
   "source": [
    "<div class=\"alert alert alert-success\">\n",
    "$\\color{red}{\\textbf{Nota:}}$ Si es la primera vez que se va a ejecutar este paquete en su sistema (computador), debes instalarlo ejecutando la siguiente celda. Una vez instalado, no será necesario volverla a ejecutar, ni tampoco en ningún otro proyecto (notebook) que use este computador:\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3487708",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c75c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.arima import auto_arima\n",
    "model = auto_arima(train, trace=True, error_action='ignore', suppress_warnings=True)\n",
    "model.fit(train)\n",
    "forecast = model.predict(n_periods=len(test))\n",
    "forecast = pd.DataFrame(forecast,index = test.index,columns=['Prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b273b",
   "metadata": {},
   "source": [
    "Ahora, grafiquemos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f798b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train, label='Train')\n",
    "plt.plot(test, label='Test')\n",
    "plt.plot(forecast, label='Prediction')\n",
    "plt.title('#Passenger Prediction')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Actual #Passenger')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46977e2",
   "metadata": {},
   "source": [
    "Nuestras predicciones se muestran en verde y los valores reales se muestran en naranja.\n",
    "\n",
    "Finalmente, calculemos el error cuadrático medio (RMSE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ecc451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rms = sqrt(mean_squared_error(test,forecast))\n",
    "print(\"RMSE: \", rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e7b6e",
   "metadata": {},
   "source": [
    "Un valor de *RMSE* (*Root Mean Square Error*) de $64.4816^*$ indica la raíz del promedio de los errores al cuadrado entre los valores pronosticados y los valores reales en un conjunto de datos. Es una medida de la diferencia entre los valores pronosticados y los valores observados en una serie temporal. Cuanto menor sea el valor del RMSE, mejor será el ajuste del modelo a los datos observados.\n",
    "\n",
    "En este contexto, un *RMSE* de $64.4816^*$ significa que, en promedio, los pronósticos del modelo difieren en alrededor de $64.4816^*$ unidades de la variable objetivo (en este caso, el número de pasajeros) de los valores reales en el conjunto de datos. Es importante interpretar este valor en relación con la escala de la variable y el contexto específico de la aplicación. Un *RMSE* más bajo indica que el modelo está haciendo predicciones más precisas y cercanas a los valores reales.\n",
    "\n",
    "($^*$Este valor cambia cada vez que hacemos una nueva predicción)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e86d2",
   "metadata": {},
   "source": [
    "### Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad1444",
   "metadata": {},
   "source": [
    "El análisis de datos de series temporales desempeña un papel fundamental. Este análisis es una tarea que enfrentarán casi todos los profesionales en su carrera, y comprender las herramientas y métodos adecuados puede capacitar a los participantes para descubrir tendencias, anticipar eventos y, por ende, influir en la toma de decisiones estratégicas. A través de la comprensión de patrones estacionales mediante conceptos como estacionariedad, autocorrelación y descomposición de tendencias, se puede orientar la planificación de promociones a lo largo del año, mejorando así los resultados financieros de las empresas. Por último, la capacidad de prever eventos futuros mediante pronósticos de series temporales se convierte en una herramienta poderosa para guiar la toma de decisiones empresariales. Estos análisis se vuelven invaluables para cualquier profesional o equipo que busque aportar un valor significativo a sus organizaciones a través de la interpretación y aplicación de datos de series temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b2b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
