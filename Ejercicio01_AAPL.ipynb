{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5903ccc9",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Analítica de datos para la toma de decisiones empresariales</h1>\n",
    "<h1 align=\"center\">Ejercicio: Analysis - Apple Stock</h1>\n",
    "<h1 align=\"center\">Centro de Educación Continua</h1>\n",
    "<h1 align=\"center\">EAFIT</h1>\n",
    "<h1 align=\"center\">2023</h1>\n",
    "<h1 align=\"center\">MEDELLÍN - COLOMBIA </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf41231",
   "metadata": {},
   "source": [
    "*** \n",
    "|![Gmail](https://img.shields.io/badge/Gmail-D14836?style=plastic&logo=gmail&logoColor=white)|<carlosalvarezh@gmail.com>|![Outlook](https://img.shields.io/badge/Microsoft_Outlook-0078D4?style=plastic&logo=microsoft-outlook&logoColor=white)|<calvar52@eafit.edu.co>|\n",
    "|-:|:-|--:|:--|\n",
    "|[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=plastic&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/carlosalvarez5/)|[![@alvarezhenao](https://img.shields.io/twitter/url/https/twitter.com/alvarezhenao.svg?style=social&label=Follow%20%40alvarezhenao)](https://twitter.com/alvarezhenao)|[![@carlosalvarezh](https://img.shields.io/badge/github-%23121011.svg?style=plastic&logo=github&logoColor=white)](https://github.com/carlosalvarezh)|[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/carlosalvarezh/Curso_CEC_EAFIT/blob/main/Ejercicio01_AAPL.ipynb)|\n",
    "\n",
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/CCLogoColorPop1.gif?raw=true\" width=\"25\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license.(c) Carlos Alberto Alvarez Henao</td>\n",
    "</table>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062d833f",
   "metadata": {},
   "source": [
    "## Contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b315c44",
   "metadata": {},
   "source": [
    "Apple Inc. (AAPL) es una empresa tecnológica multinacional estadounidense que se especializa en electrónica de consumo, software de computadora y servicios en línea. Apple es la empresa tecnológica más grande del mundo en términos de ingresos (totalizando $\\$274.5$ mil millones en $2020$) y, desde enero de 2021, la empresa más valiosa del mundo. Hasta el año 2021, Apple es el cuarto mayor vendedor de computadoras personales del mundo por ventas unitarias y el cuarto fabricante de teléfonos inteligentes más grande. Es una de las cinco grandes empresas de tecnología de la información estadounidenses, junto con Amazon, Google, Microsoft y Facebook.\n",
    "\n",
    "Los datos utilizados en este proyecto consisten en los precios históricos de las acciones de AAPL obtenidos a través de Yahoo Finance. El conjunto de datos contiene las siguientes variables: `Date` (diciembre de 1980 - agosto de 2022), `Open`, `High`, `Low`, `Close`, `Adj Close` y `Volume`, donde:\n",
    "\n",
    "- `Date` - Fecha para la cual se proporciona el precio\n",
    "- `Open` - Precio de la acción al inicio del mercado (en USD)\n",
    "- `High` - Precio más alto alcanzado en el día\n",
    "- `Low` - Precio más bajo alcanzado en el día\n",
    "- `Close` - Precio de cierre del día\n",
    "- `Adj Close` - \n",
    "- `Volume` - Número de acciones negociadas\n",
    "\n",
    "El dataset se puede descargar de [esta página de kaggle](https://www.kaggle.com/datasets/meetnagadia/apple-stock-price-from-19802021/code). El archivo se descarga como un archivo comprido en formato [.rar](https://www.win-rar.com/) el que hay qué descomprimir. Una vez descomprimido en la carpeta de trabajo, el archivo tendrá como nombre: `AAPL.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2349a8",
   "metadata": {},
   "source": [
    "## Análisis exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1256802b",
   "metadata": {},
   "source": [
    "### Análisis exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2371f6c8",
   "metadata": {},
   "source": [
    "En este cuaderno, se llevará a cabo la limpieza y preprocesamiento de un conjunto de datos del mercado de valores. El objetivo es preparar los datos para su análisis y visualización posteriores, marcando el primer paso en una serie de análisis sobre el mercado de valores. Los datos depurados se utilizarán en cuadernos futuros para el análisis exploratorio de datos y la modelización.\n",
    "\n",
    "Se emplearán diversas técnicas, como la normalización *Z-score* para tratar valores extremos y la imputación de datos faltantes para manejar valores ausentes. Además, se eliminarán columnas innecesarias y se renombrarán otras para mejorar la legibilidad de los datos. Al concluir el proceso, se dispondrá de un conjunto de datos limpios y listos para usar en fases posteriores del análisis del mercado de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d6031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importa bibliotecas de trabajo\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe1863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga archivo de datos\n",
    "df = pd.read_csv(\"Data/AAPL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51285301",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#muestra los primeros 5 y los últimos 5 registros del DF\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d698812d",
   "metadata": {},
   "source": [
    "Ahora veamos la información general del `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# información general del DF\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520acf39",
   "metadata": {},
   "source": [
    "De aquí se observa que el `df` tiene en total $10468$ filas y $7$ columnas y no se tienen datos no-nulos.\n",
    "\n",
    "Otra forma de determinar la cantidad de datos nulos en un `DataFrame` es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4005a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# devuelve valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f6c0f",
   "metadata": {},
   "source": [
    "Veamos también si hay registros duplicados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca815fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f117c1cf",
   "metadata": {},
   "source": [
    "Obsérvese que a la columna `Date`, python no la identifica como un tipo de dato reconocido, por eso le asigna el tipo `object`. Vamos a convertir los valores de dicha columna a tipo `datetime64` para ser reconocido por `pandas` como un formato de fecha válido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9403945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ad6a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d8df03",
   "metadata": {},
   "source": [
    "Ahora veamos algunos estadísticos básicos del `df` con la función `describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beebad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticos básicos del DF\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ffdeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking\n",
    "(df.isnull().sum()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e93b6ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Si hubieran datos nulos o filas, se eliminarían\n",
    "df_u = df.dropna(how=\"all\")\n",
    "df_u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734b6566",
   "metadata": {},
   "source": [
    "### Cálculo de Estadísticos básicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473da1d5",
   "metadata": {},
   "source": [
    "A continuación, se calcularan los estadísticos de las medidas de tendencia central (media, mediana y moda), indicadores de dispersión (desviación estándar, rango y varianza) y de forma (asimetría y curtosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f2387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular medidas de tendencia central\n",
    "mean_close = np.mean(df['Close'])\n",
    "median_close = np.median(df['Close'])\n",
    "mode_close = df['Close'].mode()[0]\n",
    "\n",
    "# Resultados del análisis\n",
    "print(\"Medidas de Tendencia Central:\")\n",
    "print(f\"Media: {mean_close}\")\n",
    "print(f\"Mediana: {median_close}\")\n",
    "print(f\"Moda: {mode_close}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d88a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular indicadores de dispersión\n",
    "std_close = np.std(df['Close'])\n",
    "range_close = np.max(df['Close']) - np.min(df['Close'])\n",
    "variance_close = np.var(df['Close'])\n",
    "\n",
    "print(\"\\nIndicadores de Dispersión:\")\n",
    "print(f\"Desviación Estándar: {std_close}\")\n",
    "print(f\"Rango: {range_close}\")\n",
    "print(f\"Varianza: {variance_close}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e30051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular indicadores de forma\n",
    "skewness_close = df['Close'].skew()\n",
    "kurtosis_close = df['Close'].kurtosis()\n",
    "\n",
    "print(\"\\nIndicadores de Forma:\")\n",
    "print(f\"Asimetría (Skewness): {skewness_close}\")\n",
    "print(f\"Curtosis: {kurtosis_close}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a0100b",
   "metadata": {},
   "source": [
    "Basándonos en los resultados de los estadísticos calculados, podemos sacar varias conclusiones sobre la distribución de los datos que estás analizando:\n",
    "\n",
    "1. **Medidas de Tendencia Central:**\n",
    "   - La media ($14.76$) nos da una idea del valor promedio de los datos. Sin embargo, debido a la alta desviación estándar y la presencia de valores atípicos (inducidos por la alta asimetría), la media puede no ser representativa de la mayoría de los datos.   \n",
    "   - La mediana ($0.4754$) está significativamente más cerca del extremo inferior de la escala en comparación con la media. Esto también sugiere una posible presencia de valores atípicos en el extremo superior que están sesgando la media.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "2. **Indicadores de Dispersión:**\n",
    "   - La desviación estándar ($31.93$) es bastante alta en relación con la media. Esto indica una gran variabilidad en los datos, lo que puede ser influenciado por la presencia de valores atípicos.\n",
    "   - El rango ($181.96$) es la diferencia entre el valor máximo y mínimo. Un rango grande también sugiere una amplia dispersión en los datos, nuevamente posiblemente debido a valores atípicos.\n",
    "   - La varianza ($1019.39$) es una medida de la dispersión al cuadrado. Su valor alto refuerza la idea de que los datos tienen una gran variabilidad.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "3. **Indicadores de Forma:**\n",
    "   - La asimetría (*skewness*) positiva ($3.15$) indica que la distribución tiene una cola larga hacia la derecha y los valores extremos positivos están más dispersos. Esto respalda la observación de valores atípicos en el extremo superior.\n",
    "   - La curtosis ($10.06$) es mayor de lo esperado en una distribución normal. Esto sugiere que la distribución tiene colas pesadas, lo que nuevamente indica la presencia de valores atípicos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "En resumen, los datos muestran una distribución con una asimetría positiva significativa, lo que sugiere una concentración de valores más bajos y una dispersión más amplia de valores más altos. Además, los valores atípicos en el extremo superior están influyendo en gran medida en los indicadores, como la media y la varianza. Es importante considerar estos valores atípicos al interpretar la distribución y resumir sus características. Además, la distribución no se asemeja a una distribución normal debido a la asimetría y la curtosis observadas.\n",
    "\n",
    "Los resultados de los estadísticos nos plantean algunas ideas de cómo podría ser la distribución de los datos, pero por sí solos, no nos permite tomar ninguna decisión. Apoyémonos entonces en algunos gráficos para complementar la información:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ec97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de un histograma\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['Close'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('Histograma de Precios de Cierre')\n",
    "plt.xlabel('Precio de Cierre')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70585620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los gráficos en una cuadrícula\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 12))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "# Histograma\n",
    "axes[0, 0].hist(df['Close'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Histograma de Precios de Cierre')\n",
    "axes[0, 0].set_xlabel('Precio de Cierre')\n",
    "axes[0, 0].set_ylabel('Frecuencia')\n",
    "\n",
    "# Gráfico de dispersión\n",
    "axes[0, 1].scatter(df.index, df['Close'], alpha=0.5)\n",
    "axes[0, 1].set_title('Gráfico de Dispersión de Precios de Cierre')\n",
    "axes[0, 1].set_xlabel('Índice')\n",
    "axes[0, 1].set_ylabel('Precio de Cierre')\n",
    "\n",
    "# Gráfico de línea\n",
    "axes[0, 2].plot(df['Date'], df['Close'], color='blue')\n",
    "axes[0, 2].set_title('Gráfico de Línea de Precios de Cierre')\n",
    "axes[0, 2].set_xlabel('Año')\n",
    "axes[0, 2].set_ylabel('Precio de Cierre')\n",
    "axes[0, 2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(df['Close'], ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Boxplot de Precios de Cierre')\n",
    "axes[1, 0].set_xlabel('Precio de Cierre')\n",
    "\n",
    "# Violin plot\n",
    "sns.violinplot(df['Close'], ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Violin Plot de Precios de Cierre')\n",
    "axes[1, 1].set_xlabel('Precio de Cierre')\n",
    "\n",
    "# Eliminar el espacio vacío del último subplot\n",
    "fig.delaxes(axes[1, 2])\n",
    "\n",
    "# Mostrar todos los gráficos\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8c45eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Date'], df['Close'], alpha=0.5)\n",
    "plt.title('Gráfico de Dispersión de Precios de Cierre')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Precio de Cierre')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f314a72",
   "metadata": {},
   "source": [
    "Los gráficos muestran unas tendencias que van acorde a los resultados obtenidos con los estadísticos. Se observa que desde 1980 a 2010 (aproximadamente) se presenta una tendencia casi horizontal, mientras que, a partir de ese año, el valor de la variable 'Precio de Cierre' aumenta de forma acelerada. \n",
    "\n",
    "Esto nos lleva a pensar que quizás no sea buena idea hacer un análisis de datos con fechas tan diferentes: Muchas situaciones sociales, políticas, económicas, han sucedido a lo largo de todo este periodo de tiempo. Con esto, consideramos que sería más conveniente reducir el intervalo de tiempo a partir del 2015 y centrarnos en el comportamiento de los datos a partir de esa fecha.\n",
    "\n",
    "Empecemos con el filtrado de datos desde el 2015 hasta el 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32306a9d",
   "metadata": {},
   "source": [
    "### Filtrado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ae2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtra datos en un rango de fechas específico [1990/01/01, 1999/12/31]\n",
    "\n",
    "#data_filtered = df[(df['Date'] >= '1990-01-01') & (df['Date'] <= '1999-12-31')]\n",
    "\n",
    "# Filtrar los datos desde 2015 hasta 2022\n",
    "data_filtered = df[df['Date'] >= '2015-01-01']\n",
    "\n",
    "plt.scatter(data_filtered['Date'], data_filtered['Close'],marker='.', s=2, alpha=0.5)\n",
    "plt.title('Gráfico de Dispersión de Precios de Cierre')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Precio de Cierre')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8785abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular medidas de tendencia central\n",
    "mean_close = np.mean(data_filtered['Close'])\n",
    "median_close = np.median(data_filtered['Close'])\n",
    "mode_close = data_filtered['Close'].mode()[0]\n",
    "\n",
    "# Resultados del análisis\n",
    "print(\"Medidas de Tendencia Central:\")\n",
    "print(f\"Media: {mean_close}\")\n",
    "print(f\"Mediana: {median_close}\")\n",
    "print(f\"Moda: {mode_close}\")\n",
    "\n",
    "# Calcular indicadores de dispersión\n",
    "std_close = np.std(data_filtered['Close'])\n",
    "range_close = np.max(data_filtered['Close']) - np.min(data_filtered['Close'])\n",
    "variance_close = np.var(data_filtered['Close'])\n",
    "\n",
    "print(\"\\nIndicadores de Dispersión:\")\n",
    "print(f\"Desviación Estándar: {std_close}\")\n",
    "print(f\"Rango: {range_close}\")\n",
    "print(f\"Varianza: {variance_close}\")\n",
    "\n",
    "# Calcular indicadores de forma\n",
    "skewness_close = data_filtered['Close'].skew()\n",
    "kurtosis_close = data_filtered['Close'].kurtosis()\n",
    "\n",
    "print(\"\\nIndicadores de Forma:\")\n",
    "print(f\"Asimetría (Skewness): {skewness_close}\")\n",
    "print(f\"Curtosis: {kurtosis_close}\")\n",
    "\n",
    "# Visualización de un histograma\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data_filtered['Close'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('Histograma de Precios de Cierre')\n",
    "plt.xlabel('Precio de Cierre')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c51b36",
   "metadata": {},
   "source": [
    "En resumen, los datos filtrados a partir de 2015 muestran una distribución que podría estar sesgada hacia la derecha debido a valores atípicos o una asimetría positiva. La variabilidad en los datos es notable, como se refleja en la desviación estándar y el rango. La curtosis negativa sugiere que la distribución tiene menos valores atípicos extremos en comparación con una distribución normal. Sería importante investigar más a fondo la causa de la asimetría y los valores atípicos para comprender mejor la naturaleza de los datos.\n",
    "\n",
    "Ahora calculemos los valores de los estadísticos a partir del año 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e40cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar una columna 'Year' para facilitar el análisis\n",
    "data_filtered['Year'] = pd.to_datetime(data_filtered['Date']).dt.year\n",
    "\n",
    "# Calcular indicadores año a año\n",
    "years = data_filtered['Year'].unique()\n",
    "indicators = ['Mean', 'Std Dev', 'Range', 'Median', 'Skewness', 'Kurtosis']\n",
    "indicator_values = {indicator: [] for indicator in indicators}\n",
    "\n",
    "for year in years:\n",
    "    year_data = data_filtered[data_filtered['Year'] == year]\n",
    "    \n",
    "    mean_close = year_data['Close'].mean()\n",
    "    std_close = year_data['Close'].std()\n",
    "    range_close = year_data['Close'].max() - year_data['Close'].min()\n",
    "    median_close = year_data['Close'].median()\n",
    "    skewness_close = year_data['Close'].skew()\n",
    "    kurtosis_close = year_data['Close'].kurtosis()\n",
    "    \n",
    "    indicator_values['Mean'].append(mean_close)\n",
    "    indicator_values['Std Dev'].append(std_close)\n",
    "    indicator_values['Range'].append(range_close)\n",
    "    indicator_values['Median'].append(median_close)\n",
    "    indicator_values['Skewness'].append(skewness_close)\n",
    "    indicator_values['Kurtosis'].append(kurtosis_close)\n",
    "\n",
    "# Crear un DataFrame para los indicadores\n",
    "indicators_df = pd.DataFrame(indicator_values, index=years)\n",
    "\n",
    "# Mostrar los resultados en una tabla\n",
    "print(indicators_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7caab79",
   "metadata": {},
   "source": [
    "Y realicemos algunas gráficas para visualizar los resultados en estos años:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa6af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de Líneas para comparar los indicadores año a año\n",
    "indicators_df.plot(kind='line', figsize=(12, 6))\n",
    "plt.title('Comparación de Indicadores Año a Año')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Valor del Indicador')\n",
    "plt.xticks(years)\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f1c806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogramas año a año\n",
    "\n",
    "# Crear histogramas en subplots\n",
    "years = data_filtered['Year'].unique()\n",
    "num_years = len(years)\n",
    "\n",
    "# Calcular las filas y columnas necesarias para los subplots\n",
    "num_rows = (num_years + 1) // 2  # Redondear hacia arriba en caso de número impar\n",
    "num_cols = 2\n",
    "\n",
    "# Crear la figura y subplots\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(6, 3 * num_rows))\n",
    "fig.suptitle('Histogramas de Precios de Cierre por Año', y=1.02)\n",
    "\n",
    "# Iterar a través de los años y crear los histogramas en subplots\n",
    "for i, year in enumerate(years):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    \n",
    "    year_data = data_filtered[data_filtered['Year'] == year]\n",
    "    axs[row, col].hist(year_data['Close'], bins=20, edgecolor='black', alpha=0.7)\n",
    "    axs[row, col].set_title(f'Año {year}')\n",
    "    axs[row, col].set_xlabel('Precio de Cierre')\n",
    "    axs[row, col].set_ylabel('Frecuencia')\n",
    "\n",
    "# Ajustar el espaciado entre subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar la figura con los subplots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cca5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear boxplots por año\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Year', y='Close', data=data_filtered)\n",
    "plt.title('Boxplots de Precios de Cierre por Año')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Precio de Cierre')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057c4090",
   "metadata": {},
   "source": [
    "### Detección de Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ad538d",
   "metadata": {},
   "source": [
    "Ahora, estamos interesados en determinar cuántos posibles outliers se detectan desde el 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista para almacenar los resultados de los outliers\n",
    "outliers_results = []\n",
    "\n",
    "# Detectar outliers por año\n",
    "years = data_filtered['Year'].unique()\n",
    "for year in years:\n",
    "    year_data = data_filtered[data_filtered['Year'] == year]\n",
    "    \n",
    "    Q1 = year_data['Close'].quantile(0.25)\n",
    "    Q3 = year_data['Close'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = year_data[(year_data['Close'] < lower_limit) | (year_data['Close'] > upper_limit)]\n",
    "    \n",
    "    outliers_results.append({\n",
    "        'Year': year,\n",
    "        'Num Outliers': len(outliers),\n",
    "        'Outliers': ', '.join(map(str, outliers['Close'].tolist()))\n",
    "    })\n",
    "\n",
    "# Crear un DataFrame con los resultados de los outliers\n",
    "outliers_df = pd.DataFrame(outliers_results)\n",
    "\n",
    "# Mostrar los resultados en forma de tabla\n",
    "print(outliers_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c931d6ee",
   "metadata": {},
   "source": [
    "El resultado proporcionado muestra la cantidad de outliers detectados en cada año y también enumera los valores específicos que se identificaron como outliers en ciertos años. Un outlier es un valor que se desvía significativamente del resto de los valores en un conjunto de datos y puede indicar situaciones excepcionales o errores en la medición.\n",
    "\n",
    "Análisis del resultado:\n",
    "\n",
    "1. **Años con 0 outliers:**\n",
    "   Los años 2015, 2016, 2017, 2018, 2020 y 2022 no tienen valores considerados como outliers. Esto podría indicar que los datos en estos años son más consistentes y no presentan valores extremadamente diferentes del resto.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "2. **Años con outliers:**\n",
    "   - En 2019, se identificaron 7 outliers. Esto sugiere que en ese año hubo algunos valores inusuales que se desviaron significativamente del patrón general de los datos.\n",
    "   - En 2021, se encontraron 5 outliers. Esto indica que también hubo algunos valores atípicos que se apartaron del comportamiento típico de los datos en ese año.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "3. **Análisis de valores outliers:**\n",
    "   Observando los valores específicos listados como outliers, podrías querer investigar más a fondo para entender por qué se consideraron atípicos. ¿Fueron errores de entrada, eventos inusuales o hay una razón legítima detrás de estos valores extremos?\n",
    "\n",
    "En general, el análisis de outliers te proporciona información sobre la variabilidad y distribución de tus datos. Puedes usar esta información para comprender mejor la naturaleza de los datos en diferentes años y tomar decisiones informadas sobre cómo manejar esos valores atípicos, ya sea eliminándolos si son errores o considerándolos si son indicativos de situaciones especiales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9930e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Crear una lista para almacenar los resultados de los outliers\n",
    "outliers_results = []\n",
    "\n",
    "# Detectar outliers por año\n",
    "years = data_filtered['Year'].unique()\n",
    "\n",
    "# Configurar subplots\n",
    "fig, axes = plt.subplots(len(years), 2, figsize=(12, 6 * len(years)))\n",
    "fig.tight_layout(pad=4.0)\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    year_data = data_filtered[data_filtered['Year'] == year]\n",
    "    year_data['Month'] = year_data['Date'].dt.month\n",
    "    \n",
    "    Q1 = year_data['Close'].quantile(0.25)\n",
    "    Q3 = year_data['Close'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = year_data[(year_data['Close'] < lower_limit) | (year_data['Close'] > upper_limit)]\n",
    "    \n",
    "    outliers_results.append({\n",
    "        'Year': year,\n",
    "        'Num Outliers': len(outliers),\n",
    "        'Outliers': ', '.join(map(str, outliers['Close'].tolist()))\n",
    "    })\n",
    "    \n",
    "    # Gráfico de Línea\n",
    "    ax1 = axes[i, 0]\n",
    "    sns.lineplot(data=year_data, x='Date', y='Close', ax=ax1)\n",
    "    ax1.set_title(f'Precio de Cierre - Año {year}')\n",
    "    ax1.set_xlabel('Fecha')\n",
    "    ax1.set_ylabel('Precio de Cierre')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Boxplot\n",
    "    ax2 = axes[i, 1]\n",
    "    sns.boxplot(x=year_data['Month'], y=year_data['Close'], ax=ax2)\n",
    "    ax2.set_title(f'Boxplot - Precio de Cierre por Mes en Año {year}')\n",
    "    ax2.set_xlabel('Mes')\n",
    "    ax2.set_ylabel('Precio de Cierre')\n",
    "    ax2.set_xticks(year_data['Month'].unique() - 1)\n",
    "    ax2.set_xticklabels([str(month) for month in year_data['Month'].unique()])\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Crear un DataFrame con los resultados de los outliers\n",
    "outliers_df = pd.DataFrame(outliers_results)\n",
    "\n",
    "# Mostrar los resultados en forma de tabla\n",
    "print(outliers_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc3860",
   "metadata": {},
   "source": [
    "### Análisis de Normalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288c3e11",
   "metadata": {},
   "source": [
    "A continuación, deseamos realizar un análisis de normalidad de los datos, empleando las prubas de *Shapiro-Wilk* y *Anderson-Darling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69cc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Filtrar los datos desde 2015 hasta 2022\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "filtered_data = df[df['Date'] >= '2015-01-01']\n",
    "\n",
    "# Agregar una columna 'Year' para facilitar el análisis\n",
    "filtered_data['Year'] = filtered_data['Date'].dt.year\n",
    "\n",
    "# Crear una lista para almacenar los resultados de normalidad\n",
    "normality_results = []\n",
    "\n",
    "# Realizar análisis de normalidad por año\n",
    "years = filtered_data['Year'].unique()\n",
    "\n",
    "for year in years:\n",
    "    year_data = filtered_data[filtered_data['Year'] == year]['Close']\n",
    "    \n",
    "    # Realizar la prueba de Shapiro-Wilk\n",
    "    shapiro_stat, shapiro_pvalue = stats.shapiro(year_data)\n",
    "    \n",
    "    # Realizar la prueba de Anderson-Darling\n",
    "    anderson_stat, anderson_critical_values, anderson_significance = stats.anderson(year_data)\n",
    "    \n",
    "    normality_results.append({\n",
    "        'Year': year,\n",
    "        'Shapiro-Wilk p-value': shapiro_pvalue,\n",
    "        'Anderson-Darling Statistic': anderson_stat,\n",
    "        'Anderson-Darling Critical Values': anderson_critical_values,\n",
    "        'Anderson-Darling Significance Level': anderson_significance\n",
    "    })\n",
    "\n",
    "# Crear un DataFrame con los resultados de normalidad\n",
    "normality_df = pd.DataFrame(normality_results)\n",
    "\n",
    "# Mostrar los resultados en forma de tabla\n",
    "print(normality_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21647045",
   "metadata": {},
   "source": [
    "De estos resultados, podríamos indicar las siguientes conclusiones:\n",
    "\n",
    "1. **Shapiro-Wilk $p$-value:** Este valor $p$ indica la probabilidad de que los datos sigan una distribución normal. Cuanto más pequeño sea el valor $p$, más evidencia tendrás para rechazar la hipótesis nula de normalidad. En este caso, todos los valores $p$ son extremadamente pequeños, lo que sugiere que los datos no siguen una distribución normal en ningún año.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "2. **Anderson-Darling Statistic y Critical Values:** El estadístico de *Anderson-Darling* se compara con los valores críticos para determinar si los datos siguen una distribución normal. Si el estadístico es mayor que los valores críticos, la hipótesis nula de normalidad es rechazada. En todos los años, el estadístico es mayor que los valores críticos, lo que sugiere que los datos no son normales.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "3. **Anderson-Darling Significance Level:** Estos son los niveles de significancia asociados con los valores críticos. Un nivel de significancia más bajo indica una mayor confianza en el rechazo de la hipótesis nula de normalidad. En todos los años, los niveles de significancia son bastante bajos, respaldando la conclusión de que los datos no son normales.\n",
    "\n",
    "En resumen, los resultados indican que los datos de los precios de cierre de Apple (AAPL) no siguen una distribución normal en ningún año analizado (2015-2022). Esto podría sugerir que la suposición de normalidad podría no ser adecuada para realizar análisis estadísticos que asumen esta distribución, y podrías considerar enfoques más robustos o no paramétricos para el análisis de estos datos. Es importante tener en cuenta que los precios de las acciones a menudo no siguen distribuciones normales debido a la naturaleza volátil de los mercados financieros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb298ad",
   "metadata": {},
   "source": [
    "###  Pruebas de hipótesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2915b297",
   "metadata": {},
   "source": [
    "Vamos a realizar algunas pruebas y análisis sobre los datos de los precios de cierre de Apple (AAPL) para los años 2015-2022. Dado que los datos no siguen una distribución normal según los análisis previos, utilizaremos métodos no paramétricos para realizar las pruebas. Vamos a realizar las siguientes tareas:\n",
    "\n",
    "Estimación Puntual y Intervalo de Confianza de la Mediana.\n",
    "Prueba de Hipótesis No Paramétrica (Mann-Whitney U) para comparar dos años.\n",
    "Visualización de los datos mediante Boxplots y Gráficos de Distribución.\n",
    "Primero, instalaremos las bibliotecas necesarias y luego procederemos con las tareas mencionadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a926f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_data = df[df['Date'] >= '2015-01-01']\n",
    "\n",
    "# Agregar una columna 'Year' para facilitar el análisis\n",
    "filtered_data['Year'] = filtered_data['Date'].dt.year\n",
    "\n",
    "# Estimación puntual y intervalo de confianza de la mediana\n",
    "median_estimates = filtered_data.groupby('Year')['Close'].median()\n",
    "confidence_intervals = filtered_data.groupby('Year')['Close'].apply(lambda x: stats.t.interval(0.95, len(x)-1, loc=np.mean(x), scale=stats.sem(x)))\n",
    "\n",
    "# Prueba de Mann-Whitney U para comparar dos años\n",
    "year_2020_data = filtered_data[filtered_data['Year'] == 2020]['Close']\n",
    "year_2021_data = filtered_data[filtered_data['Year'] == 2021]['Close']\n",
    "mwu_statistic, mwu_pvalue = stats.mannwhitneyu(year_2020_data, year_2021_data, alternative='two-sided')\n",
    "\n",
    "# Visualización de los datos\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=filtered_data, x='Year', y='Close')\n",
    "plt.title('Boxplot de los Precios de Cierre por Año')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Precio de Cierre')\n",
    "plt.show()\n",
    "\n",
    "# Gráficos de Distribución para los años 2020 y 2021\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(year_2020_data, label='2020')\n",
    "sns.kdeplot(year_2021_data, label='2021')\n",
    "plt.title('Distribución de los Precios de Cierre en 2020 y 2021')\n",
    "plt.xlabel('Precio de Cierre')\n",
    "plt.ylabel('Densidad')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Estimación Puntual de la Mediana por Año:\\n\", median_estimates)\n",
    "print(\"\\nIntervalos de Confianza de la Mediana por Año:\\n\", confidence_intervals)\n",
    "print(\"\\nResultado de la Prueba de Mann-Whitney U:\")\n",
    "print(\"Estadístico de Prueba:\", mwu_statistic)\n",
    "print(\"Valor p:\", mwu_pvalue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cf8bd7",
   "metadata": {},
   "source": [
    "Aquí hay algunas conclusiones y análisis que podemos extraer de los resultados:\n",
    "\n",
    "1. **Estimación Puntual de la Mediana por Año:** La mediana es una medida robusta de tendencia central que no se ve afectada por valores atípicos. Podemos observar que la mediana de los precios de cierre tiende a aumentar a medida que avanzan los años, lo que sugiere un posible aumento general en los precios en el período 2015-2022.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "2. **Intervalos de Confianza de la Mediana por Año:** Los intervalos de confianza de la mediana nos proporcionan un rango de valores donde es probable que caiga la mediana real de los precios de cierre con un 95% de confianza. A medida que avanzan los años, los intervalos de confianza se vuelven más estrechos, lo que sugiere una mayor precisión en la estimación de la mediana a medida que tenemos más datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "3. **Prueba de Mann-Whitney U:** La prueba de Mann-Whitney U es una prueba no paramétrica que se utiliza para comparar las distribuciones de dos grupos independientes. El valor p extremadamente bajo (cercano a cero) sugiere que hay una diferencia estadísticamente significativa entre los precios de cierre en los años 2020 y 2021. Dado que el valor p es muy bajo, podemos rechazar la hipótesis nula de que las distribuciones son iguales.\n",
    "\n",
    "En resumen, los análisis sugieren un aumento general en los precios de cierre a lo largo de los años y una diferencia significativa en los precios entre los años 2020 y 2021. Estos hallazgos podrían relacionarse con la tendencia general del mercado y los posibles efectos de la pandemia en 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f14d862",
   "metadata": {},
   "source": [
    "## Modelos de predicción y pronóstico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33535cf1",
   "metadata": {},
   "source": [
    "El análisis de visualización de datos utilizando diagramas de dispersión puede ser muy útil para identificar relaciones o patrones entre diferentes variables. En el conjunto de datos, podríamos considerar crear diagramas de dispersión utilizando la variable \"Close\" (precio de cierre) en combinación con otras variables como \"Open\", \"High\", \"Low\" y \"Volume\". Esto permitirá explorar posibles relaciones entre el precio de cierre y otras métricas relacionadas con las acciones de Apple.\n",
    "\n",
    "Aquí hay algunos ejemplos de cómo podrías realizar este análisis utilizando diagramas de dispersión:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a60f36f",
   "metadata": {},
   "source": [
    "### Precio de Cierre vs. Volumen de Acciones Negociadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa03530",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=filtered_data, x='Volume', y='Close')\n",
    "plt.title('Diagrama de Dispersión: Precio de Cierre vs. Volumen')\n",
    "plt.xlabel('Volumen de Acciones Negociadas')\n",
    "plt.ylabel('Precio de Cierre')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f25b21",
   "metadata": {},
   "source": [
    "### Precio de Cierre vs. Precio de Apertura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=filtered_data, x='Open', y='Close')\n",
    "plt.title('Diagrama de Dispersión: Precio de Cierre vs. Precio de Apertura')\n",
    "plt.xlabel('Precio de Apertura')\n",
    "plt.ylabel('Precio de Cierre')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d69d5",
   "metadata": {},
   "source": [
    "### Precio de Cierre vs. Precio Más Alto y Precio Más Bajo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5567e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=filtered_data, x='High', y='Close', label='Precio Más Alto')\n",
    "sns.scatterplot(data=filtered_data, x='Low', y='Close', label='Precio Más Bajo')\n",
    "plt.title('Diagrama de Dispersión: Precio de Cierre vs. Precio Más Alto y Más Bajo')\n",
    "plt.xlabel('Precios')\n",
    "plt.ylabel('Precio de Cierre')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22beffe6",
   "metadata": {},
   "source": [
    "Estos son solo ejemplos de cómo podríamos crear diagramas de dispersión para explorar posibles relaciones. Los diagramas de dispersión nos ayudarán a identificar si existe alguna correlación o tendencia entre las variables. También podríamos explorar diagramas de dispersión para otros pares de variables para obtener una comprensión más completa de los datos.\n",
    "\n",
    "Recuerda que, si deseáramos analizar específicamente el efecto de la pandemia (2020), podríamos considerar la inclusión de una variable categórica que indique si el año es 2020 o no, y crear diagramas de dispersión comparando el comportamiento de los precios de cierre en ese año en particular con los otros años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6949a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una variable categórica para indicar si el año es 2020\n",
    "filtered_data['Is2020'] = filtered_data['Year'] == 2020\n",
    "\n",
    "# Diagrama de dispersión comparando precios de cierre en 2020 vs otros años\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=filtered_data, x='Is2020', y='Close')\n",
    "plt.title('Diagrama de Dispersión: Precio de Cierre en 2020 vs Otros Años')\n",
    "plt.xticks([0, 1], ['No 2020', '2020'])\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Precio de Cierre')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed700a",
   "metadata": {},
   "source": [
    "La gráfica compara los precios de cierre en el año 2020 con los precios de cierre en los otros años (no 2020). Aquí una posible interpretación:\n",
    "\n",
    "- ***Eje $x$ (Año):*** El eje $x$ tiene dos categorías: *\"No 2020\"* y *\"2020\"*. Estas categorías representan los dos grupos de datos que estamos comparando.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Eje $y$ (Precio de Cierre):*** El eje $y$ representa el precio de cierre de las acciones de Apple. Los puntos en la gráfica representan los precios de cierre en cada año.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***\"No 2020\" (Años no 2020):*** Los puntos en esta categoría corresponden a los años que no son $2020$. Note que hay un \"hueco\" en los datos del precio de cierre entre aproximadamente $80$ y $120$. Esto indica que en esos años, los precios de cierre no se encontraban en ese rango.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***\"2020\" (Año 2020)***: Los puntos en esta categoría corresponden al año $2020$. Los datos se concentran más entre los valores de precios de cierre entre $60$ y $140$, con un pequeño vacío alrededor del valor de precio de cierre $100$. Esto sugiere que durante el año $2020$, los precios de cierre variaron más en comparación con los otros años y hubo un período en el que los precios se mantuvieron relativamente estables alrededor de $100$.\n",
    "\n",
    "En resumen, la gráfica está mostrando cómo se comparan los precios de cierre en el año $2020$ con los precios en otros años. Los patrones que observas, como los vacíos y las concentraciones de puntos, pueden indicar diferencias en la distribución de los precios de cierre entre los dos grupos ($2020$ y *no* $2020$). Puede ser interesante explorar más detalles y estadísticas para comprender mejor las diferencias observadas en la gráfica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f1351a",
   "metadata": {},
   "source": [
    "### Técnicas estadísticas para la medición de información compartida e indicadores de dependencia (Correlaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a591835e",
   "metadata": {},
   "source": [
    "Para medir la información compartida y los indicadores de dependencia entre las diferentes variables y los años (incluyendo el año $2020$ con la pandemia), podemos calcular las correlaciones entre las variables. En el conjunto de datos, tenemos varias variables como `Open`, `High`, `Low`, `Close` y `Volume`. Vamos a calcular la matriz de correlación y presentarla en forma de tabla y también generaremos un mapa de calor para visualizar las correlaciones de manera gráfica.\n",
    "\n",
    "Aquí presentamos el código para realizar estas tareas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e03070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la matriz de correlación\n",
    "correlation_matrix = filtered_data[['Open', 'High', 'Low', 'Close', 'Volume']].corr()\n",
    "\n",
    "# Crear un mapa de calor de las correlaciones\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Mapa de Calor de Correlaciones entre Variables')\n",
    "plt.show()\n",
    "\n",
    "# Mostrar la tabla de correlaciones\n",
    "print(\"Matriz de Correlación:\")\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd5d2ac",
   "metadata": {},
   "source": [
    "Los resultados de la matriz de correlación indican las relaciones entre las diferentes variables en tu conjunto de datos. Aquí hay algunas observaciones importantes:\n",
    "\n",
    "- **Variables de Precio (Open, High, Low, Close):** Las variables de precio (`Open`, `High`, `Low`, `Close`) tienen una correlación muy alta entre sí. Esto era de esperarse, ya que todas estas métricas están relacionadas con los precios de las acciones en diferentes momentos del día. La correlación cercana a $1$ indica que estas variables están altamente correlacionadas, lo que sugiere que si una variable aumenta, es probable que las demás también aumenten en la misma dirección.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Volume (Volumen):** La variable `Volume` tiene correlaciones negativas moderadas con las variables de precio. Esto sugiere que a medida que el precio sube, el volumen tiende a disminuir, y viceversa. Esta relación puede deberse a la naturaleza de cómo los inversores reaccionan ante los movimientos de precio.\n",
    "\n",
    "El mapa de calor y los valores de correlación de la tabla confirman estas observaciones. La alta correlación entre las variables de precio es un indicativo de su fuerte dependencia, mientras que la correlación negativa con el volumen sugiere una relación inversa entre el volumen de negociación y los movimientos de precio.\n",
    "\n",
    "En general, estas correlaciones muestran patrones típicos en los datos de acciones, donde las métricas de precio suelen estar relacionadas y el volumen puede tener una relación inversa con los precios. Es importante considerar que la correlación no implica causalidad, por lo que estos análisis proporcionan información sobre las relaciones estadísticas, pero no necesariamente sobre las causas subyacentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955aef76",
   "metadata": {},
   "source": [
    "### Indicadores de correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffc2758",
   "metadata": {},
   "source": [
    "Para calcular los indicadores de correlación de *Pearson*, *Spearman* y *Kendall* entre las variables en el conjunto de datos, podemos utilizar las funciones correspondientes de la librería `scipy.stats`. A continuación presentamos el código para realizar estos cálculos y mostrar los resultados en una tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b232e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "# Calcular las correlaciones\n",
    "correlation_methods = ['pearson', 'spearman', 'kendall']\n",
    "variables = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "correlation_table = []\n",
    "\n",
    "# Llenar la lista de resultados\n",
    "for var1 in variables:\n",
    "    for var2 in variables:\n",
    "        row = {'Variable 1': var1, 'Variable 2': var2}\n",
    "        for method in correlation_methods:\n",
    "            correlation_matrix = filtered_data[[var1, var2]].corr(method=method)\n",
    "            row[method] = correlation_matrix.iloc[0, 1]\n",
    "        correlation_table.append(row)\n",
    "\n",
    "# Crear el DataFrame a partir de la lista de diccionarios\n",
    "correlation_df = pd.DataFrame(correlation_table)\n",
    "\n",
    "# Mostrar la tabla de resultados\n",
    "print(correlation_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9414d3d",
   "metadata": {},
   "source": [
    "Estos resultados de correlación muestran cómo diferentes variables se relacionan entre sí utilizando diferentes métodos de correlación (*Pearson*, *Spearman* y *Kendall*). Aquí hay algunas observaciones que podemos hacer basándonos en estos resultados:\n",
    "\n",
    "- ***Pearson vs. Spearman y Kendall:*** La correlación de *Pearson* mide la relación lineal entre las variables, mientras que *Spearman* y *Kendall* miden las relaciones de clasificación (monótonas) y no dependen de la linealidad. Si las correlaciones *Pearson*, *Spearman* y *Kendall* son similares en magnitud y signo, esto sugiere una fuerte relación entre las variables.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Correlaciones positivas y negativas:*** Las correlaciones cercanas a $1$ (positivas) o $-1$ (negativas) indican una fuerte relación entre las variables. Por ejemplo, `High` y `Low` tienen correlaciones cercanas a $1$ en todos los métodos, lo que sugiere una relación muy fuerte.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Volumen y otras variables:*** Las correlaciones entre `Volume` y otras variables son en su mayoría negativas, lo que sugiere que hay una relación inversa entre el volumen de negociación y los precios de las acciones. Esto podría ser interesante de analizar más a fondo.\n",
    "\n",
    "Dado que se tienen varias combinaciones de variables, una forma efectiva de visualizar estas correlaciones podría ser utilizando un mapa de calor (`heatmap`). Un mapa de calor permite visualizar fácilmente las correlaciones en función de los colores, donde los colores más oscuros indican una correlación más fuerte. Aquí tienes un ejemplo de cómo crear un mapa de calor utilizando la biblioteca `Seaborn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una matriz de correlaciones para las variables numéricas\n",
    "correlation_matrix = correlation_df.pivot(index='Variable 1', columns='Variable 2', values='pearson')\n",
    "\n",
    "# Crear un mapa de calor\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Matriz de Correlación (Pearson)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189a8c5",
   "metadata": {},
   "source": [
    "### Análisis de regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf911e6a",
   "metadata": {},
   "source": [
    "El análisis de regresión lineal nos permite entender cómo una variable (variable dependiente) se relaciona con una o más variables predictoras (variables independientes). Aquí vamos a realizar una serie de análisis de regresión lineal para cada una de las variables del conjunto de datos en función de las otras variables. Utilizaremos la biblioteca `statsmodels` para realizar estos análisis.\n",
    "\n",
    "Aquí tienes el código para realizar el análisis de regresión lineal para cada variable en términos de las otras variables. Este código calcula los coeficientes y los valores p para cada variable predictora en términos de la variable objetivo (`Openp`, `High`, `Low`, `Close` o `Volume`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2eb375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Variables predictoras\n",
    "predictors = ['Open', 'High', 'Low', 'Volume']\n",
    "\n",
    "# Realizar el análisis de regresión lineal para cada variable\n",
    "regression_results = []\n",
    "\n",
    "for target in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "    row = {'Target Variable': target}\n",
    "    for predictor in predictors:\n",
    "        X = sm.add_constant(filtered_data[predictor])\n",
    "        y = filtered_data[target]\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        row[predictor + ' Coef'] = model.params[predictor]\n",
    "        row[predictor + ' P-value'] = model.pvalues[predictor]\n",
    "    regression_results.append(row)\n",
    "\n",
    "# Crear un DataFrame con los resultados\n",
    "regression_df = pd.DataFrame(regression_results)\n",
    "\n",
    "# Mostrar la tabla de resultados\n",
    "print(regression_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9364354f",
   "metadata": {},
   "source": [
    "Los resultados de los coeficientes y los valores p obtenidos del análisis de regresión lineal ofrecen información sobre cómo las variables predictoras (`Open`, `High`, `Low` y `Volume`) están relacionadas con las variables objetivo (`Open`, `High`, `Low`, `Close` y `Volume`). Aquí hay algunas interpretaciones de los resultados:\n",
    "\n",
    "- ***Coeficientes***: Los coeficientes indican cómo cambia la variable objetivo por unidad de cambio en la variable predictora correspondiente, manteniendo constantes las otras variables. Por ejemplo, en la primera fila, el coeficiente para `Open` es aproximadamente $1$. Esto significa que un aumento de una unidad en la variable `Open` se asocia con un aumento aproximado de $1$ en la variable objetivo `Open`. Para las otras variables, los coeficientes son cercanos a $1$, lo que sugiere una relación positiva fuerte.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Valores p***: Los valores $p$ indican la significancia estadística de los coeficientes estimados. Un valor $p$ bajo (generalmente menor que $0.05$) sugiere que el coeficiente es estadísticamente significativo, lo que significa que la variable predictora tiene un efecto significativo sobre la variable objetivo. En todos los casos, los valores $p$ son prácticamente cero, lo que indica que todas las relaciones son estadísticamente significativas.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Efectos de las variables predictoras***: Los coeficientes sugieren cómo se relacionan las variables predictoras con las variables objetivo. Por ejemplo, para `Open` y `High`, los coeficientes son cercanos a $1$, lo que sugiere una relación directa y proporcional. Sin embargo, para `Low`, los coeficientes son un poco más bajos que $1$, lo que sugiere una relación inversa pero aún fuerte. Para `Volume`, los coeficientes son negativos y muy bajos en magnitud, lo que indica que hay una relación débil y negativa entre `Volume` y las otras variables.\n",
    "\n",
    "En resumen, estos resultados sugieren que las variables predictoras están fuertemente relacionadas con las variables objetivo y que sus efectos son estadísticamente significativos. El análisis de regresión lineal proporciona una comprensión cuantitativa de cómo estas variables se influyen mutuamente. Sin embargo, hay qué tener en cuenta que estos resultados asumen relaciones lineales entre las variables, lo que puede no ser completamente válido en todos los casos.\n",
    "\n",
    "En cuanto a los valores negativos y bajos en magnitud para `Volume`, esto puede deberse a que el volumen de negociación puede tener una relación más compleja y no lineal con los precios de las acciones. También podría sugerir que el volumen de negociación no es un predictor fuerte de los precios de las acciones en este modelo lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938fcc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el gráfico de dispersión con la línea de regresión\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Open', y='Close', data=filtered_data)\n",
    "sns.regplot(x='Open', y='Close', data=filtered_data, scatter=False, color='red')\n",
    "plt.title('Regresión Lineal: Close vs Open')\n",
    "plt.xlabel('Open')\n",
    "plt.ylabel('Close')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce31097",
   "metadata": {},
   "source": [
    "También podemos visualizar todas las diferentes relaciones que tienen cada variable con las otras, haciendo una matriz de gráficos de regresión.\n",
    "\n",
    "Crear una matriz de gráficos de regresión para cada combinación de variables puede ser un poco complicado debido a la cantidad de variables involucradas. Sin embargo, podemos generar gráficos de dispersión y líneas de regresión para cada combinación de variables predictoras y variables objetivo por separado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07765612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las variables predictoras\n",
    "predictor_vars = ['Open', 'High', 'Low', 'Volume']\n",
    "\n",
    "# Definir las variables objetivo\n",
    "target_vars = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "# Crear una matriz de subplots para los gráficos de regresión\n",
    "num_rows = len(target_vars)\n",
    "num_cols = len(predictor_vars)\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n",
    "fig.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "\n",
    "for i, target_var in enumerate(target_vars):\n",
    "    for j, predictor_var in enumerate(predictor_vars):\n",
    "        ax = axes[i, j]\n",
    "        sns.regplot(data=filtered_data, x=predictor_var, y=target_var, ax=ax, scatter_kws={'s': 10},\n",
    "                    line_kws={'color': 'red'})  # Agregar la línea de regresión roja\n",
    "        ax.set_title(f'Regresión de {target_var} vs {predictor_var}')\n",
    "        ax.set_xlabel(predictor_var)\n",
    "        ax.set_ylabel(target_var)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58c776d",
   "metadata": {},
   "source": [
    "El área sombreada que se observan en algunas gráficas de regresión indica el intervalo de confianza de la regresión. En otras palabras, muestra el rango en el que es probable que caigan los valores reales de la variable dependiente (en este caso, la variable objetivo) para un valor dado de la variable independiente (en este caso, la variable predictora), considerando la incertidumbre en el modelo de regresión.\n",
    "\n",
    "El sombreado es más amplio en las zonas donde hay menos datos o mayor variabilidad, y más estrecho donde hay más datos o menor variabilidad. Esto ayuda a comprender la confiabilidad de la regresión en diferentes rangos de los predictores.\n",
    "\n",
    "Para mostrar la línea de tendencia en color rojo, se usa el parámetro `line_kws` en la función `regplot` para especificar propiedades de la línea de regresión, como el color."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0a5e9f",
   "metadata": {},
   "source": [
    "### Análisis de regresión lineal múltiple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a0b01",
   "metadata": {},
   "source": [
    "El análisis de regresión lineal múltiple implica considerar más de una variable predictora para predecir una variable objetivo. En este caso, se puede realizar un análisis de regresión lineal múltiple utilizando todas las variables predictoras (`Open`, `High`, `Low` y `Volume`) para predecir la variable objetivo (`Close`). A continuación se presenta el código para llevar a cabo este análisis utilizando la biblioteca `statsmodels`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f288f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Definir las variables predictoras\n",
    "predictor_vars = ['Open', 'High', 'Low', 'Volume']\n",
    "\n",
    "# Definir la variable objetivo\n",
    "target_var = 'Close'\n",
    "\n",
    "# Agregar una columna de constantes para el intercepto\n",
    "filtered_data.loc[:,'Intercept'] = 1\n",
    "\n",
    "# Crear el modelo de regresión lineal múltiple\n",
    "X = filtered_data[['Intercept'] + predictor_vars]\n",
    "y = filtered_data[target_var]\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Obtener los resultados del modelo\n",
    "summary = model.summary()\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46c774b",
   "metadata": {},
   "source": [
    "Los resultados del análisis de regresión lineal múltiple muestran los coeficientes estimados para cada variable predictoras (`Open`, `High`, `Low`, `Volume`) y el término de intercepto. Aquí hay algunas interpretaciones clave de los resultados:\n",
    "\n",
    "- ***Coeficientes y P-valores:*** Los coeficientes indican cómo cambia la variable objetivo (`Close`) por cada unidad de cambio en las variables predictoras. Los $p$-valores evalúan si los coeficientes son estadísticamente significativos. En este caso, todos los coeficientes de las variables predictoras (`Open`, `High`, `Low`) son significativos, lo que sugiere que estas variables influyen en el valor de la variable `Close`.\n",
    "<p>&nbsp;</p>\n",
    "- ***Intercepto:*** El coeficiente del intercepto ($0.0828$) no es estadísticamente significativo ($p$-valor de $0.098$). Esto significa que el valor del intercepto no es significativamente diferente de cero. En términos prácticos, el valor del intercepto no tiene una interpretación clara en este contexto.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***R-squared y Adj. R-squared:*** Estos valores indican cuánta varianza en la variable objetivo se explica por el modelo de regresión. Un valor de $R-cuadrado$ de $1.000$ significa que el modelo explica el $100\\%$ de la variabilidad de la variable objetivo. Sin embargo, este resultado extremadamente alto puede indicar un problema de sobreajuste, especialmente dado que se están utilizando las mismas variables como predictoras y objetivo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Prob (F-statistic):*** Este valor es el $p$-valor asociado al estadístico $F$, que evalúa si al menos una de las variables predictoras es significativamente útil para predecir la variable objetivo. Un valor muy bajo (cercano a cero) indica que al menos una de las variables predictoras es útil en el modelo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Omnibus, Jarque-Bera y Kurtosis:*** Estas estadísticas evalúan la normalidad de los residuos y la simetría de la distribución. En este caso, el valor $p$ bajo en *Omnibus* y el alto valor en *Jarque-Bera* indican que los residuos no siguen una distribución normal. El valor alto de la *kurtosis* sugiere que la distribución de los residuos es más pesada en las colas que la distribución normal.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Cond. No.:*** Esta estadística evalúa la multicolinealidad en el modelo. Un valor alto puede indicar que hay fuerte multicolinealidad entre las variables predictoras. En este caso, el valor de la condición es alto, lo que sugiere que podría haber multicolinealidad en el modelo.\n",
    "\n",
    "En resumen, los resultados sugieren que las variables predictoras (`Open`, `High`, `Low`) son útiles para predecir la variable objetivo (`Close`). Sin embargo, el modelo podría estar sobreajustando los datos debido a que se están utilizando las mismas variables como predictoras y objetivo. Es importante realizar una evaluación más detallada de los supuestos del modelo y considerar opciones para mejorar su validez y utilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca705d",
   "metadata": {},
   "source": [
    "### Métodos estadísticos de selección de variables importantes e identificación de información redundante. (validación y significancia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3ccc39",
   "metadata": {},
   "source": [
    "A continuación se presente el código para realizar pruebas estadísticas y selección de características en un problema de regresió utilizando las bibliotecas `scikit-learn` y `SciPy`, junto con el uso de métodos de selección de características como `SelectKBest` y `SelectPercentile`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530780c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_regression\n",
    "\n",
    "# Supongamos que 'filtered_data' es tu DataFrame con los datos filtrados\n",
    "\n",
    "# Variables predictoras y variable objetivo\n",
    "numeric_features = ['Open', 'High', 'Low', 'Volume']\n",
    "target_variable = 'Close'\n",
    "\n",
    "# Calcular las estadísticas de correlación\n",
    "correlation_matrix = filtered_data[numeric_features + [target_variable]].corr()\n",
    "\n",
    "# Calcular las pruebas de correlación usando f_regression\n",
    "f_scores, f_pvalues = f_regression(filtered_data[numeric_features], filtered_data[target_variable])\n",
    "\n",
    "# Crear un DataFrame para almacenar los resultados\n",
    "results = pd.DataFrame({\n",
    "    'Variable': numeric_features,\n",
    "    'F Score': f_scores,\n",
    "    'F P-value': f_pvalues,\n",
    "})\n",
    "\n",
    "# Seleccionar características con SelectKBest\n",
    "kbest_selector = SelectKBest(score_func=f_regression, k=2)\n",
    "kbest_selector.fit(filtered_data[numeric_features], filtered_data[target_variable])\n",
    "kbest_features = np.array(numeric_features)[kbest_selector.get_support()]\n",
    "\n",
    "# Seleccionar características con SelectPercentile\n",
    "percentile_selector = SelectPercentile(score_func=f_regression, percentile=50)\n",
    "percentile_selector.fit(filtered_data[numeric_features], filtered_data[target_variable])\n",
    "percentile_features = np.array(numeric_features)[percentile_selector.get_support()]\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Resultados de las pruebas estadísticas de correlación:\")\n",
    "print(results)\n",
    "\n",
    "print(\"\\nCaracterísticas seleccionadas por SelectKBest:\", kbest_features)\n",
    "print(\"Características seleccionadas por SelectPercentile:\", percentile_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4c00c",
   "metadata": {},
   "source": [
    "Los resultados indican que:\n",
    "\n",
    "- Las variables `High` y `Low` tienen una correlación más fuerte con la variable objetivo `Close` en comparación con las otras variables (`Open` y `Volume`). Esto se basa en los valores del puntaje $F$ y los $p$-valores obtenidos de las pruebas estadísticas de correlación.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Tanto el método `SelectKBest` como `SelectPercentile` seleccionaron las mismas características `High` y `Low`. Esto significa que ambas pruebas coinciden en que estas dos variables son las más relevantes para predecir la variable objetivo `Close`.\n",
    "\n",
    "En resumen, podrías concluir que en este conjunto de datos, las variables `High` y `Low` tienen una fuerte relación con la variable `Close`, y estas características pueden ser las más importantes para explicar las variaciones en el precio de cierre.\n",
    "\n",
    "Dado que las características seleccionadas son las mismas, ya sea utilizando el método `SelectKBest` o `SelectPercentile`, es un buen indicio de que estas características tienen un impacto significativo en la variable objetivo y podrían ser útiles para construir un modelo de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba84e2",
   "metadata": {},
   "source": [
    "### Validación y Significancia de Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deecc11c",
   "metadata": {},
   "source": [
    "En este ejemplo, utilizaremos los métodos de *selección de características* y *validación cruzada* para determinar qué variables son más importantes y cómo afectan al rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432679ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Cargar los datos y preprocesar si es necesario\n",
    "# Aquí asumiré que ya tienes tus datos cargados en un DataFrame llamado \"data\"\n",
    "# y que las columnas de interés son 'Open', 'High', 'Low', y 'Volume' para predecir 'Close'\n",
    "X = filtered_data[['Open', 'High', 'Low', 'Volume']]\n",
    "y = filtered_data['Close']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit del modelo en el conjunto de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calcular el error en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Realizar selección de características utilizando SelectKBest\n",
    "k_best = SelectKBest(score_func=f_regression, k=2)\n",
    "X_train_k_best = k_best.fit_transform(X_train, y_train)\n",
    "selected_features = np.array(X.columns)[k_best.get_support()]\n",
    "print(f\"Características seleccionadas por SelectKBest: {selected_features}\")\n",
    "\n",
    "# Ahora, realiza validación cruzada con diferentes números de características seleccionadas\n",
    "for num_features in range(1, len(X.columns) + 1):\n",
    "    k_best = SelectKBest(score_func=f_regression, k=num_features)\n",
    "    X_train_k_best = k_best.fit_transform(X_train, y_train)\n",
    "    \n",
    "    model.fit(X_train_k_best, y_train)\n",
    "    X_test_k_best = k_best.transform(X_test)\n",
    "    \n",
    "    y_pred = model.predict(X_test_k_best)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"MSE con {num_features} características: {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bd37ed",
   "metadata": {},
   "source": [
    "El análisis de resultados se puede realizar de la siguiente manera:\n",
    "\n",
    "- ***Mean Squared Error (MSE) Original***: El valor del *MSE* original ($0.3777$) representa el error cuadrático medio del modelo de regresión lineal utilizando todas las características disponibles (`Open`, `High`, `Low`, `Volume`) para predecir el valor de cierre (`Close`). Este valor nos da una referencia del rendimiento del modelo inicial.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Características Seleccionadas por SelectKBest***: El método *SelectKBest* seleccionó las características `High` y `Low` como las más importantes para predecir el valor de cierre. Esto indica que estas dos características tienen una mayor relación con la variable objetivo `Close` en comparación con las otras características.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***MSE con Diferentes Números de Características***: Al realizar la validación cruzada con diferentes números de características seleccionadas, podemos observar cómo cambia el *MSE*. En general, parece que el *MSE* disminuye al aumentar el número de características seleccionadas hasta un punto (3 características), luego comienza a aumentar nuevamente (4 características). Esto podría indicar que incluir las tres características `High`, `Low` y `Volume` ofrece el mejor equilibrio entre precisión y complejidad del modelo.\n",
    "\n",
    "En resumen, el análisis sugiere que las características `High` y `Low` son las más importantes para predecir el valor de cierre, y usar estas dos características junto con `Volume` podría ser una buena elección para lograr un modelo con un rendimiento aceptable. Sin embargo, agregar más características puede no necesariamente mejorar la precisión del modelo y podría aumentar la complejidad innecesariamente. Esto resalta la importancia de realizar pruebas y evaluaciones detalladas para encontrar el conjunto óptimo de características para el modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
