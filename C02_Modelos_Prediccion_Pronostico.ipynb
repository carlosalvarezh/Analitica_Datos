{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b795f7e",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Analítica de datos para la toma de decisiones empresariales</h1>\n",
    "<h1 align=\"center\">Modelos de predicción y pronóstico</h1>\n",
    "<h1 align=\"center\">Centro de Educación Continua</h1>\n",
    "<h1 align=\"center\">EAFIT</h1>\n",
    "<h1 align=\"center\">2023</h1>\n",
    "<h1 align=\"center\">MEDELLÍN - COLOMBIA </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51899269",
   "metadata": {},
   "source": [
    "*** \n",
    "***Docente:*** Carlos Alberto Álvarez Henao, I.C. D.Sc.\n",
    "\n",
    "***e-mail:*** calvar52@eafit.edu.co | carlosalvarezh@gmail.com\n",
    "\n",
    "***Linkedin:*** https://www.linkedin.com/in/carlosalvarez5/\n",
    "\n",
    "***github:*** https://github.com/carlosalvarezh/\n",
    "\n",
    "***Herramienta:*** [Jupyter Notebook](http://jupyter.org/) | [GoogleColab](https://colab.research.google.com/)\n",
    "\n",
    "***Kernel:*** Python 3.11\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3889f408",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://github.com/carlosalvarezh/CFD_Applied/blob/master/figs/CC-BY.png?raw=true\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license.(c) Carlos Alberto Alvarez Henao</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed3217",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/C03_04_Meme.jpg?raw=true\" width=\"250\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc05a1f3",
   "metadata": {},
   "source": [
    "## Visualización de datos y variables con información compartida (Diagrama de dispersión)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4dd619",
   "metadata": {},
   "source": [
    "### Definición y Conceptos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff339e1f",
   "metadata": {},
   "source": [
    "#### Diagrama de Dispersión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20e1eec",
   "metadata": {},
   "source": [
    "Un [diagrama de dispersión](https://en.wikipedia.org/wiki/Scatter_plot), también conocido como gráfico de dispersión o scatter plot, es una representación gráfica que utiliza puntos para mostrar la relación entre dos variables. Cada punto en el gráfico representa una observación en los datos y se coloca en coordenadas definidas por los valores de las dos variables. Esta visualización nos permite identificar patrones, tendencias, correlaciones y posibles valores atípicos en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31585fb",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd2aca",
   "metadata": {},
   "source": [
    "Las variables son atributos o características que se miden o registran en un conjunto de datos. En un diagrama de dispersión, tenemos dos tipos de variables:\n",
    "\n",
    "- ***Variable Independiente (X):*** Es la variable que se coloca en el eje horizontal. Es la variable que se supone que causa o influye en los cambios de la otra variable.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Variable Dependiente (Y):*** Es la variable que se coloca en el eje vertical. Es la variable que se espera que responda o cambie en función de la variable independiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02354c06",
   "metadata": {},
   "source": [
    "### Uso de Diagramas de Dispersión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31e3843",
   "metadata": {},
   "source": [
    "#### Identificación de Correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949f1f67",
   "metadata": {},
   "source": [
    "Uno de los principales usos de los diagramas de dispersión es identificar la relación entre las variables. Podemos observar si los puntos tienden a agruparse en una forma particular, como una línea recta, lo que indica una correlación lineal. Esto nos ayuda a comprender si existe una dependencia entre las variables y cómo cambian conjuntamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c30e96",
   "metadata": {},
   "source": [
    "#### Detección de Valores Atípicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d92c2d",
   "metadata": {},
   "source": [
    "Los valores atípicos son observaciones que difieren significativamente del resto de los datos. Un diagrama de dispersión puede revelar puntos que se alejan considerablemente de la mayoría, lo que puede ser indicativo de errores en los datos, eventos raros o condiciones especiales que deben tenerse en cuenta en el análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def01d9c",
   "metadata": {},
   "source": [
    "#### Visualización de Patrones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69020dd2",
   "metadata": {},
   "source": [
    "Los diagramas de dispersión también nos permiten identificar patrones o agrupamientos en los datos. Podemos observar si los puntos forman grupos o clusters, lo que puede indicar la presencia de subconjuntos dentro de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbad6bdd",
   "metadata": {},
   "source": [
    "### Ejemplos Prácticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde12cc",
   "metadata": {},
   "source": [
    "#### Ejemplo 1: Relación entre Ventas y Gastos de Marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6503f8d",
   "metadata": {},
   "source": [
    "Supongamos que tenemos un conjunto de datos de una empresa que registra las ventas mensuales y los gastos en marketing durante un año. Queremos analizar si existe una relación entre los gastos en marketing y las ventas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae07826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3470765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos de ejemplo\n",
    "#np.random.seed(42)\n",
    "meses = np.arange(1, 13)\n",
    "ventas = np.random.randint(100, 1000, size=12)\n",
    "gastos_marketing = ventas * np.random.uniform(0.1, 0.5, size=12)\n",
    "\n",
    "# Crear un DataFrame\n",
    "data = pd.DataFrame({'Meses': meses, 'Ventas': ventas, 'Gastos de Marketing': gastos_marketing})\n",
    "\n",
    "# Crear el diagrama de dispersión\n",
    "plt.figure(figsize=(5, 3))\n",
    "#sns.scatterplot(data=data, x='Gastos de Marketing', y='Ventas', s=100, color='g', alpha=0.7)\n",
    "sns.scatterplot(data=data, x='Gastos de Marketing', y='Ventas')\n",
    "plt.title('Relación entre Ventas y Gastos de Marketing')\n",
    "plt.xlabel('Gastos de Marketing')\n",
    "plt.ylabel('Ventas')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b7d8c3",
   "metadata": {},
   "source": [
    "En este ejemplo, podemos ver cómo se distribuyen las ventas en relación con los gastos de marketing. Si los puntos tienden a estar agrupados en una dirección ascendente, podemos inferir que existe una correlación positiva entre los gastos en marketing y las ventas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e4d43",
   "metadata": {},
   "source": [
    "#### Ejemplo 2: Análisis de Rendimiento de Empleados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842aea0e",
   "metadata": {},
   "source": [
    "Imaginemos que tenemos datos sobre el rendimiento de los empleados en una empresa, medido en términos de ventas generadas y horas de capacitación recibidas. Queremos analizar si hay alguna relación entre el tiempo de capacitación y el rendimiento de ventas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d5030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Establecer la semilla para reproducibilidad\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generar datos de ejemplo\n",
    "num_empleados = 50\n",
    "ventas_generadas = np.random.randint(1000, 10000, size=num_empleados)\n",
    "horas_capacitacion = np.random.randint(10, 100, size=num_empleados)\n",
    "\n",
    "# Crear un DataFrame\n",
    "employee_data = pd.DataFrame({'Ventas Generadas': ventas_generadas, 'Horas de Capacitación': horas_capacitacion})\n",
    "\n",
    "# Crear el diagrama de dispersión con regresión lineal y intervalo de confianza\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.regplot(data=employee_data, x='Horas de Capacitación', y='Ventas Generadas', scatter_kws={'s': 70}, line_kws={'color': 'red'})\n",
    "plt.title('Rendimiento de Empleados: Horas de Capacitación vs. Ventas Generadas')\n",
    "plt.xlabel('Horas de Capacitación')\n",
    "plt.ylabel('Ventas Generadas')\n",
    "\n",
    "# Mostrar el diagrama de dispersión con la línea de regresión y el intervalo de confianza\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa30187b",
   "metadata": {},
   "source": [
    "***Análisis de Resultados:***\n",
    "\n",
    "En el diagrama de dispersión generado, observamos puntos dispersos que representan la relación entre las horas de capacitación y las ventas generadas por los empleados. La línea roja representa la regresión lineal ajustada a los datos. Esta línea muestra la tendencia general en la relación entre las dos variables.\n",
    "\n",
    "En el diagrama observamos que la línea de regresión tiene una pendiente muy leve y con tendencia negativa (descendiente). Esto indica una relación muy débil entre las horas de capacitación y las ventas generadas por los empleados. En otras palabras, aunque la línea tiene una pendiente negativa, la relación entre estas dos variables es prácticamente horizontal y casi sin relación aparente.\n",
    "\n",
    "La región sombreada que rodea la línea de regresión es el intervalo de confianza para la regresión. Este intervalo de confianza nos proporciona información sobre la variabilidad y la incertidumbre en las predicciones del modelo. Cuanto más ancho sea el intervalo, mayor será la incertidumbre en las predicciones. Por el contrario, si el intervalo es más estrecho, las predicciones son más precisas y confiables. Debido a la dispersión de los puntos y la débil relación entre las variables, el intervalo de confianza es bastante amplio. Esto indica que hay mucha incertidumbre en cuanto a cómo las ventas generadas pueden variar en función de las horas de capacitación, debido a la falta de una relación clara entre estas variables.\n",
    "\n",
    "Si la línea de regresión fuera ascendente (con pendiente positiva), significaría que existe una correlación positiva entre las horas de capacitación y las ventas generadas. En otras palabras, a medida que las horas de capacitación aumentan, se espera que las ventas generadas también aumenten.\n",
    "\n",
    "En resumen, en este ejemplo, hemos utilizado un diagrama de dispersión con una línea de regresión y un intervalo de confianza para analizar la relación entre las horas de capacitación y las ventas generadas por los empleados. La regresión lineal y el intervalo de confianza nos proporcionan información valiosa sobre la relación entre las variables y la incertidumbre asociada a las predicciones del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ec0a9",
   "metadata": {},
   "source": [
    "#### Ejemplo 3: Análisis de Relación entre Inversión Publicitaria y Ventas Generadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48928aec",
   "metadata": {},
   "source": [
    "Imaginemos que trabajamos para una empresa que desea analizar la efectividad de su estrategia de publicidad en diferentes canales: televisión (TV), radio e internet. El objetivo es comprender cómo la inversión en publicidad en cada canal se relaciona con las ventas generadas por la empresa. Utilizaremos un diagrama de dispersión con colores y tamaños de puntos personalizados para visualizar esta relación y extraer conclusiones útiles para la toma de decisiones.\n",
    "\n",
    "***Datos Generados:***\n",
    "- Se han recopilado datos de inversión publicitaria y ventas generadas durante 12 meses.\n",
    "- Los canales de publicidad incluyen TV, Radio e Internet.\n",
    "- Cada mes se registra la inversión en cada canal y las ventas generadas.\n",
    "\n",
    "\n",
    "***Pregunta de Investigación:*** \n",
    "- ¿Cómo se relaciona la inversión en publicidad en diferentes canales con las ventas generadas por la empresa?\n",
    "\n",
    "***Análisis:***\n",
    "\n",
    "- Utilizaremos un diagrama de dispersión para visualizar la relación entre la inversión en publicidad y las ventas generadas.\n",
    "<p>&nbsp;</p>\n",
    "- Los puntos en el diagrama tendrán diferentes tamaños y colores para representar las inversiones en los canales de Radio e Internet.\n",
    "<p>&nbsp;</p>\n",
    "- Observaremos cómo las ventas generadas varían en función de la inversión en publicidad en los diferentes canales.\n",
    "\n",
    "\n",
    "***Resultados Esperados:***\n",
    "\n",
    "- Esperamos identificar patrones o tendencias en la relación entre inversión en publicidad y ventas generadas.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Los puntos más grandes (mayor inversión en Internet) podrían indicar una posible relación positiva entre inversión en Internet y ventas.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Los colores más oscuros (mayor inversión en Radio) podrían indicar diferentes niveles de efectividad en función de la inversión en Radio.\n",
    "\n",
    "***Acciones Potenciales:***\n",
    "\n",
    "- Si identificamos una fuerte relación positiva entre inversión en Internet y ventas, podríamos considerar aumentar la inversión en publicidad en este canal.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Si la inversión en Radio no parece tener un impacto claro en las ventas, podríamos evaluar la eficacia de esta estrategia y considerar redistribuir el presupuesto.\n",
    "\n",
    "***Conclusión:***\n",
    "\n",
    "Mediante este análisis visual utilizando el diagrama de dispersión con colores y tamaños de puntos personalizados, esperamos obtener información valiosa sobre la relación entre inversión en publicidad y ventas generadas en diferentes canales. Esto permitirá a la empresa tomar decisiones informadas sobre cómo asignar su presupuesto de publicidad de manera efectiva para maximizar el rendimiento empresarial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ace290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Establecer la semilla para reproducibilidad\n",
    "np.random.seed(456)\n",
    "\n",
    "# Generar datos de ejemplo\n",
    "num_meses = 12\n",
    "canales = ['TV', 'Radio', 'Internet']\n",
    "inversiones_tv = np.random.randint(5000, 30000, size=num_meses)\n",
    "inversiones_radio = np.random.randint(1000, 8000, size=num_meses)\n",
    "inversiones_internet = np.random.randint(200, 3000, size=num_meses)\n",
    "ventas_generadas = np.random.randint(20000, 80000, size=num_meses)\n",
    "\n",
    "# Crear un DataFrame\n",
    "advertising_data = pd.DataFrame({\n",
    "    'Meses': np.arange(1, num_meses + 1),\n",
    "    'Inversión TV': inversiones_tv,\n",
    "    'Inversión Radio': inversiones_radio,\n",
    "    'Inversión Internet': inversiones_internet,\n",
    "    'Ventas Generadas': ventas_generadas\n",
    "})\n",
    "\n",
    "# Crear el diagrama de dispersión con diferentes tamaños y colores de puntos\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=advertising_data,\n",
    "    x='Inversión TV', y='Ventas Generadas',\n",
    "    size='Inversión Internet', hue='Inversión Radio', sizes=(50, 300),\n",
    "    palette='viridis', alpha=0.7\n",
    ")\n",
    "plt.title('Relación entre Inversión Publicitaria y Ventas Generadas')\n",
    "plt.xlabel('Inversión en TV')\n",
    "plt.ylabel('Ventas Generadas')\n",
    "\n",
    "# Mostrar el diagrama de dispersión con tamaños y colores de puntos personalizados\n",
    "plt.legend(title='Inversión Radio', loc='upper right', bbox_to_anchor=(1.25, 1))\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c8682",
   "metadata": {},
   "source": [
    "***Análisis de resultados:***\n",
    "\n",
    "En este ejemplo, estamos explorando la relación entre la inversión publicitaria en tres canales diferentes (TV, Radio e Internet) y las ventas generadas por una empresa en un período de tiempo de 12 meses.\n",
    "\n",
    "- Los puntos en el diagrama de dispersión están marcados con diferentes colores, que representan la inversión en publicidad en el canal de Radio. Mientras más oscuro sea el color, mayor es la inversión en Radio.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Los puntos también varían en tamaño, donde el tamaño de los puntos se relaciona con la inversión en Internet. Los puntos más grandes indican una mayor inversión en publicidad en Internet.\n",
    "\n",
    "Al observar el diagrama de dispersión, podemos obtener las siguientes conclusiones preliminares:\n",
    "\n",
    "- Hay una tendencia general de aumento en las ventas generadas a medida que aumenta la inversión en publicidad en la televisión (canal de TV).\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- La inversión en publicidad en la radio (canal de Radio) parece tener menos influencia en las ventas generadas, ya que los puntos no muestran una relación clara entre inversión en Radio y ventas.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- La inversión en publicidad en Internet (canal de Internet) parece estar positivamente relacionada con las ventas generadas, ya que los puntos más grandes (mayor inversión en Internet) tienden a agruparse en regiones con ventas más altas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a48350",
   "metadata": {},
   "source": [
    "En este ejemplo, el uso de diferentes tamaños y colores de puntos en el diagrama de dispersión añade una dimensión adicional a la visualización, permitiéndonos explorar la relación entre variables de manera más detallada y facilitando la identificación de patrones y tendencias en los datos. Esta información puede ser crucial para la toma de decisiones empresariales, como la asignación de presupuestos de publicidad en diferentes canales para maximizar las ventas generadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3985d",
   "metadata": {},
   "source": [
    "## Técnicas estadísticas para la medición de información compartida e indicadores de dependencia (Correlaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad0e49",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd097af0",
   "metadata": {},
   "source": [
    "En este capítulo, exploraremos las técnicas estadísticas esenciales para medir la relación entre variables y comprender cómo se pueden aplicar en el análisis de datos empresariales para la toma de decisiones. Nos enfocaremos en los indicadores de dependencia, específicamente en las correlaciones, que nos permiten cuantificar la relación entre dos o más variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb6d5f",
   "metadata": {},
   "source": [
    "### Definición de Correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f1afa0",
   "metadata": {},
   "source": [
    "La [correlación](https://en.wikipedia.org/wiki/Correlation) es una medida estadística que describe la relación entre dos variables. Indica la fuerza y la dirección de la relación lineal entre las variables. Si dos variables tienen una correlación alta, significa que tienden a cambiar juntas en la misma dirección (positiva) o en direcciones opuestas (negativa). Sin embargo, es importante recordar que [***correlación no implica causalidad***](https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation), es decir, que una variable cause directamente cambios en la otra. [Aquí](https://www.xataka.com/magnet/a-margarina-divorcios-11-divertidos-ejemplos-que-correlacion-no-implica-causalidad) algunos ejemplos \"divertidos\" de esta sentencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abb61fe",
   "metadata": {},
   "source": [
    "### Indicadores de Correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846a090b",
   "metadata": {},
   "source": [
    "#### Coeficiente de Correlación de Pearson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dff498",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/C03_05_Correlation_coefficient?raw=true\" width=\"450\" />\n",
    "</p>\n",
    "\n",
    "El [coeficiente de correlación de Pearson](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient), denotado como $r_{xy}$, mide la relación lineal entre dos variables continuas. Varía entre $-1$ y $1$, donde $-1$ representa una correlación negativa perfecta, $1$ representa una correlación positiva perfecta y $0$ indica que no hay correlación lineal. Tiene dos presentaciones:\n",
    "\n",
    "- ***Para una población***\n",
    "\n",
    "El *coeficiente de correlación de Pearson* cuando se aplica a una población, típicamente se representa por la letra griega \n",
    "$\\rho(rho)$ y se refiere a ella como *coeficiente de correlación poblacional* o *coeficiente de correlación poblacional de Pearson*.\n",
    "\n",
    "Dado un par de variables aleatorias $\\displaystyle(X,Y)$, el *coeficiente de correlación poblacional de Pearson* (también denotado por$\\displaystyle \\rho_{X,Y}$) se define como:\n",
    "\n",
    "$$\\displaystyle \\rho _{X,Y}={\\sigma _{XY} \\over \\sigma _{X}\\sigma _{Y}}={\\frac {\\operatorname {Cov} (X,Y)}{\\sqrt {\\operatorname {Var} (X)\\operatorname {Var} (Y)}}}$$\n",
    "\n",
    "donde\n",
    "\n",
    "- $\\displaystyle \\sigma _{XY}$ es la [covarianza](https://en.wikipedia.org/wiki/Covariance) de $\\displaystyle (X,Y)$\n",
    "- $\\displaystyle \\sigma _{X}$ es la [desviación estándar](https://en.wikipedia.org/wiki/Standard_deviation) de la variable $X$\n",
    "- $\\displaystyle \\sigma _{Y}$ es la desviación estándar de la variable $Y$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Para una muestra***\n",
    "\n",
    "El *coeficiente de correlación de Pearson* cuando es aplicado a una muestra, se suele denotar por $\\displaystyle r_{xy}$ y se refiere a este como el *coeficiente de correlación muestral* o el *coeficiente de correlación muestral de Pearson*. Dados $n$ pares de datos $\\displaystyle \\{(x_{i},y_{i})\\}_{i=1}^{n}$, se define el *coeficiente de correlación muestral de Pearson* como:\n",
    "\n",
    "$$r_{xy} = \\frac{\\sum(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum{(x_i-\\bar{x})^2}\\sum{(y_i-\\bar{y})^2}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7475bf",
   "metadata": {},
   "source": [
    "#### Coeficiente de Correlación de Spearman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0661e2f",
   "metadata": {},
   "source": [
    "El [coeficiente de correlación de Spearman](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient), denotado como $\\rho(rho)$, mide la relación entre dos variables, pero no se limita a relaciones lineales. En cambio, se basa en los rangos de los valores en lugar de los valores reales. Es útil cuando la relación entre variables no es estrictamente lineal. El estadístico $\\rho$ viene dado por la expresión:\n",
    "\n",
    "$$\\rho=1-\\frac{6 \\sum D^2}{N\\left(N^2-1\\right)}$$\n",
    "\n",
    "donde $D$ es la diferencia entre los correspondientes estadísticos de orden de $x-y$. $N$ es el número de parejas de datos.\n",
    "\n",
    "Se tiene que considerar la existencia de datos idénticos a la hora de ordenarlos, aunque si estos son pocos, se puede ignorar tal circunstancia\n",
    "\n",
    "Para muestras mayores de $20$ observaciones, podemos utilizar la siguiente aproximación a la distribución *t de Student*\n",
    "\n",
    "$$ t=\\frac{\\rho}{\\sqrt{\\left(1-\\rho^2\\right) /(n-2)}}$$\n",
    "\n",
    "La interpretación del *coeficiente de Spearman* es igual que la del *coeficiente de correlación de Pearson*. Oscila entre $-1$ y $+1$, indicándonos asociaciones negativas o positivas respectivamente, $0$ cero, significa no correlación pero no independencia. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ac12f",
   "metadata": {},
   "source": [
    "#### Coeficiente de Correlación de Kendall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ed1d3",
   "metadata": {},
   "source": [
    "El [coeficiente de correlación de Kendall](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), $\\tau$, mide la asociación entre dos variables ordinales. Se enfoca en la concordancia o discordancia de los órdenes relativos de los valores en ambas variables. Una prueba $\\tau$ es una prueba de hipótesis no paramétrica para la dependencia estadística basada en el coeficiente $\\tau$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4269f08a",
   "metadata": {},
   "source": [
    "### Ejemplos de Aplicación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbfb665",
   "metadata": {},
   "source": [
    "#### Ejemplo 1: Ventas y Gastos de Marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c4d8f",
   "metadata": {},
   "source": [
    "Supongamos que tenemos datos de ventas mensuales y gastos de marketing para una empresa durante un año. Queremos determinar si hay alguna relación entre los gastos de marketing y las ventas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d534a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "months = np.arange(1, 13)\n",
    "sales = np.random.randint(100, 1000, size=12)\n",
    "marketing_expenses = np.random.randint(50, 500, size=12)\n",
    "\n",
    "data = pd.DataFrame({'Month': months, 'Sales': sales, 'Marketing Expenses': marketing_expenses})\n",
    "\n",
    "# Calculating Pearson correlation\n",
    "pearson_corr = data['Sales'].corr(data['Marketing Expenses'])\n",
    "\n",
    "sns.scatterplot(x='Marketing Expenses', y='Sales', data=data)\n",
    "plt.title(f'Correlation: Pearson r = {pearson_corr:.2f}')\n",
    "plt.show()\n",
    "print(\"pearson_corr: \", pearson_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ae7366",
   "metadata": {},
   "source": [
    "En el gráfico de dispersión, podemos observar una tendencia positiva entre los gastos de marketing y las ventas. El coeficiente de correlación de Pearson también confirma esta relación positiva (por ejemplo, $r \\approx 0.73$). Esto sugiere que un aumento en los gastos de marketing se relaciona con un aumento en las ventas, aunque no implica causalidad directa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7d6007",
   "metadata": {},
   "source": [
    "#### Ejemplo 2: Temperatura y Consumo de Helado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fdbe30",
   "metadata": {},
   "source": [
    "Imaginemos que tenemos datos mensuales de la temperatura promedio y el consumo de helado en una ciudad. Queremos examinar si existe alguna relación entre la temperatura y el consumo de helado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf75bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(544848)\n",
    "\n",
    "temperature = np.random.randint(20, 40, size=12)\n",
    "ice_cream_consumption = np.random.randint(50, 300, size=12)\n",
    "\n",
    "data = pd.DataFrame({'Temperature': temperature, 'Ice Cream Consumption': ice_cream_consumption})\n",
    "\n",
    "# Calculating Spearman correlation\n",
    "spearman_corr = data['Temperature'].corr(data['Ice Cream Consumption'], method='spearman')\n",
    "\n",
    "sns.scatterplot(x='Temperature', y='Ice Cream Consumption', data=data)\n",
    "plt.title(f'Correlation: Spearman ρ = {spearman_corr:.2f}')\n",
    "plt.show()\n",
    "\n",
    "print(\"spearman_corr: \", spearman_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c54724",
   "metadata": {},
   "source": [
    "El gráfico de dispersión sugiere una relación negativa no lineal entre la temperatura y el consumo de helado. Esto se refuerza por el coeficiente de correlación de Spearman (por ejemplo, ρ ≈ -0.4489), que es adecuado para capturar relaciones no lineales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "temperature = np.random.randint(20, 40, size=12)\n",
    "ice_cream_consumption = np.random.randint(50, 300, size=12)\n",
    "\n",
    "data = pd.DataFrame({'Temperature': temperature, 'Ice Cream Consumption': ice_cream_consumption})\n",
    "\n",
    "# Calculating Spearman correlation\n",
    "spearman_corr = data['Temperature'].corr(data['Ice Cream Consumption'], method='spearman')\n",
    "\n",
    "sns.scatterplot(x='Temperature', y='Ice Cream Consumption', data=data)\n",
    "plt.title(f'Correlation: Spearman ρ = {spearman_corr:.2f}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3bf42",
   "metadata": {},
   "source": [
    "Con un coeficiente de correlación de Spearman cercano a cero ($\\rho \\approx 0.09$), no podemos establecer una relación significativa entre la temperatura y el consumo de helado. Esto indica que los cambios en la temperatura no parecen tener un impacto claro y consistente en el consumo de helado en esta muestra de datos. Es posible que otros factores no considerados estén influyendo en el consumo de helado de manera más predominante. Por lo tanto, en función de estos datos, no se puede afirmar que haya una correlación fuerte o evidente entre la temperatura y el consumo de helado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f1dc61",
   "metadata": {},
   "source": [
    "#### Ejemplo3: Análisis de Empleados y Productividad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855877cc",
   "metadata": {},
   "source": [
    "Estamos interesados en comprender la relación entre la cantidad de empleados y la productividad mensual de una empresa. Queremos analizar si existe una correlación entre estos dos factores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ddfe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(1561)\n",
    "\n",
    "months = np.arange(1, 25)  # Representa dos años\n",
    "employees = np.random.randint(50, 200, size=len(months))\n",
    "productivity = np.random.uniform(0.5, 1.5, size=len(months))\n",
    "\n",
    "data = pd.DataFrame({'Month': months, 'Employees': employees, 'Productivity': productivity})\n",
    "\n",
    "# Calculating Pearson correlation\n",
    "pearson_corr = data['Employees'].corr(data['Productivity'])\n",
    "\n",
    "sns.scatterplot(x='Employees', y='Productivity', data=data)\n",
    "plt.title(f'Correlation: Pearson r = {pearson_corr:.2f}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459e81e7",
   "metadata": {},
   "source": [
    "El coeficiente de correlación de Pearson calculado es $\\rho \\approx 0.09$. El gráfico de dispersión no muestra una tendencia clara, lo que sugiere que no hay una correlación significativa entre la cantidad de empleados y la productividad. Esto indica que, en este conjunto de datos, no hay una relación fuerte entre estos dos factores. Sin embargo, se deben considerar otros factores que podrían influir en la productividad, como la capacitación y las condiciones laborales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6a9d5c",
   "metadata": {},
   "source": [
    "## Explicación de una variable en términos de otras (Modelo de regresión lineal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffcdb4a",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c971ef7",
   "metadata": {},
   "source": [
    "En esta sección, exploraremos uno de los métodos más fundamentales y poderosos en el análisis de datos: el Modelo de Regresión Lineal. Este modelo nos permite comprender cómo una variable dependiente puede ser explicada en términos de una o más variables independientes. Aprenderemos los conceptos clave, cómo implementar el modelo en Python utilizando bibliotecas como NumPy y Pandas, y cómo interpretar y evaluar los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b744c769",
   "metadata": {},
   "source": [
    "### Regresión Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88483212",
   "metadata": {},
   "source": [
    "La [regresión lineal](https://en.wikipedia.org/wiki/Linear_regression) es una técnica estadística que busca modelar la relación entre una variable dependiente (también conocida como variable de respuesta) y una o más variables independientes (también conocidas como predictores o covariables) a través de una ecuación lineal. La forma más simple de regresión lineal se llama *regresión lineal simple*, donde hay una sola variable independiente. Cuando hay más de una variable independiente, se habla de *regresión lineal múltiple*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc81c3",
   "metadata": {},
   "source": [
    "### Ecuación de Regresión Lineal Simple:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27473f3",
   "metadata": {},
   "source": [
    "#### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347bcfad",
   "metadata": {},
   "source": [
    "La ecuación básica para un modelo de regresión lineal simple es:\n",
    "\n",
    "$$y=\\beta_0+\\beta_1 \\cdot x + \\varepsilon$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $y$ es la variable dependiente a predecir.\n",
    "- $x$ son las variables predictoras.\n",
    "- $\\beta_0$ es la intersección (ordenada al origen) con el eje $y$\n",
    "- $\\beta_1$ es la pendiente de la línea de regresión.\n",
    "- $\\varepsilon$ es el término de error\n",
    "\n",
    "El objetivo principal es encontrar los valores de $\\beta_0$ y $\\beta_1$ que minimicen el error total (sumatoria de los errores al cuadrado) entre los valores reales de $y$ y los valores predichos por el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9da00ad",
   "metadata": {},
   "source": [
    "#### Ajuste de parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a53f1c4",
   "metadata": {},
   "source": [
    "La idea principal es encontrar los valores de $\\beta_0$ y $\\beta_1$ que minimizan la diferencia entre los valores reales observados $y$ y los valores predichos por la ecuación de la línea de regresión $\\bar{y}$. Es decir, queremos que la línea de regresión esté lo más cerca posible de todos los puntos de datos en el gráfico de dispersión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21264361",
   "metadata": {},
   "source": [
    "#### Minimización del error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d52159",
   "metadata": {},
   "source": [
    "Para lograr esto, utilizamos el método de [mínimos cuadrados](https://en.wikipedia.org/wiki/Least_squares). Este método busca minimizar la suma de los cuadrados de las diferencias entre los valores reales y los valores predichos. Matemáticamente, esto se representa como:\n",
    "\n",
    "$$\\sum_{i=1}^n\\left(y_i-\\bar{y}_i\\right)^2$$\n",
    "\n",
    "donde $n$ es el número de observaciones. Esta suma de cuadrados es a menudo llamada \"suma de los residuales al cuadrado\".\n",
    "\n",
    "Cuando ajustamos los valores de $\\beta_0$ y $\\beta_1$, estamos esencialmente moviendo y rotando la línea de regresión en el gráfico para encontrar la posición que minimiza el error. Si ajustamos estos parámetros de manera correcta, la línea de regresión pasará lo más cerca posible de los puntos reales, y el error (la distancia entre los puntos y la línea) será mínima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec56b3d",
   "metadata": {},
   "source": [
    "#### Cálculo de los coeficientes estadísticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed3e89",
   "metadata": {},
   "source": [
    "- ***Coeficientes de Regresión:***\n",
    "\n",
    "Los coeficientes de regresión $\\beta_0$ y $\\beta_1$ se calculan mediante las siguientes fórmulas:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\beta_1=\\frac{\\sum_{i-1}^n\\left(x_i - \\bar{x}\\right)\\left(y_i - \\bar{y}\\right)}{\\sum_{i-1}^n\\left(x_i-\\bar{x}\\right)^2} \\\\\n",
    "\\\\\n",
    "& \\beta_0=\\bar{y}-\\beta_1 \\cdot \\bar{x}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Donde:\n",
    "- $n$ es el número de observaciones.\n",
    "- $x_i$ y $y_i$ son los valores de la variable independiente e dependiente respectivamente en la observación $i$.\n",
    "- $\\bar{x}$ y $\\bar{y}$ son las medias de las variables $x$ e $y$ respectivamente.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Coeficiente de Determinación $\\left(R^2\\right)$:***\n",
    "\n",
    "El coeficiente de determinación $R^2$ mide la proporción de la variabilidad total en la variable dependiente que es explicada por la regresión. Se calcula así:\n",
    "\n",
    "$$R^2=\\frac{S S R}{S S T}$$\n",
    "\n",
    "- $S S R$ es la suma de los cuadrados de la regresión.\n",
    "- $S S T$ es la suma total de los cuadrados.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Error Estándar de Estimación (SEE):***\n",
    "\n",
    "EI SEE es una medida de cuánto difieren los valores reales de la variable dependiente de los valores predichos por el modelo. Se calcula como:\n",
    "\n",
    "$$S E E=\\sqrt{\\frac{\\sum_{i=1}^n\\left(y_i-\\bar{y}_i\\right)^2}{n-2}}$$\n",
    "\n",
    "Donde:\n",
    "- $y_i$ son los valores reales de la variable dependiente.\n",
    "- $\\bar{y}_i$ son los valores predichos por el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02817d4f",
   "metadata": {},
   "source": [
    "#### Indicadores de bondad de ajuste:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f6d284",
   "metadata": {},
   "source": [
    "Para evaluar la calidad del modelo de regresión lineal, utilizamos varios indicadores:\n",
    "\n",
    "- ***Coeficiente de Determinación ($R^2$):*** Mide la proporción de la variabilidad de la variable dependiente que es explicada por el modelo. $R^2$ varía entre $0$ y $1$, siendo $1$ indicativo de una perfecta predicción.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Error Estándar Residual (RSE):*** Estima la dispersión de los residuos (diferencias entre los valores reales y los predichos).\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***$p$-valor:*** Determina la significancia estadística de los coeficientes. Valores pequeños indican que la variable es relevante en el modelo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Intervalos de Confianza para los Coeficientes:*** Ayudan a establecer el rango probable de valores para los coeficientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3004a81",
   "metadata": {},
   "source": [
    "#### Implementación en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf0df1",
   "metadata": {},
   "source": [
    "Vamos a explorar la implementación de un modelo de regresión lineal utilizando Python y su ecosistema de bibliotecas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9090b76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generación de datos aleatorios\n",
    "np.random.seed(0)\n",
    "x = np.linspace(0, 10, 20)\n",
    "y = 2 * x + 1 + np.random.normal(0, 1, 20)\n",
    "\n",
    "# Cálculo de los parámetros del ajuste lineal\n",
    "A = np.vstack([x, np.ones(len(x))]).T\n",
    "m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "\n",
    "# Estadísticas del ajuste\n",
    "residuals = y - (m*x + c)\n",
    "rmse = np.sqrt(np.mean(residuals**2))\n",
    "r_squared = 1 - (np.sum(residuals**2) / np.sum((y - np.mean(y))**2))\n",
    "\n",
    "# Graficar los datos y la recta de ajuste\n",
    "plt.scatter(x, y, label='Datos')\n",
    "plt.plot(x, m*x + c, 'r', label='Ajuste Lineal')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.title('Ajuste Lineal de Datos Aleatorios')\n",
    "plt.show()\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Pendiente (m):\", m)\n",
    "print(\"Intercepto (c):\", c)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"Coeficiente de Determinación (R^2):\", r_squared)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16d000d",
   "metadata": {},
   "source": [
    "#### Análisis de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9879ba9c",
   "metadata": {},
   "source": [
    "Tanto el Coeficiente de Determinación $R^2$, como el *Root Mean Square Error* (*RMSE*) varían entre $0$ y $1$ en su escala.\n",
    "\n",
    "- $R^2$ varía entre $0$ y $1$. Un valor de $0$ significa que el modelo no explica nada de la variabilidad en los datos, mientras que un valor de $1$ significa que el modelo explica toda la variabilidad en los datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- El *RMSE* es siempre un número positivo y varía en magnitud. No se mide en una escala de $0$ a $1$ como el $R^2$. Cuanto más pequeño sea el valor del *RMSE*, más cercano será el ajuste del modelo a los datos reales. Un *RMSE* de $0$ indicaría que el modelo encaja perfectamente con los datos observados, lo cual es poco probable en la mayoría de los casos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50ba5a1",
   "metadata": {},
   "source": [
    "#### Ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb898ea",
   "metadata": {},
   "source": [
    "##### Ejemplo 1: Ventas en función del Gasto en Publicidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e26f1",
   "metadata": {},
   "source": [
    "Supongamos que somos consultores de una empresa y queremos entender cómo el gasto en publicidad afecta las ventas de un producto. Tenemos datos históricos de gastos en publicidad (en miles de dólares) y las ventas correspondientes (en unidades).\n",
    "\n",
    "|Gasto en Publicidad (x)|\tVentas (y)|\n",
    "|:---:|:---:|\n",
    "|100  |230|\n",
    "|150  |315|\n",
    "|200  |400|\n",
    "|250  |460|\n",
    "|300  |525|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43246093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.array([100, 150, 200, 250, 300])\n",
    "Y = np.array([230, 315, 400, 460, 525])\n",
    "\n",
    "beta1 = np.sum((X - np.mean(X)) * (Y - np.mean(Y))) / np.sum((X - np.mean(X))**2)\n",
    "beta0 = np.mean(Y) - beta1 * np.mean(X)\n",
    "\n",
    "Y_pred = beta0 + beta1 * X\n",
    "\n",
    "R2 = np.sum((Y_pred - np.mean(Y))**2) / np.sum((Y - np.mean(Y))**2)\n",
    "SEE = np.sqrt(np.sum((Y - Y_pred)**2) / (len(X) - 2))\n",
    "\n",
    "plt.scatter(X, Y, label='Datos reales')\n",
    "plt.plot(X, Y_pred, color='red', label='Regresión lineal')\n",
    "plt.xlabel('Gasto en Publicidad')\n",
    "plt.ylabel('Ventas')\n",
    "plt.title('Regresión Lineal: Gasto en Publicidad vs Ventas')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Coeficiente beta0:\", beta0)\n",
    "print(\"Coeficiente beta1:\", beta1)\n",
    "print(\"Coeficiente R2:\", R2)\n",
    "print(\"Error Estándar de Estimación:\", SEE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72aa3cf",
   "metadata": {},
   "source": [
    "En este caso, el modelo de regresión lineal muestra una relación positiva fuerte entre el gasto en publicidad y las ventas. El valor alto de $R^2=0.993$ indica que el $99.3\\%$ de la variabilidad en las ventas puede ser explicada por el gasto en publicidad. El bajo valor del SEE (10.76) sugiere que las predicciones del modelo son bastante cercanas a los valores reales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b0ecfa",
   "metadata": {},
   "source": [
    "#### Ejemplo 2: Estimación de Tiempo de Entrega basado en la Distancia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a247318",
   "metadata": {},
   "source": [
    "Supongamos que gestionamos una empresa de mensajería y deseamos predecir el tiempo de entrega de paquetes en función de la distancia entre la oficina y el destino. Tenemos los siguientes datos:\n",
    "\n",
    "|Distancia (X)|\tTiempo de Entrega (Y)|\n",
    "|:---:|:---:|\n",
    "|10|5|\n",
    "|15|7|\n",
    "|20|8|\n",
    "|25|10|\n",
    "|30|12|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dda24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([10, 15, 20, 25, 30])\n",
    "Y = np.array([5, 7, 8, 10, 12])\n",
    "\n",
    "beta1 = np.sum((X - np.mean(X)) * (Y - np.mean(Y))) / np.sum((X - np.mean(X))**2)\n",
    "beta0 = np.mean(Y) - beta1 * np.mean(X)\n",
    "\n",
    "Y_pred = beta0 + beta1 * X\n",
    "\n",
    "R2 = np.sum((Y_pred - np.mean(Y))**2) / np.sum((Y - np.mean(Y))**2)\n",
    "SEE = np.sqrt(np.sum((Y - Y_pred)**2) / (len(X) - 2))\n",
    "\n",
    "'''\n",
    "plt.scatter(X, Y, label='Datos reales')\n",
    "plt.plot(X, Y_pred, color='red', label='Regresión lineal')\n",
    "plt.xlabel('Distancia')\n",
    "plt.ylabel('Tiempo de Entrega')\n",
    "plt.title('Regresión Lineal: Distancia vs Tiempo de Entrega')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "print(\"Coeficiente beta0:\", beta0)\n",
    "print(\"Coeficiente beta1:\", beta1)\n",
    "print(\"Coeficiente R2:\", R2)\n",
    "print(\"Error Estándar de Estimación:\", SEE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cd5d18",
   "metadata": {},
   "source": [
    "***Cuál es su conclusión?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64fcafd",
   "metadata": {},
   "source": [
    "#### Ejemplo 3: Cuarteto de Anscombe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb81afd",
   "metadata": {},
   "source": [
    "El [Cuarteto de Anscombe](https://en.wikipedia.org/wiki/Anscombe%27s_quartet) es un conjunto de cuatro conjuntos de datos que tienen propiedades estadísticas muy similares, pero visualmente distintas. Fue presentado por el estadístico *Francis Anscombe* en 1973 como una poderosa demostración de la importancia de visualizar los datos antes de realizar análisis y tomar decisiones basadas en ellos. Cada conjunto de datos tiene 11 observaciones (puntos), lo que lo convierte en un ejemplo convincente para ilustrar cómo los resultados pueden ser engañosos si solo se confía en estadísticas descriptivas.\n",
    "\n",
    "|  x1   |  y1   |$|$|  x2   |  y2   |$|$| x3   |  y3   |$|$| x4   |  y4   |\n",
    "|-------|-------|-  |-------|-------|-  |------|-------|-  |------|-------|\n",
    "| 10.0  |  8.04 |$|$| 10.0  |  9.14 |$|$|10.0  |  7.46 |$|$| 8.0  |  6.58 |\n",
    "|  8.0  |  6.95 |$|$|  8.0  |  8.14 |$|$| 8.0  |  6.77 |$|$| 8.0  |  5.76 |\n",
    "| 13.0  |  7.58 |$|$| 13.0  |  8.74 |$|$|13.0  | 12.74 |$|$| 8.0  |  7.71 |\n",
    "|  9.0  |  8.81 |$|$|  9.0  |  8.77 |$|$| 9.0  |  7.11 |$|$| 8.0  |  8.84 |\n",
    "| 11.0  |  8.33 |$|$| 11.0  |  9.26 |$|$|11.0  |  7.81 |$|$| 8.0  |  8.47 |\n",
    "| 14.0  |  9.96 |$|$| 14.0  |  8.10 |$|$|14.0  |  8.84 |$|$| 8.0  |  7.04 |\n",
    "|  6.0  |  7.24 |$|$|  6.0  |  6.13 |$|$| 6.0  |  6.08 |$|$| 8.0  |  5.25 |\n",
    "|  4.0  |  4.26 |$|$|  4.0  |  3.10 |$|$| 4.0  |  5.39 |$|$|19.0  | 12.50 |\n",
    "| 12.0  | 10.84 |$|$| 12.0  |  9.13 |$|$|12.0  |  8.15 |$|$| 8.0  |  5.56 |\n",
    "|  7.0  |  4.82 |$|$|  7.0  |  7.26 |$|$| 7.0  |  6.42 |$|$| 8.0  |  7.91 |\n",
    "|  5.0  |  5.68 |$|$|  5.0  |  4.74 |$|$| 5.0  |  5.73 |$|$| 8.0  |  6.89 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c539510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cuarteto de Anscombe\n",
    "anscombe_1 = np.array([\n",
    "    [10.0, 8.04], [8.0, 6.95], [13.0, 7.58],\n",
    "    [9.0, 8.81], [11.0, 8.33], [14.0, 9.96],\n",
    "    [6.0, 7.24], [4.0, 4.26], [12.0, 10.84],\n",
    "    [7.0, 4.82], [5.0, 5.68]\n",
    "])\n",
    "\n",
    "anscombe_2 = np.array([\n",
    "    [10.0, 9.14], [8.0, 8.14], [13.0, 8.74],\n",
    "    [9.0, 8.77], [11.0, 9.26], [14.0, 8.10],\n",
    "    [6.0, 6.13], [4.0, 3.10], [12.0, 9.13],\n",
    "    [7.0, 7.26], [5.0, 4.74]\n",
    "])\n",
    "\n",
    "anscombe_3 = np.array([\n",
    "    [10.0, 7.46], [8.0, 6.77], [13.0, 12.74],\n",
    "    [9.0, 7.11], [11.0, 7.81], [14.0, 8.84],\n",
    "    [6.0, 6.08], [4.0, 5.39], [12.0, 8.15],\n",
    "    [7.0, 6.42], [5.0, 5.73]\n",
    "])\n",
    "\n",
    "anscombe_4 = np.array([\n",
    "    [8.0, 6.58], [8.0, 5.76], [8.0, 7.71],\n",
    "    [8.0, 8.84], [8.0, 8.47], [8.0, 7.04],\n",
    "    [8.0, 5.25], [19.0, 12.50], [8.0, 5.56],\n",
    "    [8.0, 7.91], [8.0, 6.89]\n",
    "])\n",
    "\n",
    "anscombe_data = [anscombe_1, anscombe_2, anscombe_3, anscombe_4]\n",
    "labels = [\"Cuarteto 1\", \"Cuarteto 2\", \"Cuarteto 3\", \"Cuarteto 4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1420c53",
   "metadata": {},
   "source": [
    "Calculando los estadísticos de cada conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e29958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticos del conjuntos de datos\n",
    "for i, data in enumerate(anscombe_data):\n",
    "    x, y = data[:, 0], data[:, 1]\n",
    "       \n",
    "    # Calcular estadísticos\n",
    "    mean_x, mean_y = np.mean(x), np.mean(y)\n",
    "    slope, intercept = np.polyfit(x, y, 1)\n",
    "    correlation = np.corrcoef(x, y)[0, 1]\n",
    "    \n",
    "    print(f\"\\nEstadísticas para {labels[i]}:\")\n",
    "    print(f\"Media de X: {mean_x:.2f}\")\n",
    "    print(f\"Media de Y: {mean_y:.2f}\")\n",
    "    print(f\"Pendiente: {slope:.2f}\")\n",
    "    print(f\"Intercepto: {intercept:.2f}\")\n",
    "    print(f\"Coeficiente de Correlación: {correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36bdf87",
   "metadata": {},
   "source": [
    "¿Qué podemos decir de los resultados de los estadísticos calculados? Tómese su tiempo para pensar y discutirlo, basado en la teoría.\n",
    "\n",
    "Ahora grafiquemos los datos de donde se obtuvieron dichos resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12876bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar los conjuntos de datos y calcular estadísticos\n",
    "for i, data in enumerate(anscombe_data):\n",
    "    x, y = data[:, 0], data[:, 1]\n",
    "    \n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.scatter(x, y, label=labels[i])\n",
    "    plt.plot(x, np.polyval(np.polyfit(x, y, 1), x), 'r', label='Línea de Tendencia')\n",
    "    plt.title(labels[i])\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235d55a",
   "metadata": {},
   "source": [
    "***Análisis de resultados:***\n",
    "\n",
    "- La clave en el Cuarteto de Anscombe es que, a pesar de que las estadísticas resumen de cada conjunto de datos (como media, varianza, correlación, etc.) son similares, las representaciones gráficas de estos datos son muy diferentes. Esto demuestra que, aunque las estadísticas pueden proporcionar información importante, la visualización de los datos es esencial para comprender su comportamiento real.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- El Cuarteto de Anscombe subraya el peligro de depender únicamente de estadísticas numéricas sin explorar la distribución y la forma de los datos a través de gráficos. Al no considerar las peculiaridades visuales de los datos, uno podría llegar a conclusiones erróneas o incluso perder patrones importantes.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Este ejemplo destaca la importancia de explorar visualmente los datos y cómo un mal entendimiento de su comportamiento puede llevar a decisiones incorrectas. Es crucial recordar que los números cuentan solo una parte de la historia, y es esencial combinar análisis estadísticos con visualización de datos para obtener una comprensión completa y precisa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3f28e9",
   "metadata": {},
   "source": [
    "### Ecuación de Regresión Lineal Múltiple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d955f",
   "metadata": {},
   "source": [
    "#### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef54dfd7",
   "metadata": {},
   "source": [
    "La Regresión Lineal Múltiple es una técnica fundamental en el campo de la estadística y el análisis de datos. Se trata de una extensión poderosa de la Regresión Lineal Simple, diseñada para abordar situaciones en las que una variable dependiente $Y$ se relaciona con dos o más variables independientes $X_1,X_2,\\ldots,X_n$. La principal pregunta que busca responder es cómo estas variables independientes influyen en la variable dependiente y cómo pueden ser utilizadas para predecir su comportamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab5f66",
   "metadata": {},
   "source": [
    "#### Comprendiendo la Problemática"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe5ed1",
   "metadata": {},
   "source": [
    "Imaginemos una situación en la que una empresa quiere estimar las ventas de sus productos en función de varios factores, como el precio, el gasto en publicidad y la competencia. En lugar de abordar cada variable por separado, la *Regresión Lineal Múltiple* permite analizar cómo estas variables interactúan entre sí para afectar las ventas. Esto es especialmente útil en situaciones empresariales, ciencias sociales, ciencias naturales y muchos otros campos donde las relaciones no son simples y únicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd4f23b",
   "metadata": {},
   "source": [
    "#### Ecuación de Regresión Lineal Múltiple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36570921",
   "metadata": {},
   "source": [
    "La ecuación general de la Regresión Lineal Múltiple es:\n",
    "\n",
    "$$Y=\\beta_0+\\beta_1 X_1+\\beta_2 X_2+\\ldots+\\beta_n X_n+\\varepsilon$$\n",
    "\n",
    "Aquí:\n",
    "\n",
    "- $Y$ es la variable dependiente que estamos tratando de predecir o entender.\n",
    "- $X_1, X_2, \\ldots, X_p$ son las variables independientes o predictores.\n",
    "- $\\beta_0$ es el término de intersección o el valor esperado de $Y$ cuando todas las $X$ son cero.\n",
    "- $\\beta_1, \\beta_2, \\ldots, \\beta_n$ son los coeficientes de regresión, que indican cómo cambia $Y$ en respuesta a cambios en las $X$.\n",
    "- $\\varepsilon$ representa el error, que captura la variabilidad no explicada por el modelo.\n",
    "\n",
    "A medida que se van adicionando más variables, de una $x$ a dos ($x_1$ y $x_2$), ya el problema cambia de *\"encontrar la recta que mejor se ajusta a una serie de datos\"* (en *2D*), a *encontrar el mejor plano que se ajuste a la nube de puntos tridimensionales* (3D). Y a medida que se añaden más variables, ya estaríamos hablando de hiperplanos en espacios multidimensionales. Cada una de las dimensiones representando una característica de la realidad del fenómeno que los datos representan. Se puede tener una gran cantidad de atributos y, por lo tanto, de dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b5ef70",
   "metadata": {},
   "source": [
    "#### Forma vectorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a90f94",
   "metadata": {},
   "source": [
    "La forma más práctica de representar esta combinación lineal de variables para cada uno de nuestros datos es empleando la nomenclatura vectorial, es decir, en vez de tener un conjunto de ecuaciones del tipo:\n",
    "\n",
    "$$y_1=\\beta_0+\\beta_1x_{11}+\\beta_2x_{12}+\\beta_3x_{13}+\\ldots$$\n",
    "$$y_2=\\beta_0+\\beta_1x_{21}+\\beta_2x_{22}+\\beta_3x_{23}+\\ldots$$\n",
    "$$y_3=\\beta_0+\\beta_1x_{31}+\\beta_2x_{32}+\\beta_3x_{33}+\\ldots$$\n",
    "$$\\vdots$$\n",
    "\n",
    "se puede conformar una matriz en la que cada columna representa una característica de los datos de entrada, y las filas representa cada una de las mediciones que se tienen en el conjunto de datos\n",
    "\n",
    "$$\\textbf{X}=\\begin{bmatrix} 1 & x_{11} & x_{12} & x_{13} & \\ldots \\\\ 1 & x_{21} & x_{22} & x_{23} & \\ldots \\\\ 1 & x_{31} & x_{32} & x_{33} & \\ldots \\\\ \\vdots & \\vdots & \\vdots & \\vdots & \\ddots \\end{bmatrix}$$\n",
    "\n",
    "Para cada una de las ecuaciones se tiene la variable $y$, que es la variable a modelar. Juntando todas en un vector, se tiene\n",
    "\n",
    "$$\\textbf{Y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3  \\\\ \\vdots\\end{bmatrix}$$\n",
    "\n",
    "y se puede hacer lo mismo con los factores para generar un vector de parámetros\n",
    "\n",
    "$$\\textbf{B}=\\begin{bmatrix} \\beta_0 & \\beta_1 & \\beta_2 & \\beta_3 \\ldots\\end{bmatrix}$$\n",
    "\n",
    "Con esto, se puede reducir la escitura de una gran cantidad de ecuaciones a una sola ecuación vectorial escrita como\n",
    "\n",
    "$$\\textbf{Y}=\\textbf{X}\\textbf{B}$$\n",
    "\n",
    "Esta forma de escribir no es solo estética, sino que nos facilitará la comprensión del algoritmo a programar además de ser mucho más eficiente, ya que los procesadores y GPUs procesan de forma más eficiente sobre este tipo de estructuras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6348a212",
   "metadata": {},
   "source": [
    "#### Ecuación Matricial y Mínimos Cuadrados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a6d13",
   "metadata": {},
   "source": [
    "La ecuación matricial que resume este proceso es:\n",
    "\n",
    "$$\\textbf{B}=\\left(\\textbf{X}^T \\textbf{X}\\right)^{-1} \\textbf{X}^T Y$$\n",
    "\n",
    "- $\\textbf{X}$ es la matriz de diseño que contiene los valores de las variables independientes para cada observación.\n",
    "- $\\textbf{Y}$ es el vector de valores de la variable dependiente.\n",
    "- $\\textbf{X}^T$ es la matriz transpuesta de $X$.\n",
    "- $\\left(\\textbf{X}^T \\textbf{X}\\right)^{-1}$ es la inversa de la matriz producto $\\textbf{X}^T \\textbf{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6623d3e",
   "metadata": {},
   "source": [
    "#### Evaluación de la calidad del ajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2a940",
   "metadata": {},
   "source": [
    "Una vez que se obtienen los coeficientes $\\beta$, es crucial evaluar la calidad del ajuste del modelo. Algunos estadísticos clave son:\n",
    "\n",
    "- ***Coeficiente de Determinación $\\left(R^2\\right)$ :*** Mide la proporción de la variabilidad total en \n",
    "$\\textbf{Y}$ explicada por el modelo. Varía entre $0$ (ninguna explicación) y $1$ (explicación completa).\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Error Estándar Residual (RMSE o $\\sigma$ ):*** Representa la desviación estándar de los residuos. Un RMSE más bajo indica un mejor ajuste.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Estadístico F y Prueba t:*** Evalúan la significancia del modelo y de $\\sigma_z$ coeficientes individuales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aef333",
   "metadata": {},
   "source": [
    "#### Ejemplo: Casas de Boston"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d6c1a",
   "metadata": {},
   "source": [
    "##### Descripción del Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa69068",
   "metadata": {},
   "source": [
    "En este ejemplo, utilizaremos el conjunto de datos de las casas de Boston, que contiene información sobre diferentes atributos de viviendas en Boston y sus respectivos valores medios. El objetivo es predecir el valor medio de las viviendas ($\\textbf{Y}$) utilizando cuatro variables independientes: tasa de criminalidad ($\\texttt{CRIM}$), cantidad promedio de habitaciones por vivienda ($\\texttt{RM}$), proporción de viviendas ocupadas por sus propietarios construidas antes de 1940 ($\\texttt{AGE}$) y tasa de impuesto a la propiedad ($\\texttt{TAX}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3308d504",
   "metadata": {},
   "source": [
    "##### Ruta de Solución"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9e8744",
   "metadata": {},
   "source": [
    "- ***Carga de Datos:*** Se carga el conjunto de datos de las casas de Boston utilizando la función `load_boston` de [`sklearn.datasets`](https://scikit-learn.org/stable/datasets.html). Luego, se crea un DataFrame data para almacenar los atributos y el vector target para almacenar los valores medios de las viviendas.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Selección de Variables:*** Se eligen cuatro variables independientes específicas para este ejemplo: $\\texttt{CRIM}$, $\\texttt{RM}$, $\\texttt{AGE}$ y $\\texttt{TAX}$. Estas variables se almacenan en la matriz $\\textbf{X}$.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***División de Datos:*** Se divide el conjunto de datos en conjuntos de entrenamiento y prueba utilizando la función `train_test_split` de `sklearn.model_selection`. Esto nos permitirá evaluar el rendimiento del modelo en datos no vistos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Creación y Ajuste del Modelo:*** Se crea un objeto de regresión lineal utilizando `LinearRegression` de `sklearn.linear_model`. Luego, se ajusta el modelo utilizando los datos de entrenamiento (`X_train` y `y_train`).\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Predicciones y Evaluación:*** Se realizan predicciones en el conjunto de prueba (`X_test`) utilizando el modelo ajustado. Se calculan los estadísticos de calidad del ajuste, como el *Error Estándar Residual (RMSE)* y el *Coeficiente de Determinación* ($R^2$), utilizando las funciones `mean_squared_error` y `r2_score` de `sklearn.metrics`.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Presentación de Resultados:*** Se presentan los coeficientes de ajuste, el término de intersección, el *RMSE* y el $R^2$ como resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886ddcea",
   "metadata": {},
   "source": [
    "##### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acfe706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96d981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar el conjunto de datos de las casas de Boston\n",
    "boston = load_boston()\n",
    "data = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "target = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb525803",
   "metadata": {},
   "source": [
    "En vez de la biblioteca de sklearn usaremos la URL directa al dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ee50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Cargar el conjunto de datos de las casas de Boston desde la URL\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con los datos y nombres de columnas\n",
    "feature_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "data_df = pd.DataFrame(data, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f81c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37d09de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae806b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913891f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar cuatro variables independientes para el ejemplo\n",
    "selected_features = ['CRIM', 'RM', 'AGE', 'TAX']\n",
    "X = data_df[selected_features]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599ffe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y ajustar el modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular estadísticos de calidad del ajuste\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Obtener los coeficientes de ajuste\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Presentar resultados\n",
    "print(\"Coeficientes de Ajuste:\", coefficients)\n",
    "print(\"Término de Intersección:\", intercept)\n",
    "print(\"Error Estándar Residual (RMSE):\", rmse)\n",
    "print(\"Coeficiente de Determinación (R^2):\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddbf671",
   "metadata": {},
   "source": [
    "##### Análisis de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e8ce49",
   "metadata": {},
   "source": [
    "Los coeficientes de ajuste representan cómo cada variable independiente contribuye al valor medio de las viviendas. En este caso:\n",
    "\n",
    "- El coeficiente de ajuste para $\\texttt{CRIM}$ es aproximadamente $-0.1354$. Esto sugiere que, manteniendo las otras variables constantes, un aumento en la tasa de criminalidad está asociado con una disminución de aproximadamente $\\$135$ por unidad en el valor medio de las viviendas.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- El coeficiente de ajuste para $\\texttt{RM}$ es aproximadamente $8.138$. Esto indica que, manteniendo las otras variables constantes, un aumento en la cantidad promedio de habitaciones por vivienda está relacionado con un aumento de aproximadamente $\\$8,138$ en el valor medio de las viviendas.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- El coeficiente de ajuste para $\\texttt{AGE}$ es aproximadamente $-0.0287$. Esto implica que un aumento en la proporción de viviendas ocupadas por sus propietarios construidas antes de 1940 está asociado con una disminución de aproximadamente $\\$28.7$ por unidad en el valor medio de las viviendas.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- El coeficiente de ajuste para $\\texttt{TAX}$ es aproximadamente $-0.0096$. Esto sugiere que un aumento en la tasa de impuesto a la propiedad está asociado con una disminución de aproximadamente $\\$9.6$ por unidad en el valor medio de las viviendas.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- El término de intersección (aproximadamente $-22.2662$) representa el valor esperado de las viviendas cuando todas las variables independientes son cero. Sin embargo, en este contexto, este valor puede no tener una interpretación directa y práctica debido a que muchas de las variables nunca serán iguales a cero en situaciones reales.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Error Estándar Residual (RMSE):*** El *RMSE* es una medida de la desviación promedio entre los valores reales y las predicciones del modelo. En este caso, el *RMSE* es aproximadamente 6.1324. Esto significa que, en promedio, las predicciones del modelo tienen un error de alrededor de $\\$6,132$ en relación con los valores reales de las viviendas. Un *RMSE* más bajo indica un mejor ajuste del modelo a los datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Coeficiente de Determinación ($R^2$):*** El $R^2$ de aproximadamente $0.4872$ indica que alrededor del $48.72\\%$ de la variabilidad en los valores medios de las viviendas puede ser explicada por el modelo de regresión lineal múltiple. Esto sugiere que el modelo tiene cierta capacidad para predecir las variaciones en los valores medios de las viviendas, pero no explica la variabilidad en su totalidad.\n",
    "\n",
    "***Análisis General***\n",
    "\n",
    "- Los resultados sugieren que el modelo de regresión lineal múltiple tiene cierta capacidad para predecir los valores medios de las viviendas en función de las variables seleccionadas ($\\texttt{CRIM}$, $\\texttt{RM}$, $\\texttt{AGE}$ y $\\texttt{TAX}$). Sin embargo, el $R^2$ relativamente bajo y el *RMSE* moderado indican que aún existe una cantidad significativa de variabilidad que el modelo no puede explicar. Esto podría deberse a la falta de consideración de otras variables importantes que influyen en el valor de las viviendas.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "En resumen, mientras que el modelo tiene utilidad predictiva, es importante considerar que hay otros factores que podrían influir en los valores de las viviendas y que no están considerados en este análisis. Sería recomendable explorar más variables y realizar análisis adicionales para mejorar la precisión y capacidad explicativa del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec3e8ed",
   "metadata": {},
   "source": [
    "## Métodos estadísticos de selección de variables importantes e identificación de información redundante. (validación y significancia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aefae4",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1494b31",
   "metadata": {},
   "source": [
    "En este capítulo, exploraremos cómo seleccionar variables importantes y evitar la redundancia en el análisis de datos. Abordaremos métodos estadísticos para validar la significancia de las variables en modelos de predicción y pronóstico. Utilizaremos indicadores y técnicas para evaluar la importancia de las variables y cómo identificar aquellas que pueden ser redundantes o irrelevantes para el análisis. Es deseable reducir el número de variables de entrada tanto para disminuir el costo computacional del modelado como, en algunos casos, para mejorar el rendimiento del modelo.\n",
    "\n",
    "Los métodos de selección de características basados en estadísticas implican evaluar la relación entre cada variable de entrada y la variable objetivo utilizando estadísticas y seleccionar aquellas variables de entrada que tienen la relación más fuerte con la variable objetivo. Estos métodos pueden ser rápidos y efectivos, aunque la elección de las medidas estadísticas depende del tipo de datos tanto de las variables de entrada como de las variables de salida.\n",
    "\n",
    "Por lo tanto, el desafío consiste en seleccionar una medida estadística adecuada para un conjunto de datos al realizar la selección de características basada en filtros. Descubriremos cómo elegir medidas estadísticas para la selección de características basada en filtros con datos numéricos y categóricos.\n",
    "\n",
    "Al finalizar el capítulo, usted sabrá que:\n",
    "\n",
    "- Existen dos tipos principales de técnicas de selección de características: supervisadas y no supervisadas, y los métodos supervisados se pueden dividir en envolvente (wrapper), filtro e intrínseco.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Los métodos de selección de características basados en filtros utilizan medidas estadísticas para evaluar la correlación o dependencia entre variables de entrada que se pueden filtrar para elegir las características más relevantes.\n",
    "<p>&nbsp;</p>\n",
    "- Las medidas estadísticas para la selección de características deben elegirse cuidadosamente en función del tipo de datos de la variable de entrada y de la variable de salida o respuesta.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b8ce11",
   "metadata": {},
   "source": [
    "### Métodos de Selección de características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4a2c5",
   "metadata": {},
   "source": [
    "Los métodos de [selección de características](https://en.wikipedia.org/wiki/Feature_selection) tienen como objetivo reducir el número de variables de entrada para mejorar la eficiencia de los modelos predictivos. En algunos casos, el exceso de variables puede ralentizar el desarrollo y el entrenamiento de modelos, así como consumir recursos de memoria. Además, incluir variables irrelevantes puede degradar el rendimiento del modelo. Estos métodos se dividen en enfoques supervisados y no supervisados. Los métodos no supervisados ignoran la variable objetivo y eliminan variables redundantes mediante la correlación. Los métodos supervisados, en cambio, utilizan la variable objetivo para eliminar variables irrelevantes.\n",
    "\n",
    "La selección de características se puede clasificar en métodos de envoltura ([wrapper methods](https://en.wikipedia.org/wiki/Feature_selection#Wrapper_method)) y métodos de filtro. Los métodos de envoltura crean múltiples modelos con diferentes combinaciones de características y seleccionan las que optimizan una métrica de rendimiento, sin importar el tipo de variables. Estos pueden ser costosos computacionalmente. Los métodos de filtro, por otro lado, utilizan técnicas estadísticas para evaluar la relación entre cada variable de entrada y la variable objetivo, seleccionando las más relevantes para el modelo.\n",
    "\n",
    "También hay algoritmos de aprendizaje automático que realizan selección de características durante el entrenamiento del modelo. Estos métodos intrínsecos incluyen modelos de regresión penalizados como Lasso y árboles de decision, como el bosque aleatorio. Además, la selección de características se relaciona con las técnicas de reducción de dimensionalidad. Ambos enfoques buscan reducir el número de variables de entrada en un modelo predictivo. Sin embargo, la selección de características elige qué mantener o eliminar del conjunto de datos, mientras que la reducción de dimensionalidad crea nuevas características a través de proyecciones de los datos. En definitiva, la reducción de dimensionalidad es una alternativa a la selección de características en lugar de un tipo de esta.\n",
    "\n",
    "Resumiendo:\n",
    "\n",
    "- ***Selección de Características:*** Seleccionar un subconjunto de características de entrada del conjunto de datos.\n",
    "  - ***No supervisado:*** No utilizar la variable objetivo (por ejemplo, eliminar variables redundantes).\n",
    "    - Correlación.\n",
    "  - ***Supervisado:*** Utilizar la variable objetivo (por ejemplo, eliminar variables irrelevantes).\n",
    "    - ***Wrapper:*** Buscar subconjuntos de características que tengan un buen rendimiento.\n",
    "      - RFE.\n",
    "    - ***Filtro:*** Seleccionar subconjuntos de características basados en su relación con la variable objetivo.\n",
    "      - Métodos Estadísticos.\n",
    "      - Métodos de Importancia de Características.\n",
    "    - ***Intrínseco:*** Algoritmos que realizan selección automática de características durante el entrenamiento.\n",
    "      - Árboles de Decisión.\n",
    "- ***Reducción de Dimensionalidad:*** Proyectar los datos de entrada en un espacio de características de menor dimensión.\n",
    "\n",
    "La imagen a continuación proporciona un resumen de esta jerarquía de técnicas de selección de características.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/C03_Feature_Slection_Techniques.webp?raw=true\" width=\"500\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fcc2ef",
   "metadata": {},
   "source": [
    "### Estadísticas para Métodos de Selección de Características Basados en Filtros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b7e25e",
   "metadata": {},
   "source": [
    "Es común utilizar medidas estadísticas de tipo correlación entre las variables de entrada y salida como base para la selección de características mediante filtros. Como tal, la elección de las medidas estadísticas depende en gran medida de los tipos de datos de las variables.\n",
    "\n",
    "Los tipos de datos comunes incluyen numéricos (como la altura) y categóricos (como una etiqueta), aunque cada uno puede subdividirse aún más, como números enteros y de punto flotante para variables numéricas, y booleanos, ordinales o nominales para variables categóricas.\n",
    "\n",
    "Tipos de datos comunes para las variables de entrada:\n",
    "\n",
    "- ***Variables Numéricas.***\n",
    "  - Variables Enteras.\n",
    "  - Variables de Punto Flotante.\n",
    "- ***Variables Categóricas.***\n",
    "  -Variables Booleanas (dicotómicas).\n",
    "  - Variables Ordinales.\n",
    "  - Variables Nominales.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/C03_02_Data_Variable_Types.webp?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "En función del conocimiento sobre el tipo de datos de una variable, es más sencillo elegir una medida estadística adecuada para un método de selección de características basado en filtros. En esta sección, se abordan dos categorías principales de tipos de variables: numéricas y categóricas, y se distinguen dos grupos clave de variables: las de entrada y las de salida. Las variables de entrada son las que se utilizan como insumos en un modelo, y es precisamente este conjunto el que se busca reducir en la selección de características. Por otro lado, las variables de salida son las que se buscan predecir, siendo llamadas en muchas ocasiones variables de respuesta.\n",
    "\n",
    "El tipo de variable de respuesta a menudo señala el tipo de problema de modelado predictivo en cuestión. Por ejemplo, una variable de salida numérica indica un problema de regresión, mientras que una variable de salida categórica indica un problema de clasificación. En la selección de características basada en filtros, las medidas estadísticas se aplican típicamente una variable de entrada a la vez con respecto a la variable objetivo. Estas medidas son univariadas, lo que puede traducirse en que las interacciones entre las variables de entrada no se consideran en el proceso de filtrado.\n",
    "\n",
    "Con este marco de trabajo, revisemos algunas medidas estadísticas univariadas que se pueden utilizar para la selección de características basada en filtros.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/C03_03_Choose_Feature_Selection_Method.webp?raw=true\" width=\"500\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72508cb6",
   "metadata": {},
   "source": [
    "#### Entrada Numérica, Salida Numérica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9763f676",
   "metadata": {},
   "source": [
    "Este es un problema de modelado predictivo de regresión con variables de entrada numéricas.Las técnicas más comunes son utilizar un coeficiente de correlación, como el de Pearson para una correlación lineal, o métodos basados en rangos para una correlación no lineal.\n",
    "\n",
    "- Coeficiente de correlación de Pearson (lineal).\n",
    "- Coeficiente de correlación de Spearman (no lineal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba892ed",
   "metadata": {},
   "source": [
    "#### Entrada Numérica, Salida Categórica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141daa5",
   "metadata": {},
   "source": [
    "Este es un problema de modelado predictivo de clasificación con variables de entrada numéricas.Este podría ser el ejemplo más común de un problema de clasificación. Nuevamente, las técnicas más comunes son basadas en correlación, aunque en este caso, deben tener en cuenta la variable objetivo categórica.\n",
    "\n",
    "- Coeficiente de correlación ANOVA (lineal).\n",
    "- Coeficiente de correlación de Kendall (no lineal).\n",
    "- Kendall asume que la variable categórica es ordinal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc019cf",
   "metadata": {},
   "source": [
    "#### Entrada Categórica, Salida Numérica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cf36b9",
   "metadata": {},
   "source": [
    "Este es un problema de modelado predictivo de regresión con variables de entrada categóricas. Este es un ejemplo poco común de un problema de regresión (por ejemplo, no lo encontrarías con frecuencia).\n",
    "\n",
    "No obstante, puedes usar los mismos métodos de \"Entrada Numérica, Salida Categórica\" (descritos arriba), pero al revés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b7abd6",
   "metadata": {},
   "source": [
    "#### Entrada Categórica, Salida Categórica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa35f350",
   "metadata": {},
   "source": [
    "Este es un problema de modelado predictivo de clasificación con variables de entrada categóricas. La medida de correlación más común para datos categóricos es la prueba de chi-cuadrado. También puedes utilizar la información mutua (ganancia de información) del campo de la teoría de la información.\n",
    "\n",
    "- Prueba de Chi-Cuadrado (tablas de contingencia).\n",
    "- Información Mutua.\n",
    "\n",
    "De hecho, la información mutua es un método poderoso que puede resultar útil tanto para datos categóricos como numéricos, es decir, es independiente de los tipos de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d813cbf2",
   "metadata": {},
   "source": [
    "### Consejos y Trucos para la Selección de Características (Aqui vamos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d30dd",
   "metadata": {},
   "source": [
    "Esta sección ofrece algunas consideraciones adicionales al usar la selección de características basada en filtros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0856f915",
   "metadata": {},
   "source": [
    "#### Estadísticas de Correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eff8c1",
   "metadata": {},
   "source": [
    "La biblioteca [`scikit-learn`](https://scikit-learn.org/stable/) proporciona una implementación de la mayoría de las medidas estadísticas útiles. Por ejemplo:\n",
    "\n",
    "- Coeficiente de Correlación de Pearson: [`f_regression()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html)\n",
    "- ANOVA: [`f_classif()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html)\n",
    "- Chi-Cuadrado: [`chi2()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html)\n",
    "- Información Mutua: [`mutual_info_classif()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html) y [`mutual_info_regression()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html)\n",
    "\n",
    "Además, la biblioteca SciPy proporciona una implementación de muchas más estadísticas, como el coeficiente de Kendall ([`kendalltau`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html)) y la correlación de rango de Spearman ([`spearmanr`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e2f7ea",
   "metadata": {},
   "source": [
    "#### Método de Selección"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d9bb4",
   "metadata": {},
   "source": [
    "La biblioteca `scikit-learn` también proporciona diversos métodos de filtrado una vez que se han calculado las estadísticas para cada variable de entrada con respecto al objetivo.\n",
    "\n",
    "Dos de los métodos más populares son:\n",
    "\n",
    "- Seleccionar las primeras k variables: [`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)\n",
    "- Seleccionar las variables del percentil superior: [`SelectPercentile`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed1aaf",
   "metadata": {},
   "source": [
    "#### Transformación de Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c07d12",
   "metadata": {},
   "source": [
    "Considera transformar las variables para acceder a diferentes métodos estadísticos. Por ejemplo, puedes transformar una variable categórica en ordinal, incluso si no lo es, y ver si surgen resultados interesantes. También puedes convertir una variable numérica en discreta (por ejemplo, en intervalos); prueba medidas basadas en categorías.\n",
    "\n",
    "Algunas medidas estadísticas asumen propiedades de las variables, como el coeficiente de Pearson que supone una distribución de probabilidad gaussiana en las observaciones y una relación lineal. Puedes transformar los datos para cumplir con las expectativas de la prueba y probarla independientemente de las expectativas y comparar los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805323a0",
   "metadata": {},
   "source": [
    "#### ¿Cuál es el Mejor Método?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d542d",
   "metadata": {},
   "source": [
    "- No existe un mejor método de selección de características.\n",
    "\n",
    "- Así como no existe un conjunto de variables de entrada perfecto ni un mejor algoritmo de aprendizaje automático. Al menos no de manera universal.\n",
    "\n",
    "- En su lugar, debes descubrir qué funciona mejor para tu problema específico mediante una experimentación sistemática cuidadosa.\n",
    "\n",
    "- Prueba una variedad de modelos diferentes ajustados a diferentes subconjuntos de características elegidos a través de diferentes medidas estadísticas y descubre qué funciona mejor para tu problema específico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b26b65",
   "metadata": {},
   "source": [
    "### Selección de Variables Importantes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88b10ab",
   "metadata": {},
   "source": [
    "#### Definición\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77567521",
   "metadata": {},
   "source": [
    "La selección de variables importantes se refiere a identificar y mantener las variables más influyentes y relevantes para un modelo de predicción o análisis. Esto ayuda a mejorar la precisión del modelo y reduce el riesgo de [sobreajuste](https://en.wikipedia.org/wiki/Overfitting) al eliminar variables irrelevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d864930",
   "metadata": {},
   "source": [
    "####  Métodos de Selección de Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6e880d",
   "metadata": {},
   "source": [
    "##### Filtro de Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b74b57f",
   "metadata": {},
   "source": [
    "- ***Uso:*** El [filtro de variables](https://en.wikipedia.org/wiki/Feature_selection) es una técnica rápida y simple para identificar las variables más relevantes antes de construir un modelo. Se basa en medidas estadísticas como la correlación y la prueba de [chi-cuadrado](https://en.wikipedia.org/wiki/Chi-squared_test) ($\\chi ^2$) para evaluar la relación entre cada variable y la variable objetivo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Ventajas:*** Es eficiente para conjuntos de datos grandes. Puede ayudar a descartar variables irrelevantes rápidamente.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Desventajas:*** No considera la interacción entre variables y el modelo final. Puede ignorar variables importantes si no tienen una alta correlación con la variable objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654c081",
   "metadata": {},
   "source": [
    "##### Wrapper Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfab33f",
   "metadata": {},
   "source": [
    "- ***Uso:*** Los [wrapper methods](https://en.wikipedia.org/wiki/Feature_selection#Wrapper_method) utilizan algoritmos de modelado para evaluar diferentes conjuntos de variables y seleccionar el mejor conjunto que optimiza el rendimiento del modelo. Ejemplos incluyen el backward elimination y el forward selection.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Ventajas:*** Toman en cuenta la interacción entre variables. Pueden mejorar el rendimiento del modelo al considerar múltiples combinaciones de variables.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Desventajas:*** Pueden ser computacionalmente costosos y propensos al sobreajuste si no se manejan adecuadamente. Pueden requerir mucho tiempo para encontrar el mejor conjunto de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad7dd40",
   "metadata": {},
   "source": [
    "##### Embedded Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f235e3e5",
   "metadata": {},
   "source": [
    "- ***Uso:*** Los métodos integrados incluyen la selección de variables como parte del proceso de entrenamiento del modelo. Ejemplos incluyen la [regresión LASSO](https://en.wikipedia.org/wiki/Lasso_(statistics)) y [Ridge](https://en.wikipedia.org/wiki/Ridge_regression), que penalizan los coeficientes de las variables menos importantes.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Ventajas:*** Seleccionan automáticamente las variables relevantes durante el proceso de entrenamiento. Ayudan a prevenir el sobreajuste al penalizar coeficientes irrelevantes.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Desventajas:*** Pueden ser difíciles de ajustar y pueden requerir ajustes de parámetros. La interpretación de los coeficientes puede ser más compleja debido a la penalización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c669a90",
   "metadata": {},
   "source": [
    "### Identificación de Información Redundante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649cef0b",
   "metadata": {},
   "source": [
    "#### Matriz de Correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163ca2c3",
   "metadata": {},
   "source": [
    "- ***Uso:*** La matriz de correlación evalúa la relación lineal entre pares de variables. Las variables altamente correlacionadas pueden indicar redundancia. En esencia, es una tabla cuadrada que muestra los coeficientes de correlación entre todas las combinaciones posibles de variables en un conjunto de datos.\n",
    "\n",
    "  El coeficiente de correlación es un número que oscila entre -1 y 1. Un valor de 1 indica una correlación positiva perfecta, lo que significa que a medida que una variable aumenta, la otra también lo hace de manera proporcional. Un valor de -1 indica una correlación negativa perfecta, donde una variable aumenta mientras que la otra disminuye proporcionalmente. Un valor de 0 implica que no hay relación lineal entre las variables.\n",
    "\n",
    "  La matriz de correlación es especialmente útil para identificar patrones y asociaciones en los datos. Si dos variables tienen un coeficiente de correlación alto, esto sugiere que tienden a cambiar juntas en la misma dirección. Por otro lado, un coeficiente cercano a 0 indica que las variables no están relacionadas de manera lineal.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Ventajas:*** Es fácil de calcular y visualizar. Ayuda a identificar variables que podrían ser redundantes.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Desventajas:*** Solo identifica relaciones lineales. Puede no capturar interacciones complejas entre variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd82fa",
   "metadata": {},
   "source": [
    "#### Análisis de Componentes Principales (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27bbbc4",
   "metadata": {},
   "source": [
    "- ***Uso:*** El [Análisis de Componentes Principales](https://en.wikipedia.org/wiki/Principal_component_analysis) (PCA, siglás en inglés) es una técnica  de reducción de dimensionalidad utilizada en el análisis de datos para simplificar la complejidad de un conjunto de variables, mientras retiene la mayor parte de la información importante. Su objetivo principal es transformar un conjunto de variables correlacionadas en un nuevo conjunto de variables no correlacionadas llamadas \"componentes principales\".\n",
    "\n",
    "  El proceso del PCA implica calcular los componentes principales, que son combinaciones lineales de las variables originales. El primer componente principal se elige de manera que capture la mayor varianza posible en los datos. El segundo componente principal se elige de manera que sea no correlacionado con el primero y también capture la mayor varianza posible, y así sucesivamente. Los componentes principales están ordenados en función de la cantidad de varianza que explican, lo que significa que los primeros componentes principales capturan la mayor parte de la variabilidad en los datos.\n",
    "\n",
    "  La interpretación de los componentes principales puede variar según el contexto, pero en general, cada componente principal puede considerarse como una \"dirección\" en el espacio original de las variables. Cada variable original tiene un peso (llamado carga) en cada componente principal, lo que indica su contribución a ese componente. Los componentes principales también son ortogonales entre sí, lo que significa que no están correlacionados.\n",
    "\n",
    "  El PCA es útil para reducir la dimensionalidad de los datos, lo que puede facilitar la visualización y el análisis. También puede ayudar a eliminar variables redundantes o ruido en los datos y permitir una comprensión más clara de las relaciones subyacentes entre las variables. Además, el PCA se utiliza a menudo para mejorar la eficiencia y el rendimiento de los modelos de machine learning al reducir el número de variables en la entrada..\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Ventajas:*** Reduce la multicolinealidad y la redundancia. Ayuda en la interpretación al proporcionar nuevas variables independientes.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Desventajas:*** Puede ser difícil de interpretar debido a la transformación lineal. Puede perder información en los componentes de menor importancia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998f860a",
   "metadata": {},
   "source": [
    "#### Factorización de Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dd4106",
   "metadata": {},
   "source": [
    "- ***Uso:*** La factorización de matrices descompone la matriz de datos en matrices más pequeñas, como la matriz de factores y la matriz de coeficientes. Puede separar la información redundante.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Ventajas:*** Puede identificar patrones latentes y relaciones entre variables. Puede reducir la redundancia y la dimensionalidad.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Desventajas:*** Puede ser complejo y computacionalmente costoso. La interpretación puede ser desafiante debido a la naturaleza latente de los factores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfc29ac",
   "metadata": {},
   "source": [
    "### Validación y Significancia de Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410dfd1",
   "metadata": {},
   "source": [
    "#### Definición:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f361d3",
   "metadata": {},
   "source": [
    "La validación de variables se refiere a determinar si las variables seleccionadas son estadísticamente significativas y tienen un impacto real en la predicción o el análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de817e0",
   "metadata": {},
   "source": [
    "#### Métodos de Validación y Significancia:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743ee38e",
   "metadata": {},
   "source": [
    "- ***Pruebas Estadísticas:*** Las pruebas estadísticas son herramientas utilizadas para evaluar si las diferencias o relaciones observadas en los datos son estadísticamente significativas o si podrían haber ocurrido por azar. Estas pruebas involucran la comparación de muestras de datos y la utilización de distribuciones estadísticas para calcular la probabilidad de obtener los resultados observados bajo una hipótesis nula. Si esta probabilidad (valor $p$) es lo suficientemente baja, se rechaza la hipótesis nula y se concluye que hay evidencia estadística de una relación o diferencia significativa. Por ejemplo, en el contexto empresarial, se podría usar una prueba estadística para determinar si existe una diferencia significativa en las ventas entre dos grupos de productos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Validación Cruzada:*** La validación cruzada es una técnica que se utiliza para evaluar el rendimiento de un modelo de aprendizaje automático y estimar cómo se generalizará a datos no vistos. Implica dividir el conjunto de datos en varias partes, donde una parte se reserva para probar el modelo y las otras partes se utilizan para entrenarlo. Este proceso se repite varias veces, de modo que cada parte del conjunto de datos se utiliza tanto para entrenar como para probar el modelo. La validación cruzada nos proporciona una estimación más confiable del rendimiento del modelo en datos nuevos y ayuda a evitar el sobreajuste. Por ejemplo, en el ámbito empresarial, se podría usar la validación cruzada para evaluar el rendimiento de un modelo de predicción de demanda de productos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Bootstrapping:*** El bootstrapping es una técnica de muestreo que se utiliza para estimar la distribución de una estadística poblacional a partir de una muestra de datos. Implica generar múltiples muestras de tamaño similar al de la muestra original mediante muestreo con reemplazo. Luego, se calcula la estadística de interés en cada una de estas muestras generadas. Esta técnica nos proporciona intervalos de confianza para la estadística de interés y nos permite realizar inferencias sobre la población subyacente. En el contexto empresarial, el bootstrapping se podría aplicar para estimar el intervalo de confianza de los beneficios esperados de un nuevo proyecto de inversión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e990744a",
   "metadata": {},
   "source": [
    "#### Aplicabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b791a",
   "metadata": {},
   "source": [
    "- ***Aplicar:*** Los métodos de selección de variables son apropiados cuando se busca construir modelos más precisos, reducir el ruido y mejorar la interpretación de los resultados. Son útiles cuando se tienen muchas variables y se desea eliminar las irrelevantes o redundantes. También son útiles cuando se quiere evitar el sobreajuste y mejorar la generalización del modelo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***No Aplicar:*** Los métodos de selección de variables pueden no ser necesarios en conjuntos de datos pequeños o cuando las variables son conocidas y relevantes para el análisis. No son apropiados si se descartan variables importantes debido a la falta de correlación lineal o si se ignoran interacciones complejas entre variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f8f0a4",
   "metadata": {},
   "source": [
    "### Ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33460472",
   "metadata": {},
   "source": [
    "#### Ejemplo 1: Identificación de Características Relevantes en Datos de Ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd66f70",
   "metadata": {},
   "source": [
    "Una empresa de retail, se busca determinar qué características de los productos tienen un impacto significativo en las ventas. Se dispone de un conjunto de datos que incluye información como precio, categoría del producto, promociones, y reseñas de clientes. El objetivo es utilizar métodos de selección de características para identificar las variables más influyentes en las ventas.\n",
    "\n",
    "Se aplicará el método de `SelectKBest` para seleccionar las mejores características basadas en su relación con las ventas. Además, se calculará la matriz de correlación para identificar posibles relaciones entre las variables.\n",
    "\n",
    "Se generará una matriz de correlación con un mapa de calor para visualizar las relaciones entre las características y las ventas. Además, se graficarán las características seleccionadas en función de las ventas para analizar su comportamiento.\n",
    "\n",
    "A partir de los resultados obtenidos, se identificarán las características más relevantes para las ventas. Se analizará cómo varían las ventas en función de estas características y se evaluará si las relaciones encontradas tienen sentido desde una perspectiva empresarial. Esto permitirá tomar decisiones informadas para mejorar las estrategias de ventas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Generar datos de ejemplo\n",
    "X, y = make_regression(n_samples=100, n_features=5, noise=0.3, random_state=42)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(X, columns=['Precio', 'Categoria', 'Promociones', 'Resenas', 'Otro'])\n",
    "df['Ventas'] = y\n",
    "\n",
    "# Calcular correlación y selección de características\n",
    "corr_matrix = df.corr()\n",
    "selector = SelectKBest(score_func=f_regression, k=3)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Visualización de matriz de correlación y características seleccionadas\n",
    "plt.figure(figsize=(5, 4))\n",
    "#sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, center=0, linewidths=1, annot=True, fmt=\".2f\")\n",
    "\n",
    "plt.title(\"Matriz de Correlación\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.scatter(X_new[:, 0], y, label='Precio')\n",
    "plt.scatter(X_new[:, 1], y, label='Promociones')\n",
    "plt.scatter(X_new[:, 2], y, label='Resenas')\n",
    "plt.xlabel('Características')\n",
    "plt.ylabel('Ventas')\n",
    "plt.title('Características vs Ventas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8af75b",
   "metadata": {},
   "source": [
    "La matriz de correlación es una representación visual de las relaciones lineales entre las variables en un conjunto de datos. Cada celda en la matriz muestra el coeficiente de correlación entre dos variables. El coeficiente de correlación es un número que indica la fuerza y la dirección de la relación entre dos variables. Puede tomar valores entre -1 y 1, donde:\n",
    "\n",
    "Si el coeficiente de correlación es cercano a 1, indica una correlación positiva fuerte, lo que significa que a medida que una variable aumenta, la otra también tiende a aumentar.\n",
    "Si el coeficiente de correlación es cercano a -1, indica una correlación negativa fuerte, lo que significa que a medida que una variable aumenta, la otra tiende a disminuir.\n",
    "Si el coeficiente de correlación es cercano a 0, indica una correlación débil o nula, lo que significa que no hay una relación lineal clara entre las variables.\n",
    "Interpretar la matriz de correlación implica observar los valores en las celdas para identificar las relaciones entre las variables. Por ejemplo, si en la matriz se observan coeficientes de correlación altos y positivos entre dos variables, eso sugiere que hay una relación directa entre esas variables, y cuando una aumenta, la otra también lo hace.\n",
    "\n",
    "En el contexto del curso \"Analítica de Datos para la Toma de Decisiones Empresariales\", la matriz de correlación es una herramienta importante para comprender cómo las diferentes variables pueden estar relacionadas entre sí en un conjunto de datos empresariales. Esto puede ayudar a identificar patrones, tendencias y posibles factores que afectan el rendimiento empresarial, lo que a su vez puede guiar la toma de decisiones informadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eac617",
   "metadata": {},
   "source": [
    "## Modelos generales para pronósticos a corto plazo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc1560b",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91e8e72",
   "metadata": {},
   "source": [
    "En esta sección, exploraremos los modelos de pronóstico a corto plazo, que son herramientas esenciales en la toma de decisiones empresariales. Estos modelos nos permiten prever las tendencias futuras y hacer predicciones precisas basadas en datos históricos y patrones observados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72788e02",
   "metadata": {},
   "source": [
    "### Definición y Conceptos Clave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5582580",
   "metadata": {},
   "source": [
    "Los modelos de pronóstico a corto plazo son técnicas analíticas que se utilizan para predecir valores futuros de una variable basada en datos históricos. Estos modelos son especialmente útiles cuando se busca anticipar el comportamiento en un horizonte de tiempo relativamente cercano, como días, semanas o meses. Algunos conceptos clave incluyen:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f147ff4a",
   "metadata": {},
   "source": [
    "#### Serie de Tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151b3e9c",
   "metadata": {},
   "source": [
    "Una [serie de tiempo](https://en.wikipedia.org/wiki/Time_series) es una secuencia de observaciones realizadas en intervalos de tiempo regulares. Estos datos están indexados en función del tiempo y se utilizan para analizar patrones, tendencias y variabilidad a lo largo del tiempo. Las series de tiempo se encuentran en una amplia variedad de campos, como economía, finanzas, meteorología, ventas y más. Pueden ser unidimensionales (una única variable) o multidimensionales (varias variables relacionadas)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba99232a",
   "metadata": {},
   "source": [
    "#### Tendencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dbd98a",
   "metadata": {},
   "source": [
    "La tendencia en una serie de tiempo se refiere a la dirección general en la que los datos se mueven a lo largo del tiempo. Puede ser ascendente (crecimiento) o descendente (declive). La identificación de la tendencia es fundamental para comprender el comportamiento subyacente de los datos. Las tendencias pueden ser lineales o no lineales y pueden ser afectadas por factores económicos, sociales y tecnológicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037f09c7",
   "metadata": {},
   "source": [
    "#### Estacionalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd23a90a",
   "metadata": {},
   "source": [
    "La [estacionalidad](https://en.wikipedia.org/wiki/Seasonality) se refiere a patrones recurrentes que ocurren en intervalos regulares dentro de una serie de tiempo. Estos patrones suelen estar asociados con factores estacionales, como las estaciones del año, días de la semana o eventos regulares. La estacionalidad puede ser aditiva o multiplicativa. Una estacionalidad aditiva significa que el efecto estacional se suma al nivel base de la serie, mientras que una estacionalidad multiplicativa significa que el efecto estacional se multiplica por el nivel base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f3e9b",
   "metadata": {},
   "source": [
    "#### Componente Residual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5cf4c0",
   "metadata": {},
   "source": [
    "El componente residual es la parte de una serie de tiempo que no puede ser explicada por la tendencia o la estacionalidad. Representa el ruido aleatorio, las fluctuaciones y las influencias impredecibles en los datos. El análisis del componente residual es importante para evaluar si un modelo de pronóstico está capturando adecuadamente las variaciones no explicadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f7b7a7",
   "metadata": {},
   "source": [
    "#### Procedimiento de Trabajo y Casos de Uso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62259633",
   "metadata": {},
   "source": [
    "- ***Recopilación de Datos:*** Recolectar datos históricos en intervalos de tiempo regulares.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Exploración y Visualización:*** Graficar los datos para identificar tendencias y patrones estacionales. Esto puede incluir trazar la serie de tiempo, calcular estadísticas descriptivas y detectar valores atípicos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Descomposición:*** Descomponer la serie de tiempo en sus componentes clave: tendencia, estacionalidad y componente residual.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Modelado y Pronóstico:*** Utilizar métodos de pronóstico adecuados, como Suavización Exponencial, ARIMA, regresión, etc., para predecir los valores futuros basados en los componentes identificados.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Evaluación y Ajuste:*** Evaluar el rendimiento del modelo utilizando indicadores como MAE, MSE, RMSE y MAPE. Ajustar el modelo si es necesario para mejorar la precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e28e5c2",
   "metadata": {},
   "source": [
    "#### Ventajas y Desventajas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d16184",
   "metadata": {},
   "source": [
    "***Ventajas:***\n",
    "\n",
    "- ***Toma de Decisiones Informadas:*** Los modelos de pronóstico ayudan a tomar decisiones empresariales basadas en datos históricos y patrones observados.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Anticipación de Tendencias:*** Permite anticipar tendencias futuras y comportamientos estacionales, lo que ayuda a planificar y optimizar recursos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Análisis de Impacto:*** Permite evaluar el impacto de cambios en variables clave en el futuro.\n",
    "\n",
    "***Desventajas:***\n",
    "\n",
    "- ***Datos Insuficientes:*** Los modelos de pronóstico requieren una cantidad suficiente de datos históricos para ser efectivos. En situaciones con datos limitados, la precisión puede ser baja.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Incertidumbre:*** Los modelos de pronóstico no pueden predecir eventos inesperados o disruptivos, lo que puede afectar la precisión de las predicciones.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Sensibilidad a Cambios:*** Los modelos pueden ser sensibles a cambios abruptos en los datos históricos, lo que puede generar predicciones inexactas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3426b1b3",
   "metadata": {},
   "source": [
    "#### Aspectos a Considerar en el Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f601a82",
   "metadata": {},
   "source": [
    "- ***Tamaño de la Muestra:*** Es importante tener suficientes datos históricos para desarrollar modelos confiables.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Identificación de Patrones:*** Buscar tendencias y estacionalidades en los datos para seleccionar el modelo adecuado.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Ajuste de Parámetros:*** Algunos modelos, como ARIMA, requieren ajuste de parámetros. La selección incorrecta puede afectar la calidad del pronóstico.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Validación Cruzada:*** Utilizar técnicas como la validación cruzada para evaluar la capacidad del modelo para generalizar a nuevos datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Evaluación Continua:*** Los modelos deben ser evaluados y ajustados regularmente a medida que llegan nuevos datos para garantizar su precisión continua."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6046ce19",
   "metadata": {},
   "source": [
    "Ver ejemplo en el archivo [Ejemplos_C03_5_TimeSeriesAnalysis.ipynb](./Ejemplos_C03_5_TimeSeriesAnalysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c028bf6e",
   "metadata": {},
   "source": [
    "## Identificación de datos raros (outliers) y métodos explicativos en presencia de datos raros no identificados (Regresión robusta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3136d",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc95b9b",
   "metadata": {},
   "source": [
    " En esta sección, exploraremos cómo lidiar con un desafío común en el análisis de datos: los datos raros (outliers) y cómo afectan nuestros modelos predictivos. Además, aprenderemos sobre una técnica poderosa llamada regresión robusta que nos permite construir modelos de predicción confiables incluso en presencia de datos raros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c35924",
   "metadata": {},
   "source": [
    "### Identificación de Datos Raros (Outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d19ff6e",
   "metadata": {},
   "source": [
    "#### Definición y Concepto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42d705",
   "metadata": {},
   "source": [
    "Los datos raros, también conocidos como [outliers](https://en.wikipedia.org/wiki/Outlier), son observaciones que se desvían significativamente del patrón general de los datos en un conjunto. Estos valores atípicos pueden surgir debido a errores de medición, eventos inusuales o simplemente representar casos extremadamente inusuales. La identificación de outliers es crucial ya que pueden tener un impacto adverso en nuestros modelos predictivos al sesgar los resultados y afectar la interpretación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e3651f",
   "metadata": {},
   "source": [
    " #### Indicadores para la Identificación de Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0164a70",
   "metadata": {},
   "source": [
    "Para identificar datos raros, utilizamos diferentes indicadores y técnicas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb3da4b",
   "metadata": {},
   "source": [
    "##### Gráficos de Dispersión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07782fb2",
   "metadata": {},
   "source": [
    "Los gráficos de dispersión nos permiten visualizar la relación entre dos variables. Los outliers pueden aparecer como puntos aislados en el gráfico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0796a88",
   "metadata": {},
   "source": [
    "##### Diagrama de Caja (Boxplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf605d6",
   "metadata": {},
   "source": [
    "Los diagramas de caja son herramientas visuales que resumen la distribución de un conjunto de datos, mostrando la mediana, cuartiles y posibles valores atípicos. Los puntos fuera de los \"bigotes\" del diagrama se consideran outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5abcb7",
   "metadata": {},
   "source": [
    "##### Z-Score y Puntuación T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349ee3da",
   "metadata": {},
   "source": [
    "El [Z-Score](https://en.wikipedia.org/wiki/Standard_score) y la [puntuación T](https://en.wikipedia.org/wiki/Student%27s_t-test) (*t-student*) son medidas que indican cuántas desviaciones estándar una observación está lejos de la media. Valores altos en estas métricas pueden indicar outliers potenciales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f4eb51",
   "metadata": {},
   "source": [
    "##### Rango Intercuartílico (IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4916b49",
   "metadata": {},
   "source": [
    "El *IQR* es la diferencia entre el tercer cuartil y el primer cuartil en un diagrama de caja. Los valores fuera de $1.5$ veces el *IQR* por encima del tercer cuartil o por debajo del primer cuartil son considerados outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71a3d74",
   "metadata": {},
   "source": [
    "### Regresión Robusta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d44d79b",
   "metadata": {},
   "source": [
    "#### Desafíos de la Regresión Clásica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be45721",
   "metadata": {},
   "source": [
    "En la regresión clásica, estamos asumiendo que los datos siguen una distribución normal y que los outliers tienen un impacto limitado en nuestros resultados. Sin embargo, esto no siempre es cierto en la realidad. Los outliers pueden distorsionar severamente los coeficientes de regresión y hacer que nuestros modelos sean poco confiables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4999d440",
   "metadata": {},
   "source": [
    "#### Introducción a la Regresión Robusta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d22e7f",
   "metadata": {},
   "source": [
    "La [regresión robusta](https://en.wikipedia.org/wiki/Robust_regression) es una técnica que aborda los desafíos de los outliers al construir modelos de predicción más sólidos. A diferencia de la regresión clásica, la regresión robusta asigna menos peso a los datos que son influenciados por outliers, lo que permite que el modelo se adapte mejor a los patrones reales de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2489c59",
   "metadata": {},
   "source": [
    "#### Métodos de Regresión Robusta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264480e4",
   "metadata": {},
   "source": [
    "##### M-Estimadores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754a3a96",
   "metadata": {},
   "source": [
    "Los [M-Estimadores](https://en.wikipedia.org/wiki/M-estimator) son una clase de técnicas de regresión robusta que minimizan una función objetivo que combina la suma de residuos ponderados. Esto hace que el modelo sea menos sensible a los outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082afda0",
   "metadata": {},
   "source": [
    "##### Regresión MM (Mínimos Cuadrados Medianamente Ponderados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab135b8",
   "metadata": {},
   "source": [
    "Esta técnica combina las ventajas de los M-Estimadores y la mediana, lo que la hace más robusta en presencia de datos con outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e974c",
   "metadata": {},
   "source": [
    "##### Regresión Huber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5905b85",
   "metadata": {},
   "source": [
    "La [regresión Huber](https://en.wikipedia.org/wiki/Huber_loss) (*Huber loss*) utiliza una función de pérdida que es cuadrática cerca del origen y lineal lejos del origen. Esto permite que tenga un comportamiento robusto en la presencia de outliers sin descartar por completo su influencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d00bdd8",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71691a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Generar datos sintéticos con outliers\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "X = np.random.rand(n)\n",
    "y = 2*X + 1 + 0.2*np.random.randn(n)\n",
    "y[95] = 30  # Introducir un outlier\n",
    "\n",
    "# Gráfico de dispersión\n",
    "plt.scatter(X, y)\n",
    "plt.title('Gráfico de Dispersión con Outlier')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "\n",
    "# Calcular Z-Score\n",
    "z_scores = np.abs(stats.zscore(y))\n",
    "\n",
    "# Calcular puntuación T\n",
    "t_scores = np.abs((y - np.mean(y)) / np.std(y))\n",
    "\n",
    "# Diagrama de Caja\n",
    "plt.boxplot(y)\n",
    "plt.title('Diagrama de Caja')\n",
    "plt.show()\n",
    "\n",
    "# Regresión clásica\n",
    "X_constant = sm.add_constant(X)\n",
    "model = sm.OLS(y, X_constant).fit()\n",
    "\n",
    "# Regresión robusta usando M-Estimadores\n",
    "robust_model = sm.RLM(y, X_constant).fit()\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Resultados de la Regresión Clásica:\")\n",
    "print(model.summary())\n",
    "\n",
    "print(\"\\nResultados de la Regresión Robusta (M-Estimadores):\")\n",
    "print(robust_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f095c57",
   "metadata": {},
   "source": [
    "#### Análisis de Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cbd16d",
   "metadata": {},
   "source": [
    "***Regresión clásica:***\n",
    "\n",
    "| item  |  coef     | std err  |      t    |    P>t     |    [0.025 |   0.975]|\n",
    "|:-----:|:---------:|:--------:|:---------:|:----------:|:--------:|:-------:|\n",
    "|const  |  1.2891   |   0.530  |    2.434  |    0.017   |    0.238 |    2.340|\n",
    "|x1     |  1.9840   |   0.953  |    2.082  |    0.040   |    0.093 |    3.875|\n",
    "\n",
    "\n",
    "|Estadístico                 |  valor  | Estadístico                | Valor     |\n",
    "|:--------------------------:|:-------:|:--------------------------:|:---------:|\n",
    "|Omnibus:                    |  215.266| Durbin-Watson:             |      2.035|\n",
    "|Prob(Omnibus):              |    0.000| Jarque-Bera (JB):          |  38566.153|\n",
    "|Skew:                       |    9.787| Prob(JB):                  |       0.00|\n",
    "|Kurtosis:                   |   97.195| Cond. No.                  |       4.18|\n",
    "\n",
    "En resumen, la interpretación de los resultados es la siguiente:\n",
    "\n",
    "- Los valores $t$ y los valores $p$ indican la significancia estadística de los coeficientes. En este caso, el coeficiente del intercepto es estadísticamente significativo al nivel de significancia del $0.05$ ($p = 0.017$), mientras que el coeficiente de $x1$ es también significativo al mismo nivel ($p = 0.040$).\n",
    "\n",
    "- Los intervalos de confianza proporcionan un rango en el cual es probable que se encuentre el valor real del coeficiente en la población.\n",
    "\n",
    "- Las estadísticas de diagnóstico en la parte inferior de la tabla pueden ayudar a evaluar la calidad del ajuste del modelo y la validez de las suposiciones. Por ejemplo, un valor $p$ bajo en *Omnibus* y un valor alto en *Jarque-Bera* pueden indicar problemas con la normalidad de los residuos. El valor de *Durbin-Watson* se refiere a la autocorrelación en los residuos.\n",
    "\n",
    "En resumen, estos resultados sugieren que los coeficientes son significativos, pero los diagnósticos indican que el modelo podría tener problemas con la normalidad de los residuos y la posible autocorrelación. La regresión robusta podría proporcionar una estimación más confiable en este caso.\n",
    "\n",
    "***Regresión Robusta:***\n",
    "\n",
    "| item  |  coef     | std err  |      z    |    P>z     |    [0.025 |   0.975]|\n",
    "|:-----:|:---------:|:--------:|:---------:|:----------:|:--------:|:-------:|\n",
    "|const  |    1.0423 |    0.036 |    28.603 |      0.000 |    0.971       1.114\n",
    "|x1     |    1.9106 |    0.066 |    29.132 |      0.000 |    1.782       2.039\n",
    "\n",
    "- El valor \"$z$\" se calcula dividiendo el coeficiente por su error estándar, y el valor $p$ ($p>|z|$) representa la probabilidad de observar un valor $z$ igual o mayor si el coeficiente no tuviera ningún efecto en la variable dependiente. En este caso, los valores $p$ asociados con ambos coeficientes son $0.000$, lo que sugiere que tanto el intercepto como el coeficiente de $x1$ son estadísticamente significativos.\n",
    "\n",
    "En resumen, estos resultados confirman que tanto el intercepto como el coeficiente de la variable independiente son significativos en el modelo de regresión robusta utilizando *M-Estimadores*. Además, la regresión robusta ayuda a mitigar el impacto potencial de los outliers en los coeficientes estimados, proporcionando resultados más confiables en presencia de datos raros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd8d42",
   "metadata": {},
   "source": [
    "Ver ejemplo en el archivo [Ejemplos_C03_6_Outliers.ipynb](./Ejemplos_C03_6_Outliers.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
