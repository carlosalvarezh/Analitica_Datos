{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5281ece",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Analítica de datos para la toma de decisiones empresariales</h1>\n",
    "<h1 align=\"center\">Ejercicio: Feature Selection - Diabetes Indios Pima</h1>\n",
    "<h1 align=\"center\">Centro de Educación Continua</h1>\n",
    "<h1 align=\"center\">EAFIT</h1>\n",
    "<h1 align=\"center\">2023</h1>\n",
    "<h1 align=\"center\">MEDELLÍN - COLOMBIA </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7540c1f3",
   "metadata": {},
   "source": [
    "*** \n",
    "|![Gmail](https://img.shields.io/badge/Gmail-D14836?style=plastic&logo=gmail&logoColor=white)|<carlosalvarezh@gmail.com>|![Outlook](https://img.shields.io/badge/Microsoft_Outlook-0078D4?style=plastic&logo=microsoft-outlook&logoColor=white)|<calvar52@eafit.edu.co>|\n",
    "|-:|:-|--:|:--|\n",
    "|[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=plastic&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/carlosalvarez5/)|[![@alvarezhenao](https://img.shields.io/twitter/url/https/twitter.com/alvarezhenao.svg?style=social&label=Follow%20%40alvarezhenao)](https://twitter.com/alvarezhenao)|[![@carlosalvarezh](https://img.shields.io/badge/github-%23121011.svg?style=plastic&logo=github&logoColor=white)](https://github.com/carlosalvarezh)|[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/carlosalvarezh/Curso_CEC_EAFIT/blob/main/C02_Modelos_Prediccion_Pronostico.ipynb)|\n",
    "\n",
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/CCLogoColorPop1.gif?raw=true\" width=\"25\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license.(c) Carlos Alberto Alvarez Henao</td>\n",
    "</table>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95be8a0",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef37de59",
   "metadata": {},
   "source": [
    "Como científico de datos que trabaja con Python, es crucial entender la importancia de la selección de características al construir un modelo de aprendizaje automático. En problemas de ciencia de datos en la vida real, es casi raro que todas las variables en el conjunto de datos sean útiles para construir un modelo. Agregar variables redundantes reduce la capacidad de generalización del modelo y también puede disminuir la precisión general de un clasificador. Además, agregar más variables a un modelo aumenta la complejidad general del mismo.\n",
    "\n",
    "Según la [Ley de la Parsimonia de la 'Navaja de Occam'](https://en.wikipedia.org/wiki/Occam%27s_razor), la mejor explicación de un problema es aquella que implica el menor número posible de suposiciones. Por lo tanto, la selección de características se convierte en una parte indispensable en la construcción de modelos de aprendizaje automático.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd92f317",
   "metadata": {},
   "source": [
    "### Objetivos de Aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6110f0c8",
   "metadata": {},
   "source": [
    "- Comprender la importancia de la selección de características.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Familiarizarse con diferentes técnicas de selección de características.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Aplicar técnicas de selección de características en la práctica y evaluar el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e0b87f",
   "metadata": {},
   "source": [
    "### Selección de características en el aprendizaje automático"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449fab44",
   "metadata": {},
   "source": [
    "El objetivo de las técnicas de selección de características en el aprendizaje automático es encontrar el mejor conjunto de características que permita construir modelos optimizados de los fenómenos estudiados.\n",
    "\n",
    "Las técnicas de selección de características en el aprendizaje automático se pueden clasificar ampliamente en las siguientes categorías:\n",
    "\n",
    "- ***[Técnicas Supervisadas](https://en.wikipedia.org/wiki/Supervised_learning):*** Estas técnicas se pueden utilizar para datos etiquetados y para identificar las características relevantes que aumentan la eficiencia de modelos supervisados como la clasificación y la regresión. Por ejemplo, [regresión lineal](https://en.wikipedia.org/wiki/Linear_regression), [árbol de decisión](https://en.wikipedia.org/wiki/Decision_tree), [Máquinas de Vectores de Soporte](https://en.wikipedia.org/wiki/Support_vector_machine), etc.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***[Técnicas No Supervisadas](https://en.wikipedia.org/wiki/Unsupervised_learning):*** Estas técnicas se pueden utilizar para datos no etiquetados. Por ejemplo, [Agrupamiento K-Means](https://en.wikipedia.org/wiki/K-means_clustering), [Análisis de Componentes Principales](https://en.wikipedia.org/wiki/Principal_component_analysis), [Agrupamiento Jerárquico](https://en.wikipedia.org/wiki/Hierarchical_clustering), etc.\n",
    "\n",
    "Desde un punto de vista taxonómico, estas técnicas se clasifican en métodos de [filtro](https://en.wikipedia.org/wiki/Feature_selection#Filter_method), [envoltura](https://en.wikipedia.org/wiki/Feature_selection#Wrapper_method), [embebidos](https://en.wikipedia.org/wiki/Feature_selection#Embedded_method) y métodos híbridos.\n",
    "\n",
    "Ahora, discutamos en detalle algunas de estas populares técnicas de selección de características en el aprendizaje automático."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be43799c",
   "metadata": {},
   "source": [
    "## Análisis Exploratorio de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e7b26d",
   "metadata": {},
   "source": [
    "### Entendiendo el conjunto de datos: Diabetes de los Indios Pima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f4dcf1",
   "metadata": {},
   "source": [
    "Pongámonos primero en contexto: El Conjunto de Datos de [Diabetes de los Indios Pima](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database) implica predecir el inicio de la diabetes en un plazo de $5$ años en los Indios Pima dados detalles médicos.\n",
    "\n",
    "Es un problema de [clasificación binaria](https://en.wikipedia.org/wiki/Binary_classification) ($2$ clases). El número de observaciones para cada clase no está equilibrado. Hay $768$ observaciones con $8$ variables de entrada y $1$ variable de salida. Se cree que los valores faltantes están codificados con valores cero. Los nombres de las variables son los siguientes:\n",
    "\n",
    "Tenemos una variable objetivo:\n",
    "\n",
    "- `Outcome`: $1$ (tiene diabetes) y $0$ (no tiene diabetes) ($Y$)\n",
    "\n",
    "Contamos con 8 variables explicativas (todas numéricas) que son:\n",
    "\n",
    "- `Pregnancies`: Número de veces que está embarazada. ($X_1$)\n",
    "\n",
    "- `Glucose`: Prueba de tolerancia a la glucosa oral: OGTT (concentración de glucosa en plasma de dos horas después de 75 g de glucosa anhidra en mg/dl) ($X_2$)\n",
    "\n",
    "- `BloodPressure`: Presión arterial diastólica en mmHg ($X_3$)\n",
    "\n",
    "- `SkinThickness`: Grosor del pliegue cutáneo del tríceps (en mm) ($X_4$)\n",
    "\n",
    "- `Insulin`: 2 h de insulina sérica en U/ml ($X_5$)\n",
    "\n",
    "- `BMI`: índice de masa corporal, IMC, en kg/m2 ($X_6$)\n",
    "\n",
    "- `DiabetesPedigreeFunction`: Función que representa la probabilidad de que padezcan la enfermedad extrapolando la historia de sus antepasados. ($X_7$)\n",
    "\n",
    "- `AGE`: Edad en años. ($X_8$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d58828",
   "metadata": {},
   "source": [
    "### Cargue de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d509ef1c",
   "metadata": {},
   "source": [
    "Carguemos el conjunto de datos y realicemos una breve exploración del dataset para tener un mejor entendimiento del problema a desarrollar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b2665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import missingno as msno\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f512559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargue de datos\n",
    "df = pd.read_csv(\"Data/diabetes2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ac12ca",
   "metadata": {},
   "source": [
    "Damos una rápida inspección visual de los datos, tanto en las primeras como en las últimas entradas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdb79a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f4b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969584e",
   "metadata": {},
   "source": [
    "Se observa que hay algunos valores `NaN`. Ahora miremos la información general del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab388c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2f60c",
   "metadata": {},
   "source": [
    "Efectivamente todas las columnas de las características cuentan con algunos datos faltantes. Vamos a chequear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed09c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fbe4c7",
   "metadata": {},
   "source": [
    "Veamos un resumen de las estadísticas descriptivas de cada una de las columnas numéricas del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977edf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7067904",
   "metadata": {},
   "source": [
    "Observemos que los valores mínimos en las columnas `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin` y `BMI` es de $0$, lo que no es posible. Dichos valores de $0$ representan valores faltanes, por lo que hay qué reemplazarlos por `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']\n",
    "df[cols] = df[cols].replace({'0':np.nan, 0:np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b751749",
   "metadata": {},
   "source": [
    "volvamos a ver el resumen del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56235b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac843ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba79c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625cbf7e",
   "metadata": {},
   "source": [
    "Visualicemos el número de valores faltantes empleando un diagrama de barras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb45691",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install missingno #ejecutar únicamente la primera vez para su instalación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c0b094",
   "metadata": {},
   "source": [
    "Se observa que la variable `Insulin` contiene la mayor cantidad de datos faltantes, seguida por la variable `SkinThickness`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07248c57",
   "metadata": {},
   "source": [
    "Ahora exploremos cómo se correlacionan las diferentes variables entre sí:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19581f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "sns.heatmap(corr, annot=True, square=True)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72ede4c",
   "metadata": {},
   "source": [
    "Del gráfico de correlación podemos extraer la siguiente información\n",
    "\n",
    "***Correlaciones positivas:***\n",
    "\n",
    "- `Glucose` e `Insulin` ($0.59$): Niveles más altos de insulina corresponden a niveles más altos de glucosa en sangre.\n",
    "- `Age` y `Pregnancies` ($0.54$): Las mujeres mayores tienden a tener más embarazos.\n",
    "- `Glucose` y `Outcome` ($0.48$): Las mujeres con niveles más altos de glucosa tienen más probabilidad de tener diabetes.\n",
    "- `SkinThickness` y `BMI` ($0.63$): Las mujeres con valores más altos de grosor del pliegue cutáneo tienden a tener un *IMC* más alto, lo que a menudo indica sobrepeso u obesidad.\n",
    "\n",
    "***Correlación negativa:***\n",
    "\n",
    "- `DiabetesPedigreeFunction` y `Pregnancies`: $-0.031$\n",
    "\n",
    "En general, un coeficiente de correlación por encima de $0.7$ entre dos características sugiere multicolinealidad. Sin embargo, en estos datos, no hay tales correlaciones altas, lo que indica que la multicolinealidad no es una preocupación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9acdae",
   "metadata": {},
   "source": [
    "Ahora, vamos a agrupar los datos por la variable `Outcome`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405da601",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Outcome').mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5663a8",
   "metadata": {},
   "source": [
    "De estos resultados resaltemos:\n",
    "\n",
    "- Las mujeres diabéticas tienden a tener un mayor número de embarazos, niveles más altos de glucosa, presión arterial, grosor de la piel, insulina, IMC y función del pedigrí de la diabetes que aquellas que no son diabéticas y también es probable que sean mayores.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Ambos grupos tienen un *IMC* mucho más alto que el rango normal $(18.5$ a $25)$, lo que indica obesidad.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Las mujeres que tienen diabetes tienen más probabilidades de tener antecedentes ancestrales de diabetes.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Las mujeres con diabetes tienen un promedio de insulina superior al rango normal ($16$ a $166 muU/ml$), mientras que los que no tienen diabetes tienen niveles de insulina promedio en el rango normal.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Ambos grupos tienen un promedio de glucosa superior al rango normal ($\\leq 100 mg/dL$). Podría indicar que algunas mujeres no diabéticas tienen riesgo de tener diabetes en el futuro, especialmente aquellas con niveles más altos de insulina.\n",
    "\n",
    "Ahora, veamos una representación gráfica de los mismos resultados empleando un gráfico de líneas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Outcome').mean().T.plot(figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e29fe",
   "metadata": {},
   "source": [
    "El gráfico de líneas nos ayuda a visualizar lo mismo, que el valor medio de cada característica es mayor para las mujeres diabéticas que para las no diabéticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbed1af1",
   "metadata": {},
   "source": [
    "Ahora, grafiquemos los datos empleando diagrama de barras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00446dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relation between each feature and the outcome variable by barplot.\n",
    "plt.figure(figsize = (20,10))\n",
    "for i,col in enumerate(set(df.columns) - {'Outcome'}):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    sns.barplot(data = df, x = 'Outcome',y = col,)\n",
    "    plt.xlabel('Outcome', fontsize = 15)\n",
    "    plt.xticks(fontsize = 10)\n",
    "    plt.ylabel(col, fontsize = 15)\n",
    "    plt.yticks(fontsize = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0962dde8",
   "metadata": {},
   "source": [
    "Veamos cómo es su representación empleando diagramas de caja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff5380",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "for i,col in enumerate(set(df.columns) - {'Outcome'}):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    sns.boxplot(data = df,x = 'Outcome', y = col )\n",
    "    plt.xlabel('Outcome', fontsize = 15)\n",
    "    plt.xticks(fontsize = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d7a8bd",
   "metadata": {},
   "source": [
    "Solo para asegurarnos de que los datos no estén desequilibrados, trazamos el gráfico de recuento para la variable de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc30470",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'Outcome', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us first analyze the distribution of the target variable\n",
    "\n",
    "labels = ['Non-Diabetic','Datiabetic']\n",
    "MAP = {}\n",
    "for e, i in enumerate(df['Outcome'].unique()):\n",
    "    MAP[i] = labels[e]\n",
    "#MAP={0:'Not-Survived',1:'Survived'}\n",
    "df1 = df.copy()\n",
    "df1['Outcome'] = df1['Outcome'].map(MAP)\n",
    "explode = np.zeros(len(labels))\n",
    "explode[-1] = 0.1\n",
    "print('\\033[1mOutcome Variable Distribution'.center(55))\n",
    "plt.pie(df1['Outcome'].value_counts(), labels=df1['Outcome'].value_counts().index, counterclock = False, shadow = True, \n",
    "        explode = explode, autopct = '%1.1f%%', radius = 1, startangle = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87620ff8",
   "metadata": {},
   "source": [
    "### Análisis Univariado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4c28d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99921f44",
   "metadata": {},
   "source": [
    "Ahora tenemos que imputar los valores faltantes, pero para eso primero veamos el tipo de distribuciones de nuestros datos para decidir cómo podemos imputarlos.\n",
    "\n",
    "El método de imputación debe decidirse después de considerar la distribución de los datos: *distribución normal* o *distribución sesgada* (ya sea a la derecha o a la izquierda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9d0406",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 25))\n",
    "for i, col in enumerate(set(df.columns) - {'Outcome'}):\n",
    "    plt.subplot(6, 4, i + 1)\n",
    "    sns.histplot(df[col], kde = True)  # Utiliza histplot con kde=True para trazar la distribución y la estimación de densidad.\n",
    "    plt.xlabel(col, fontsize=15)\n",
    "    plt.xticks(fontsize=15)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcb8c7e",
   "metadata": {},
   "source": [
    "La distribución de las variables `BloodPressure`, `SkinThickness` y `BMI` es normal, mientras que para todas las demás características está sesgada. Por lo tanto, para estos, podemos reemplazar los valores faltantes por la media y, para el resto, por la mediana. \n",
    "\n",
    "(***NOTA:*** Recuerde que esto es solo una idea. Las decisiones deberán ser enmarcadas en el contexto del tipo de problema que se está desarrollando)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc8969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc701f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy(deep = True)\n",
    "\n",
    "#for column in df1[['BloodPressure', 'SkinThickness', 'BMI']]: # corregir\n",
    "for column in df1[['BloodPressure', 'BMI']]:\n",
    "    df1[column] = df1[column].fillna(df1[column].mean())\n",
    "\n",
    "for column in df1[['Pregnancies','Glucose','DiabetesPedigreeFunction','Age']]:\n",
    "    df1[column] = df1[column].fillna(df1[column].mean())\n",
    "    #df1[column] = df1[column].fillna(df1[column].median()) #corregir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97002287",
   "metadata": {},
   "source": [
    "Veamos el antes y el después de esta operación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dbc4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f17ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e55ee5",
   "metadata": {},
   "source": [
    "Dado que el grosor de la piel y la insulina tienen un gran número de valores faltantes, por lo que utilizamos [`KNNImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html) para estas características, ya que el uso de media/mediana genera muchos valores atípicos en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70daf903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors = 5, weights='distance', metric = 'nan_euclidean',)\n",
    "imputed_data = imputer.fit_transform(df1) \n",
    "df2 = pd.DataFrame(imputed_data)\n",
    "df2.columns = df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999b62a",
   "metadata": {},
   "source": [
    "Veamos cómo quedó el `df2`resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4bdffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47ddc89",
   "metadata": {},
   "source": [
    "ahora revisemos los estadísticos tanto del `df` original como el final, `df2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97907bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eefd21",
   "metadata": {},
   "source": [
    "Realicemos diagramas de caja para comprobar si hay valores atípicos (después de completar los valores faltantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f9c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "for i,col in enumerate(set(df2.columns) - {'Outcome'}):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    sns.boxplot(data = df2,x = col)\n",
    "    plt.xlabel(col, fontsize = 15)\n",
    "    plt.xticks(fontsize = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e18997",
   "metadata": {},
   "source": [
    "La distribución de edades está muy sesgada, lo que significa que la mayoría de las mujeres eran jóvenes.\n",
    "\n",
    "Además, vemos valores atípicos para cada característica. Los valores atípicos son valores dentro de un conjunto de datos que varían mucho de los demás, es decir, son mucho más grandes o significativamente más pequeños. Tenemos que eliminar/reemplazar los valores atípicos para obtener una mayor precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2071b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df2):\n",
    "    outliers = pd.DataFrame(columns=[\"Feature\", \"No.of Outliers\", \"Handled?\"])\n",
    "    for col in list(set(df2.select_dtypes(include=np.number).columns) - {'Outcome'}):\n",
    "        q1 = df2[col].quantile(0.25)\n",
    "        q3 = df2[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        low = q1 - (1.5 * iqr)\n",
    "        high = q3 + (1.5 * iqr)\n",
    "        n = df2.loc[(df2[col] < low) | (df2[col] > high)].shape[0]\n",
    "\n",
    "        df2.loc[(df2[col] < low), col] = low\n",
    "        df2.loc[(df2[col] > high), col] = high\n",
    "\n",
    "        #handled = df2[col].all() < high\n",
    "        handled = all(df2[col] < high)\n",
    "        outliers = pd.concat([outliers, pd.DataFrame({'Feature': [col], \"No.of Outliers\": [n], \"Handled?\": [handled]})])\n",
    "\n",
    "    outliers['Handled?'] = outliers['Handled?'].astype(bool)\n",
    "\n",
    "    return outliers\n",
    "\n",
    "detect_outliers(df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d3a78c",
   "metadata": {},
   "source": [
    "Ahora, dado que se reemplaza cada valor atípico, se realizan diagramas de caja para cada característica después de tratar los valores atípicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8758ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "for i,col in enumerate(set(df2.columns) - {'Outcome'}):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    sns.boxplot(data = df2, x = col)\n",
    "    plt.xlabel(col, fontsize = 15)\n",
    "    plt.xticks(fontsize = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185cf21a",
   "metadata": {},
   "source": [
    "Por lo tanto, los datos ahora están libres de valores atípicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b0b682",
   "metadata": {},
   "source": [
    "### Análisis bivariado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a94eef",
   "metadata": {},
   "source": [
    "El [análisis bivariado](https://en.wikipedia.org/wiki/Bivariate_analysis) es el estudio de la relación entre dos variables en un conjunto de datos. En otras palabras, implica analizar cómo dos variables diferentes están relacionadas o se comportan juntas. Esto se logra al examinar la asociación, correlación o dependencia entre estas dos variables y puede ayudarnos a comprender mejor cómo una variable afecta o se relaciona con la otra.\n",
    "\n",
    "El análisis bivariado es fundamental para explorar patrones, identificar tendencias y descubrir posibles relaciones en los datos. Puede involucrar la visualización de datos, como gráficos de dispersión o tablas de contingencia, así como la realización de pruebas estadísticas para determinar si existe una relación significativa entre las dos variables.\n",
    "\n",
    "Un gráfico de pares nos permite visualizar las relaciones entre dos variables así como ver la distribución de cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d7d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = df2, kind = 'scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1779100",
   "metadata": {},
   "source": [
    "De las gráficas observamos:\n",
    "\n",
    "- Existe una alta relación lineal entre el grosor de la piel y el IMC (también tuvieron la correlación más alta).\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Los niveles de insulina y glucosa muestran una alta relación lineal (lo cual también quedó claro en la matriz de correlación)\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Ahora, para ver la relación entre dos variables con respecto a la tercera variable, `Outcome`, utilizamos el parámetro `hue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753be98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = df2, hue = 'Outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac03c36",
   "metadata": {},
   "source": [
    "del diagrama de pares se observa:\n",
    "\n",
    "- Las mujeres diabéticas tienden a tener un valor más alto para cada característica, es decir, tienen más edad, son más obesas y tienen más números de embarazos, niveles altos de PA, glucosa e insulina.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Además, si vemos los gráficos de niveles de glucosa con otras características, vemos que los niveles más altos de glucosa son un factor clave para la diabetes, independientemente de los otros factores, es decir, si la mujer tiene niveles de glucosa más altos, es más probable que tenga diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347bea2e",
   "metadata": {},
   "source": [
    "Otra gráfica usada para este tipo de análisis es la llamada *joint plot*, y consta de tres gráficos en uno. El centro contiene la relación bivariada entre las variables $x$ e $y$. Los gráficos superior y derecho muestran la distribución univariada de las variables, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x = 'Glucose', y = 'Insulin', data = df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a567c3",
   "metadata": {},
   "source": [
    "Muestra la relación lineal entre la glucosa y la insulina, también sus distribuciones univariadas, ambas están sesgadas hacia la derecha.\n",
    "\n",
    "Ahora, hacemos el gráfico conjunto con respecto a la variable `Outcome` con la ayuda del parámetro `hue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x = 'BMI', y = 'SkinThickness', data = df2, hue = 'Outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ee347",
   "metadata": {},
   "source": [
    "Muestra la relación lineal entre el IMC y el grosor de la piel del tríceps.\n",
    "\n",
    "Es probable que las mujeres diabéticas sean más obesas y tengan un mayor grosor de la piel del tríceps, además de sus distribuciones univariadas, lo que muestra que ambas características tienen una distribución sesgada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d92edfb",
   "metadata": {},
   "source": [
    "## Selección de características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85897f5c",
   "metadata": {},
   "source": [
    "### Características más importantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e2ffb9",
   "metadata": {},
   "source": [
    "Podemos comprobar la importancia de cada característica utilizando el algoritmo de [Extra Tree Regresor](https://en.wikipedia.org/wiki/Random_forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704d97fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# Crear el modelo\n",
    "model = ExtraTreesRegressor()\n",
    "\n",
    "# Supongamos que 'df2' contiene tus datos\n",
    "x = df2.drop(\"Outcome\", axis=1)\n",
    "y = df2[\"Outcome\"]\n",
    "\n",
    "# Ajustar el modelo a tus datos\n",
    "model.fit(x, y)\n",
    "\n",
    "# Imprimir las características de importancia\n",
    "print(model.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee414c6",
   "metadata": {},
   "source": [
    "Los resultados obtenidos representan las características de importancia del modelo `ExtraTreesRegressor` para predecir la variable objetivo `Outcome`. Cada valor en la lista corresponde a una característica específica del conjunto de datos. Estos valores de importancia son numéricos y reflejan la contribución relativa de cada característica para hacer predicciones precisas.\n",
    "\n",
    "Presentamos algunas observaciones generales sobre los resultados:\n",
    "\n",
    "- ***Las características de importancia suman 1:*** La suma de todos los valores de importancia es igual a $1$, lo que significa que representan la proporción de la importancia total distribuida entre las características. Esto es útil para entender cuánto contribuye cada característica en relación con las demás.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Características más importantes:*** Las características con valores de importancia más altos son aquellas que tienen un mayor impacto en las predicciones del modelo. En este caso, las características con los valores más altos son la segunda característica (`Glucose`), la sexta característica (`BMI`), la quinta característica, `Insulin` y la octava característica (`Age`).\n",
    "\n",
    "Ahora, realicemos una visualización emplenado un diagrama de barras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08612045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing by bar graph\n",
    "feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': x.columns})\n",
    "plt.figure(figsize = (5, 5))\n",
    "sns.barplot(x = 'Value', y = 'Feature', data = feature_imp.sort_values(by = 'Value', ascending = False))\n",
    "plt.title('Features importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26281678",
   "metadata": {},
   "source": [
    "Se corrobora lo indicado en el anterior resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c8a63f",
   "metadata": {},
   "source": [
    "### Análisis de Componentes Principales (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e947fa20",
   "metadata": {},
   "source": [
    "El [Análisis de Componentes Principales](https://en.wikipedia.org/wiki/Principal_component_analysis) (*PCA*) es un método de reducción de dimensionalidad que convierte un conjunto de variables correlacionadas en un conjunto de variables no correlacionadas, llamadas componentes principales, al tiempo que reduce la dimensionalidad del conjunto de datos.\n",
    "\n",
    "Los *Componentes Principales* (*PC*) son [combinaciones lineales](https://en.wikipedia.org/wiki/Linear_combination) de las características originales del conjunto de datos que se crean de manera que capturen la máxima variabilidad en los datos. En el contexto del *Análisis de Componentes Principales* (*PCA*), los *PC* se ordenan en función de cuánta variabilidad explican.\n",
    "\n",
    "- ***PC1 (Primer Componente Principal):*** Representa la dirección en la cual los datos tienen la mayor variabilidad. Es la componente principal más importante y explica la mayor proporción de la variabilidad total en los datos. El *PC1* está compuesto por combinaciones de las características originales que tienen las mayores cargas. Las cargas indican la contribución de cada característica a *PC1*. Si una característica tiene una alta carga positiva en *PC1*, significa que esta característica está fuertemente asociada con *PC1*. Se puede interpretar a *PC1* como una combinación específica de características que influyen significativamente en la variabilidad de los datos.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***PC2 (Segundo Componente Principal):*** Es la segunda componente principal más importante y explica la variabilidad adicional que no se captura en *PC1*. Aunque es menos importante que *PC1*, sigue siendo relevante. El *PC2* está compuesto por combinaciones de las características originales que tienen las segundas mayores cargas en términos de su influencia en la variabilidad de los datos. Se puede interpretar a *PC2* como una combinación específica de características que contribuyen a la variabilidad que no está capturada por *PC1*.\n",
    "\n",
    "Así sucesivamente. \n",
    "\n",
    "En cuanto a la interpretación de estos componentes en el contexto de los datos, podemos considerar lo siguiente:\n",
    "\n",
    "- ***PC1*** puede representar una combinación de características que tienen un impacto significativo en la diabetes o en la predicción de resultados.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***PC2*** podría capturar patrones adicionales relacionados con la diabetes que no se explican completamente por *PC1*.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***PC3*** y ***PC4*** pueden revelar patrones aún más sutiles o específicos en los datos.\n",
    "\n",
    "La elección de cuántos de estos componentes principales retener depende de los objetivos analíticos y de cuánta variabilidad se está dispuesto a sacrificar para reducir la dimensionalidad de los datos. Por lo general, se seleccionan suficientes componentes principales para retener una alta proporción de la variabilidad total, pero esto puede variar según el caso de uso específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11827c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling is required before applying pca\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(x)\n",
    "scaled_data = pd.DataFrame(scaled_data)\n",
    "scaled_data\n",
    "pca = PCA(n_components = 4)\n",
    "principalComponents = pca.fit_transform(scaled_data)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2','PC3','PC4'])\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f19475a",
   "metadata": {},
   "source": [
    "El resultado obtenido muestra la variación explicada por cada uno de los primeros cuatro componentes principales (*PC*) después de aplicar el *análisis de componentes principales* (*PCA*) a los datos escalados. Cada valor en la lista representa la proporción de variación total en los datos que es explicada por el correspondiente componente principal. Aquí hay un análisis de estos resultados:\n",
    "\n",
    "- El *PC1* explica el $32.52\\%$ de la variación total en los datos. Esto indica que el *PC1* captura una cantidad significativa de información de las características originales y es la componente principal más importante.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- El *PC2* explica el $18.03\\%$ de la variación total. El *PC2* captura información adicional, pero en menor medida que *PC1*. Aunque es menos importante que *PC1*, aún es una contribución significativa.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- El *PC3* explica el $14.60\\%$ de la variación total. El *PC3* agrega información adicional, pero con una contribución menor en comparación con *PC1* y *PC2*.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- El *PC4* explica el $11.96\\%$ de la variación total. El *PC4* es la componente principal que explica la menor cantidad de variación, pero aún puede ser relevante dependiendo de los objetivos de reducción de dimensionalidad.\n",
    "\n",
    "Estos resultados  indican cuánta información se retiene al representar los datos en un espacio de menor dimensión utilizando *PCA*. En este caso, los primeros cuatro componentes principales explican aproximadamente el $77.11\\%$ ($32.52\\% + 18.03\\% + 14.60\\% + 11.96\\%$) de la variación total en los datos. Esta información es útil para tomar decisiones sobre cuántos componentes principales seleccionar para reducir la dimensionalidad de los datos mientras se conserva la mayor cantidad posible de información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9ace31",
   "metadata": {},
   "source": [
    "## Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eafd3b",
   "metadata": {},
   "source": [
    "Una vez seleccionadas las características principales, vamos a aplicar el modelo a los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1376d74",
   "metadata": {},
   "source": [
    "### División Train - Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078811e7",
   "metadata": {},
   "source": [
    "Para modelar, primero tenemos que dividir nuestros datos en conjuntos de datos de entrenamiento y prueba, para ello, se empleará la función [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) del módulo `scikit-learn`. Se indica que el $20\\%$ de los datos se reservarán para el conjunto de prueba (`test`), mientras que el $80\\%$ se utilizará para el conjunto de entrenamiento (`train`). `random_state=0` establece una semilla aleatoria para garantizar que la división sea reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9164cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27868f8",
   "metadata": {},
   "source": [
    "### Búsqueda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff05190",
   "metadata": {},
   "source": [
    "Se empleará el concepto de [Búsqueda de Cuadrícula con Validación Cruzada](https://en.wikipedia.org/wiki/Hyperparameter_optimization) ([`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)) para la sintonización de hiperparámetros en el aprendizaje automático. Grid Search CV es una técnica utilizada para encontrar la mejor combinación de hiperparámetros para un modelo de aprendizaje automático al buscar sistemáticamente a través de un conjunto predefinido de hiperparámetros y evaluar el rendimiento del modelo mediante validación cruzada.\n",
    "\n",
    "A continuación se importan diferentes tipos de algoritmos de aprendizaje automático para problemas de clasificación. Dependiendo del conjunto de datos y del problema que se esté abordando, se pueden probar diferentes modelos y técnicas para encontrar el que mejor se adapte a las necesidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6409255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d87fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params={\n",
    "    \"decision_tree\":{\n",
    "        'model':DecisionTreeClassifier(random_state=0),\n",
    "        'params':{\n",
    "              'max_features': ['sqrt', 'log2'],\n",
    "              'max_depth':[3,4,5,6],\n",
    "              'criterion':['gini', 'entropy', 'log_loss']\n",
    "        }\n",
    "    },\n",
    "     \"random_forest\":{\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params':{\n",
    "            'n_estimators': [10,50,100], \n",
    "            'max_features': ['sqrt', 'log2'],\n",
    "            'max_depth':[3,4,5,6],\n",
    "            'criterion':['gini', 'entropy', 'log_loss']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "scores_scaled = []\n",
    "for mn,mp in model_params.items(): \n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv = 5, return_train_score = False)\n",
    "    clf.fit(x_train,y_train)\n",
    "    scores_scaled.append({'model':mn, 'best score':clf.best_score_,'best params': clf.best_params_})\n",
    "\n",
    "df3 = pd.DataFrame(scores_scaled, columns = ['model','best score','best params'])\n",
    "df3.sort_values(by=['best score'], ascending=False)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c2e363",
   "metadata": {},
   "source": [
    "Veamos los resultados alcanzados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d512ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca2c3ce",
   "metadata": {},
   "source": [
    "De estos, el modelo `random_forest` ofrece la mayor precisión, con un $76.4\\%$.\n",
    "\n",
    "Ahora verificamos la precisión de otros modelos, que deben aplicarse a los datos escalados. Para esto, primero divida los datos escalados en particiones de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f4a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set for scaled data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(scaled_data, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea0b9b5",
   "metadata": {},
   "source": [
    "Se aplicarán tres modelos de aprendizaje automático: *Support Vector Machine* (*SVM*), *Regresión Logística* y *Gradient Boosting*, y se utilizarán datos escalados para mejorar la precisión de los modelos. Es decir, antes de entrenar y evaluar estos modelos, los datos se someterán a un proceso de escalado, como se hizo previamente con los otros modelos.\n",
    "\n",
    "El proceso de escalado asegura que todas las variables tengan una influencia equitativa en los modelos, lo que puede llevar a una mejor precisión en las predicciones. Los modelos de *SVM* y *Regresión Logística*, en particular, pueden verse afectados por la magnitud de las variables, por lo que es común escalar los datos antes de usarlos con estos algoritmos. El modelo de *aumento de gradiente* (*Gradient Boosting*) también puede beneficiarse de datos escalados para un mejor rendimiento.\n",
    "\n",
    "Esta es una práctica recomendada en el aprendizaje automático al utilizar datos escalados para estos modelos, lo que debería resultar en una mayor precisión en las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752dd307",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params2={\n",
    " \"svm\":{\n",
    " 'model': SVC(random_state=0),\n",
    " 'params':{\n",
    " 'C': [0.1, 1, 10, 100, 1000], \n",
    " 'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    " 'kernel': ['rbf','linear']\n",
    " }\n",
    " },\n",
    " 'logistic_regression':{\n",
    " 'model': LogisticRegression(),\n",
    " 'params':{'penalty':[ 'l2', 'elasticnet'], \n",
    " 'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    " 'C': [1,5,10]\n",
    " }\n",
    " },\n",
    "\"gradient_boosting\":{\n",
    " 'model': GradientBoostingClassifier(),\n",
    " 'params':{\n",
    " 'max_depth':[3,4,5],\n",
    " 'n_estimators':[5,10,50,100],\n",
    " 'criterion':['friedman_mse', 'squared_error', 'mse']\n",
    " }\n",
    " \n",
    " }\n",
    "}\n",
    "scores_scaled2 = []\n",
    "\n",
    "for mn,mp in model_params2.items():\n",
    "    clf2 = GridSearchCV(mp['model'], mp['params'], cv = 5, return_train_score = False)\n",
    "    clf2.fit(x_train1,y_train1)\n",
    "    scores_scaled2.append({'model':mn, 'best score':clf2.best_score_, 'best params': clf2.best_params_})\n",
    "\n",
    "df4 = pd.DataFrame(scores_scaled2, columns = ['model','best score','best params'])\n",
    "df4.sort_values(by = ['best score'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cdf002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ceed84",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3d638e",
   "metadata": {},
   "source": [
    "Dado que el bosque aleatorio obtuvo la mayor precisión en los datos de entrenamiento ($76,4\\%$) de los 5 algoritmos, elegiremos el modelo `Random Forest` para nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba81b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_final = RandomForestClassifier(criterion ='gini', max_depth = 4, max_features = 'log2', n_estimators = 100)\n",
    "model_final.fit(x_train, y_train)\n",
    "y_pred1 = model_final.predict(x_test)\n",
    "print('Accuracy of model for testing data is ',accuracy_score(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73c4f6d",
   "metadata": {},
   "source": [
    "¡Eso suena muy bien! Una precisión del $77,92\\%$ en los datos de prueba indica que el modelo de clasificación *Random Forest* que se ha entrenado es capaz de predecir correctamente la etiqueta de clase en aproximadamente el $77,92\\%$ de las muestras de prueba. En otras palabras, el modelo es bastante efectivo en la clasificación de los datos de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd336ae",
   "metadata": {},
   "source": [
    "### Rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed0ccb",
   "metadata": {},
   "source": [
    "Sin embargo, hay qué recordar que la precisión no es la única métrica importante a considerar al evaluar un modelo de clasificación. Dependiendo de la aplicación y de la distribución de clases en los datos, puede ser útil examinar otras métricas como la *recall*, la *precisión*, la *F1-score*, la *matriz de confusión*, etc., para obtener una imagen más completa del rendimiento del modelo. \n",
    "\n",
    "Vamos a emplear la matriz de confusión y el mapa de calor para visualizarla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "sns.heatmap(pd.DataFrame(confusion_matrix(y_test,y_pred1)), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0b519d",
   "metadata": {},
   "source": [
    "La matriz de confusión muestra cómo se clasificaron las muestras en el conjunto de prueba.\n",
    "\n",
    "- ***Verdaderos positivos (TP):*** Son los casos en los que el modelo predijo correctamente la clase positiva (en este caso, diabetes): $25$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Verdaderos negativos (TN):*** Son los casos en los que el modelo predijo correctamente la clase negativa (en este caso, no diabetes): $95$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Falsos positivos (FP):*** Son los casos en los que el modelo predijo incorrectamente la clase positiva cuando en realidad era negativa. Es decir, el modelo hizo una predicción de diabetes cuando no había diabetes: $12$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Falsos negativos (FN):*** Son los casos en los que el modelo predijo incorrectamente la clase negativa cuando en realidad era positiva. Es decir, el modelo hizo una predicción de no diabetes cuando había diabetes: 22\n",
    "\n",
    "Estos valores son esenciales para calcular métricas de evaluación como *precisión*, *exhaustividad* y *F1-score*. Estas métricas  dan una idea del rendimiento general del modelo en la clasificación de casos positivos y negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7935d",
   "metadata": {},
   "source": [
    "### Validación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9382bd8",
   "metadata": {},
   "source": [
    "Por último, realicemos una validación cruzada para encontrar la precisión media. En particular, se calculará la puntuación de validación cruzada para el modelo final utilizando 5 divisiones (folds) diferentes del conjunto de datos. La precisión promedio dará una idea de qué tan bien se desempeña el modelo en datos no vistos y puede ser una métrica útil para evaluar su rendimiento.\n",
    "\n",
    "Los \"5 folds\" en la validación cruzada se refieren a una técnica en la que se divide el conjunto de datos en 5 partes aproximadamente iguales o \"folds\". El propósito principal de esta técnica es evaluar el rendimiento de un modelo de manera más robusta y precisa, especialmente cuando se dispone de un conjunto de datos limitado.\n",
    "\n",
    "El proceso de validación cruzada de 5 folds se realiza de la siguiente manera:\n",
    "\n",
    "1. El conjunto de datos se divide en 5 partes (folds) de aproximadamente igual tamaño.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "2. El modelo se entrena y se evalúa 5 veces, cada vez utilizando una combinación diferente de 4 de los 5 folds como datos de entrenamiento y el fold restante como datos de prueba.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "3. Se calcula una métrica de evaluación (como la precisión) para cada una de las 5 iteraciones.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "4. Finalmente, se calcula la puntuación promedio y posiblemente otras estadísticas (como la desviación estándar) de las métricas obtenidas en las 5 iteraciones.\n",
    "\n",
    "Esta técnica permite obtener una estimación más robusta del rendimiento del modelo, ya que evalúa el modelo en diferentes subconjuntos de datos. Ayuda a detectar si el modelo está sobreajustado (overfitting) o subajustado (underfitting) y proporciona una idea más precisa de cómo podría funcionar en datos no vistos.\n",
    "\n",
    "En resumen, los \"5 folds\" en la validación cruzada son 5 divisiones del conjunto de datos que se utilizan para entrenar y evaluar repetidamente un modelo, lo que ayuda a obtener una evaluación más confiable del rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189fd8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score = cross_val_score(model_final, x, y, cv = 5)\n",
    "accuracy_rate = []\n",
    "accuracy_rate.append(score.mean())\n",
    "print('Average accuracy of the final model is ',accuracy_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e0e247",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8139a621",
   "metadata": {},
   "source": [
    "La conclusión del proceso para los datos de Diabetes en indios Pima podría ser la siguiente:\n",
    "\n",
    "- Hemos realizado un análisis exhaustivo de los datos de Diabetes en indios Pima, que incluyó la exploración de datos, la limpieza de datos, la visualización de datos y la construcción de un modelo de clasificación utilizando el algoritmo de Bosque Aleatorio (Random Forest).\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Después de aplicar la validación cruzada de 5 folds a nuestro modelo de Bosque Aleatorio, obtuvimos una precisión promedio del $75\\%$. Esto indica que nuestro modelo tiene un rendimiento razonable al predecir la presencia o ausencia de diabetes en función de las características de los pacientes.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- Sin embargo, es importante destacar que la precisión del modelo no es la única métrica a considerar. Para un problema de clasificación de diabetes, también es crucial evaluar la sensibilidad (la capacidad del modelo para detectar casos positivos de diabetes) y la especificidad (la capacidad del modelo para detectar casos negativos de diabetes) en función de los objetivos clínicos y las implicaciones de salud.\n",
    "\n",
    "En resumen, hemos construido un modelo de clasificación de diabetes que muestra un rendimiento decente en términos de precisión promedio. Este modelo puede ser útil como una herramienta de apoyo para la detección temprana de diabetes en pacientes indios Pima, pero es importante considerar otras métricas y realizar una evaluación más completa antes de su implementación clínica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd293d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
